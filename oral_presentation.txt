

## Slide 1: Title  
> **“Modeling Fatigue and Injury Risk in Athletic Movements: A Deep Learning Approach to Basketball Biomechanics”**  
> “Good afternoon. I’m Geoffrey Hadfield. Today I’ll walk you through how we applied LSTM‑based deep learning to forecast fatigue and flag injury risk during basketball shooting trials.”

---

## Slide 2: Introduction → Project Overview  
“Basketball requires split‑second moves and explosive jumps. As fatigue builds, joint stability declines and non‑contact injuries become far more likely. If we can predict an athlete’s fatigue trajectory and identify the moments when joints are high‑risk, coaches can intervene—adjusting drills or prescribing rest—before injury strikes. Our capstone project set out to create exactly that forecasting system.”

---

## Slide 3: Deep Learning Approach  
“Classical time‑series tools falter when signals combine smooth endurance drains with sudden exhaustion bursts. LSTM networks, however, learn to remember—or ignore—features over time, making them ideal for our multidimensional biomechanical and physiological streams.”

---

## Slide 4: Project Goals  
“We built two interconnected models:  
1. **Regression** of a continuous `exhaustion_rate`—how quickly fatigue accumulates frame by frame.  
2. **Classification** of `injury_risk`—a binary flag when fatigue crosses a high‑risk threshold.  
By combining them, we provide actionable insights: real‑time fatigue scores and early warning flags for injury prevention.”

---

## Slide 5: Sequence Analysis  
“Shooting sequences vary in length, so we tested three alignment methods:  
- **Hierarchical Dynamic Time Warping**  
- **Distributed Padding**  
- **Basic Sliding Window (`set_window`)**  
Surprisingly, the fixed sliding window delivered the best short‑term forecasts—allowing us to predict two windows ahead with consistent accuracy.”

---

## Slide 6: Key Literature  
“Two studies guided our design:  
1. A 2020 *Engineering Fracture Mechanics* paper using neural nets to model fatigue crack growth analogies in muscle (DOI 10.1016/j.engfracmech.2020.107402).  
2. A 2024 *Journal of Sports Science & Medicine* article forecasting injury risk by combining fatigue and biomechanical metrics (DOI 10.52082/jssm.2024.537).”

---

## Slide 7: Data Source  
“We leveraged the **SPL Open Biomechanics** dataset: 125 basketball shooting trials, each frame tagged with joint kinematics, simulated heart rate, sleep metrics, HRV, and more—yielding a rich, time‑synchronized X/Y data stream.”

---

## Slide 8: X‑Features — Joint Metrics  
“Per frame we record mechanically meaningful metrics:  
- **Joint Energy** (50–250 J)  
- **Joint Power** (100–1000 W)  
These describe how much work each joint does during the lift, release, and follow‑through.”

---

## Slide 9: X‑Features — Physiological Metrics  
“To capture systemic fatigue, we include simulated physiology:  
- **Heart Rate** (60–180 bpm)  
- **Sleep Quality & Duration**  
- **Resting HR & HRV**  
- **Stress Index**  
Together these enrich our model with whole‑body context.”

---

## Slide 10: X‑Features — Temporal & Asymmetry  
“We engineered higher‑order and asymmetry features:  
- **Exhaustion Rate per Trial** (our regression target)  
- **Rolling Averages & Lagged Exhaustion**  
- **Left/Right Joint Asymmetries**  
- **Player Height & Weight**  
In total, over 80 candidate inputs.”

---

## Slide 11: Y‑Variables — Regression  
> “**Exhaustion Rate** measures per‑trial fatigue accumulation rate:  
> \[
> \text{exhaustion_rate} = \frac{\Delta(\text{by_trial_exhaustion_score})}{\Delta(\text{by_trial_time})}
> \]  
> This gives us a dynamic, frame‑wise fatigue measure—far richer than a single end‑of‑trial score.”

---

## Slide 12: Y‑Variables — Classification  
> “**Injury Risk** flags high‑risk windows whenever rolling exhaustion exceeds the athlete’s own expanding 75th percentile:  
> ```python
> data['injury_risk'] = (data['rolling_exhaustion'] >
>     safe_expanding_quantile(data['rolling_exhaustion'])).astype(int)
> ```  
> This self‑referential threshold adapts to each player’s evolving capacity.”

---

## Slide 13: Energy Calculations  
> “We compute a normalized exhaustion score by cumulatively summing each trial’s total joint energy and dividing by the trial maximum:  
> ```python
> df['by_trial_energy'] = df.groupby('trial_id')['total_energy'].cumsum()
> df['by_trial_exhaustion_score'] = (
>     df.groupby('trial_id')['by_trial_energy']
>       .transform(lambda x: x / x.max())
> )
> ```  
> That score runs from 0 to 1.”

---

## Slides 14–15: Descriptive Statistics  
“We examined means, standard deviations, minima, and maxima for every feature.  For example, joint_power averaged ~20 W, with occasional spikes above 60 W.  These summaries confirmed no wild outliers lurked.”

---

## Slide 16: Multicollinearity Assessment  
“A near‑perfect 0.91 correlation emerged between joint_energy and joint_power.  Since joint_energy scored higher in feature‑importance analyses, we dropped joint_power to avoid redundancy.  We applied the same logic to highly correlated HR metrics.”

---

## Slide 17: Correlation Matrix  
*(Display heatmap)*  
“This heatmap reveals a few strong pairwise correlations—pruning these variables simplified our inputs without sacrificing signal.”

---

## Slides 18–21: Feature Importance (SHAP & Permutation)  
“After fitting preliminary LSTM and tree‑based models, we computed both SHAP and permutation importances.  
- For **injury_risk**, rolling_exhaustion_std, hip_asymmetry, and simulated_HR topped the charts.  
- For **exhaustion_rate**, lagged exhaustion, joint_energy, and rolling_hr_mean were most predictive.  
From these, we distilled three 10‑feature sets: one for overall fatigue, one for overall injury, and a specialized set per joint.”

---

## Slide 22: Data Visualizations  
“We plotted histograms and scatterplots of joint metrics against exhaustion_rate, ensuring our feature scales and relationships appeared sensible before model fitting.”

---

## Slide 23: Final Feature Selection  
“Armed with importance rankings, we finalized three lean feature sets—each containing the top ten predictors.  This ensured every model trained on its strongest signals.”

---

## Slide 24: **Model Selection Criteria**  
“We weighed two philosophies:  
1. **Stationarity‑Based** (ARIMA, N‑BEATS) – Highly interpretable but brittle under sudden regime shifts.  
2. **Adaptive Deep Learning** (LSTM variants) – Dynamically learns non‑linear patterns and abrupt fatigue spikes, requiring more data and compute.  
Because basketball fatigue blends slow drains and fast exhaustion—and we need both real‑time and offline insights—we focused on **LSTM‑family models**.”

---

## Slide 25: **LSTM Variants in Plain English**  

**Standard LSTM**  
- A two‑layer network that filters incoming frames, learning which past signals to remember or forget.  
- **Ideal for real‑time fatigue forecasting** on live drills.  
- **Trade‑off:** Lightweight and fast, but blind to future context.

**Bidirectional LSTM (BiLSTM)**  
- Runs two LSTMs—forward and backward—then merges them.  
- **Great for injury classification** on complete trials, spotting subtle pre‑ and post‑movement patterns.  
- **Trade‑off:** Twice the compute, not suited for live monitoring.

**TCN‑LSTM Hybrid**  
- A Temporal Convolutional Network first extracts features at multiple time scales, then an LSTM weaves those features into a temporal story.  
- **Best for** capturing both fast shocks (shot release) and slow trends (cumulative fatigue).  
- **Trade‑off:** More hyperparameters, longer training, needs more data.

**TCN‑BiLSTM (Exploratory)**  
- Combines multi‑scale convolution with bidirectional memory for maximum pattern capacity.  
- **Trade‑off:** Highest compute cost and overfitting risk.

**Baselines**  
- **N‑BEATS** for probabilistic forecasts,  
- **Exponential Smoothing** for a simple benchmark,  
- **XGBoost** to compare against tree‑based models.

---

## Slide 26: **Core LSTM Math—Explained**  
“Every LSTM cell uses three gates to manage memory:  
1. **Forget Gate** – decides which old details to discard.  
2. **Input Gate** – selects which new details to store.  
3. **Output Gate** – determines what to reveal from memory.  
This learnable gating lets the network tune itself to real‑time fatigue drifts and sudden exhaustion bursts.”

---

## Slide 27: Preprocessing & Training  
“We clipped negative values, standardized with z‑scores, filtered near‑zero variance columns, and imputed missing frames.  Models trained up to 200 epochs with Adam optimizer, batch size 32, and early stopping (patience = 5).”

---

## Slides 28–29: **Base Model Performance**  

**Exhaustion Forecast (Shot‑Phase LSTM):**  
- **MSE:** 0.0034  
- **MAE:** 0.0282  
- **R²:** 0.7340  

**Injury Classification (Trial‑Aggregated BiLSTM):**  
- **Accuracy:** 0.950  
- **Precision:** 0.950  
- **Recall:** 1.000  
- **F1 Score:** 0.974  

**XGBoost (Injury):** Accuracy 0.967

---

## Slides 30–31: **Joint‑Specific Models**  
“We trained separate LSTM or XGBoost models per joint.  The **right elbow** achieved 93% accuracy for injury risk; the **left wrist** topped 0.29 MSE for exhaustion rate.  These joint‑level predictions inform targeted load management.”

---

## Slide 32: Regression Forecast Plot  
*(Show shot_phase_agg_exhaustion_rate_forecast.png)*  
“Our LSTM tracks both gradual fatigue drifts and sudden jumps, giving actionable minute‑by‑minute exhaustion forecasts.”

---

## Slide 33: Alternative Forecasting  
*(Show nbeats_expsmoothing_forecast.png)*  
“By comparison, N‑BEATS and exponential smoothing delivered MAEs of 0.135 and 0.117—far worse than our 0.028.”

---

## Slide 34: Injury‑Risk Forecast Plot  
*(Show trial_agg_injury_forecast.png)*  
“This chart overlays predicted high‑risk windows (red) on actual fatigue spikes, enabling preemptive rest or technique tweaks.”

---

## Slide 35: Base Injury Model Plot  
*(Show overall_injury_forecast.png)*  
“Our overall classifier hits nearly 89% accuracy on raw sequences—a robust baseline for live monitoring.”

---

## Slide 36: Classification Alternatives  
“While LSTMs excel at temporal nuance, tree‑based methods (Random Forest, CatBoost, XGBoost) remain strong when data or compute are limited.  We recommend them as complementary baselines.”

---

## Slide 37: Conclusion → Best Models  
- **Exhaustion Prediction:** Shot‑Phase LSTM (R² = 0.7340; MAE = 0.0282)  
- **Injury Classification:** Trial‑Aggregated BiLSTM (F1 = 0.974)

“These dual‑pipeline LSTM models provide accurate, real‑time fatigue scores and high‑precision injury alerts.”

---

## Slide 38: Joint‑Specific Highlights  
- **Top Joints for Injury Risk:**  
  1. Right Elbow (93.0% accuracy, 0.861 F1)  
  2. Right Wrist (92.5%, 0.862 F1)  
  3. Left Hip (88.4%, 0.730 F1)  
- **Exhaustion Outliers:** Ankle models showed high variance—future work will refine low‑torque joint modeling.

---

## Slide 39: **Key Accomplishments**  
1. **Dual‑Pipeline Framework:** Seamlessly handled both fatigue regression and injury classification under one reproducible codebase.  
2. **Hierarchical Sequence Handling:** Demonstrated that a simple sliding‑window alignment outperforms more complex warping on near‑term forecasts.  
3. **Advanced Feature Engineering:** Introduced rolling statistics and joint‑asymmetry metrics that consistently ranked in the top ten predictors.  
4. **Modular LSTM Architectures:** Explored five LSTM‑based variants plus three classical baselines, quantifying interpretability vs. predictive power trade‑offs.  
5. **Actionable Accuracy:** Achieved MAE < 0.03 for fatigue and F1 > 0.97 for injury risk—meeting real‑world demands of athletic trainers.  
6. **Reproducibility & Deployment Readiness:** Packaged data pipelines, model checkpoints, and evaluation scripts in a public GitHub repo, complete with documentation.

---

## Slide 40: Applications & Future Work  
- **Real‑Time Monitoring Dashboards** for trainers  
- **Automated Injury‑Alert Systems**  
- **Extension to Other Sports** (e.g., soccer cutting drills)  
- **Incorporating Attention Layers** for pinpointing critical frames

---

## Slide 41: Limitations  
- Single‐player dataset—needs multi‐athlete validation  
- Simulated physiology—real wearable noise awaits  
- Compute demands—future work on model compression for edge devices

---

## Slide 42: Summary  
“By fusing biomechanics, simulated physiology, and tailored LSTM pipelines, we deliver minute‑by‑minute fatigue forecasts and high‑precision injury alerts.  This framework paves the way for smarter, safer athletic training.”

---

## Slide 43: Resources  
“Full code, data‑processing scripts, and model artifacts are on GitHub:  
`github.com/GeoffHadfield/capstone‑dsbio`  
Thank you for listening! I’m happy to take any questions.