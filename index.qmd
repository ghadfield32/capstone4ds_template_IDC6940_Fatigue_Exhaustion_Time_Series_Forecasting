---
title: "Capstone Project: Modeling Fatigue and Injury Risk in Athletic Movements like Basketball Shooting"
author: "Geoffrey Hadfield"
date: "2025-03-24"
format: html
editor: visual
---


## Introduction

Fatigue and injury risk modeling have become pivotal in sports analytics, particularly for basketball players. Predicting fatigue levels and assessing injury risk help in optimizing training programs and enhancing athlete longevity. Long Short-Term Memory (LSTM) networks, a type of Recurrent Neural Network (RNN), offer significant potential due to their ability to capture temporal patterns and sequential dependencies, critical in physiological and biomechanical data analysis.

Recent developments have showcased that fatigue accumulation can directly impact injury susceptibility, highlighting the importance of accurately modeling temporal fatigue progression. This project aims to leverage LSTM models to effectively forecast fatigue levels and predict joint injury risks in basketball players, contributing valuable insights for injury prevention strategies and optimized athletic performance.

Previous research on LSTM's efficacy in fatigue modeling forms the basis of our methodological approach, emphasizing the use of biomechanical and simulated physiological data.

Athlete Burnout: Research has shown that burnout is influenced by multiple factors (e.g., stress, training load, support systems) that vary among athletes. Customizing training and recovery protocols based on individual warning signs may mitigate injury risks.

Fatigue Data Collection: Detailed datasets have been published to capture muscle activity, motion capture data, and self-reported fatigue levels during shoulder rotations. These resources serve as a foundation for building predictive algorithms.

Methodological Advances: Recent studies have applied neural network architectures to model fatigue—such as a fully-connected network for predicting crack growth in metals [DOI: 10.1016/j.engfracmech.2020.107402]—and used combined physical and physiological workload metrics to forecast injury risk in professional soccer players [DOI: 10.52082/jssm.2024.537].

## Methods

##### LSTM (Long Short-Term Memory) Networks

Long Short-Term Memory (LSTM) networks are a specialized type of Recurrent Neural Network (RNN) designed to overcome the vanishing gradient problem that typically hinders standard RNNs when modeling long-term dependencies. Unlike traditional RNNs, LSTMs utilize gating mechanisms to selectively retain or discard information over sequences.

The core components of an LSTM cell include:

- **Forget Gate:**  
  $$f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)$$  
  Determines which information to remove from the cell state.

- **Input Gate:**  
  $$i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)$$  
  $$\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)$$  
  Decides which new candidate values to add to the cell state.

- **Cell State Update:**  
  $$C_t = f_t \odot C_{t-1} + i_t \odot \tilde{C}_t$$

- **Output Gate:**  
  $$o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)$$  
  $$h_t = o_t \odot \tanh(C_t)$$  
  Controls the information output to the next hidden state.

Here, \( W \) and \( b \) represent weights and biases, respectively, \( \sigma \) is the sigmoid function, and \( \odot \) is element-wise multiplication.

Compared to standard RNNs, LSTMs are especially effective in handling data with temporal correlations—making them suitable for modeling fatigue progression and injury risk in sequential biomechanical and physiological data.

##### Preprocessing Options: 
Sequencing into categories of different lengths causing us to test DTW vs Pad vs set_window to understand what would be the best option for handling this data 




## Data Description

The dataset utilized in this project comprises biomechanical and simulated physiological data collected from a Basketball Player from SPL Open Biomech dataset. Data was gathered during basketball shooting trials, incorporating joint-level biomechanical metrics and simulated physiological signals.

Key features derived in this project include:

##### Engineered Metrics
X metrix:
Joint Metrics: Aggregated joint energy and power are computed to serve as primary indicators of physical output.

Simulated Physiological Measures: A simulated heart rate is calculated as a function of mean and joint energy. In addition, “fake body” metrics (sleep quality, sleep duration, resting heart rate, heart rate variability, and stress index) are introduced to mimic wearable sensor data.

Temporal Dynamics: Lag features (e.g., previous trial exhaustion) and rolling statistics (moving averages, volatility measures) capture trends across trials. The trial exhaustion rate is defined as the change in exhaustion per trial.

Asymmetry Features: Differences between left and right joint metrics are measured to detect imbalances that may predispose athletes to injury.


y metrics:
'by_trial_exhaustion_score': "Exhaustion score normalized within each trial, calculated as cumulative energy divided by maximum energy in the trial.",
'joint_energy_by_trial_exhaustion_score': "Normalized exhaustion score for a specific joint within a trial, scaled to the maximum trial energy.",
data['exhaustion_rate'] = data['by_trial_exhaustion_score'].diff() / data['by_trial_time'].diff()
data['injury_risk'] = (data['rolling_exhaustion'] > safe_expanding_quantile(data['rolling_exhaustion'])).astype(int)


y_metrics chosen: 
  Regression: exhaustion_rate
    Went with how quickly fatigue builds up over time, exhaustion_rate being more relevant than the overall “snapshot” of fatigue for a trial, by_trial_exhaustion_score
  Classification: Injury_risk 
    Went with a optional but dangerous percentile (.75) of the rolling exhaustion to show and forecast moments when there is injury_risk

functions for above: 
def calculate_by_trial_energy(df, energy_columns, debug=False):
    """
    Calculates energy metrics (by-trial and overall) and exhaustion scores.
    """
    step_name = "Calculating by-trial energy and exhaustion scores"
    df_before = df.copy()

    new_columns = ['by_trial_energy', 'by_trial_exhaustion_score',
                   'overall_cumulative_energy', 'overall_exhaustion_score']

    # By-trial energy
    df['by_trial_energy'] = df.groupby('trial_id')['total_energy'].cumsum()
    # By-trial exhaustion score
    df['by_trial_exhaustion_score'] = (
        df.groupby('trial_id')['by_trial_energy']
        .transform(lambda x: x / x.max())
    )

    # Overall cumulative energy
    df['overall_cumulative_energy'] = df['total_energy'].cumsum()
    max_overall_cumulative_energy = df['overall_cumulative_energy'].max()
    df['overall_exhaustion_score'] = (
        df['overall_cumulative_energy'] / max_overall_cumulative_energy
    )

    df_after = df.copy()

    _print_debug_info(df_before, df_after, new_columns, step_name, debug)

    return df

def safe_expanding_quantile(s):
    return s.expanding().quantile(0.75).shift().fillna(0)


Dataset contains 125 trials.


- **Joint Metrics:**
  - Joint Energy (Joules, range: 50–250 J)
  - Joint Power (Watts, range: 100–1000 W)

- **Simulated Physiological Metrics:**
  - Simulated Heart Rate (beats per minute, range: 60–180 bpm)

- **Physical Traits** (for categorical handling)
  - Player weight
  - Player height 

- **Temporal Features:**
  - Trial Exhaustion Rate (dimensionless, normalized between 0–1)
  - Lag and rolling average features derived from trials

- **Asymmetry Features:**
  - Differences between left/right joints (Joules, range: -50 to 50 J)





## Analysis and Results

##### Descriptive Statistics

(change the below to a qmd table format)
Descriptive Statistics:
Variable	Type	Mean	Std Dev	Min	Max
joint_energy	float64	1.346318	0.914461	0.000000	49.115825
joint_power	float64	20.153438	12.502850	0.000000	60.832273
energy_acceleration	float64	-11458.53	133306.5	-2189662.0	0.072830
hip_asymmetry	float64	0.004024	0.006579	0.000000	0.184738
wrist_asymmetry	float64	0.022392	0.021801	0.000000	0.244317
rolling_power_std	float64	3.349565	3.234210	0.061415	17.383747
rolling_hr_mean	float64	61.079085	0.516449	60.09147	63.641281
rolling_energy_std	float64	0.203486	0.388516	0.002191	19.403572
simulated_HR	float64	61.079297	0.549815	60.000000	75.117490
player_height_in_meters	float64	1.910000	0.000000	1.910000	1.910000
player_weight__in_kg	float64	90.700000	4.263389e-14	90.700000	90.700000
by_trial_exhaustion_score	float64	0.450268	0.266615	0.000000	1.000000
injury_risk	int32	0.274897	0.446476	0.000000	1.000000



##### Check for Multicollinearity Variables
x metrics:
solution: we should combine or remove or review feature importance to ensure they are needed:
  - joint_energy and joint_power: The correlation is 0.909506 
    -method: dropping Joint energy because it has less correlation than 
  - rolling_hr_mean and simulated_HR: The correlation is 0.919149

joint_energy and joint_power (correlation: 0.909506)

For by_trial_exhaustion_score:

    joint_energy has higher importance (Perm: 0.109296, SHAP: 0.045438) than joint_power (Perm: 0.031813, SHAP: 0.023560)

For injury_risk:

    Both features have similar importance values, with joint_energy slightly higher (Perm: 0.154789, SHAP: 0.028769) compared to joint_power (Perm: 0.145825, SHAP: 0.028232)

rolling_hr_mean and simulated_HR (correlation: 0.919149)

For by_trial_exhaustion_score:

    simulated_HR has significantly higher importance (Perm: 1.386061, SHAP: 0.199147) than rolling_hr_mean (Perm: 0.454274, SHAP: 0.077322)

For injury_risk:

    rolling_hr_mean has higher importance (Perm: 1.079943, SHAP: 0.278289) than simulated_HR (Perm: 0.541816, SHAP: 0.082835)
1. For joint_energy and joint_power:

Unlike the initial suggestion, the data shows that joint_energy actually has higher importance for both target variables. Given this contradiction with the original recommendation:

    Keep joint_energy since it has higher importance metrics for both targets


2. For rolling_hr_mean and simulated_HR:

These features show target-dependent importance, which complicates the decision:

    For by_trial_exhaustion_score: Keep simulated_HR (drop rolling_hr_mean)

    For injury_risk: Keep rolling_hr_mean (drop simulated_HR)



x to y metrics:
correlation:
  - by_trial_exhaustion_score shows high correlations with rolling_hr_mean (0.865287) and simulated_HR (0.879951)


<img src="images/corr_matrix.png" alt="Correlation matrix for LSTM Regression y_var= by_trial_exhaustion_score and injury_risk" style="width:100%; display:block; margin: 0 auto;" />


<img src="images/shap_importance_injury_risk.png" alt="Perm and SHAP importance for Regression Model Forecasting Injury Risk" style="width:100%; display:block; margin: 0 auto;" />

<img src="images/permutation_importance_injury_risk.png" alt="Perm and SHAP importance for Regression Model Forecasting Injury Risk" style="width:100%; display:block; margin: 0 auto;" />


<img src="images/shap_importance_exhaustion_rate.png" alt="Perm and SHAP importance for Regression Model Forecasting Exhaustion Rate" style="width:100%; display:block; margin: 0 auto;" />

<img src="images/permutation_importance_exhaustion_rate.png" alt="Perm and SHAP importance for Regression Model Forecasting Exhaustion Rate" style="width:100%; display:block; margin: 0 auto;" />


##### Data Visualizations

- Histogram distributions for joint metrics.
<img src="images/histograms.png" alt="Joint Histograms" style="width:100%; display:block; margin: 0 auto;" />

- Scatter plots showing correlation between physiological metrics and fatigue rates.
<img src="images/scatter_plot_exhaustion_score.png" alt="Joint  by Exhaustion Rate Scatter Plot" style="width:100%; display:block; margin: 0 auto;" />






##### Modeling and Results
Steps:
    Explain your data preprocessing and cleaning steps.

    Present your key findings in a clear and concise manner.

    Use visuals to support your claims.

    Tell a story about what the data reveals.

work below----------------




Predictive Modeling Pipelines Pipeline 1: Regression for Predicting Trial Exhaustion Rate

       
Input Features: Aggregated joint metrics, simulated physiological features, and temporal features.

Model: A baseline linear regression model is used, with future plans to incorporate Random Forests, Gradient Boosting, or LSTM networks.

Evaluation: Model performance is assessed using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R², along with visualizations comparing predicted versus actual exhaustion rates.


Pipeline 2: Classification for Predicting Joint Injury Risk

        
Input Features: Joint-specific metrics, asymmetry measurements, and cumulative load indicators.

Labeling: Trials are classified as high injury risk if a rolling sum of joint stress exceeds a threshold (e.g., the 75th percentile).

Model: Initially, logistic regression or decision tree classifiers are employed. Future work may involve Random Forests or neural network-based methods.

Evaluation: Metrics such as accuracy, precision, recall, F1-score, and ROC-AUC are used, supplemented by feature importance analyses using SHAP values.


Integration and Modularity

Both pipelines share common preprocessing and feature engineering modules, ensuring that the workflow is modular and reproducible. Visualization tools—including histograms, correlation matrices, and temporal trend plots—are used throughout the analysis to validate each transformation step. Experimental Results

The LSTM-based regression model for fatigue prediction demonstrated promising results:

       
MSE: 0.00596

MAE: 0.01762

R² Score: 0.91808


Similarly, the injury risk classifier achieved strong performance:

         
Overall Accuracy: 98.16%

Precision: 93.84%

Recall: 99.77%

F1 Score: 96.72%





### Conclusion
Steps:
    Summarize your key findings.

    Discuss the implications of your results.
-----work below:

Joint-specific models yielded varying metrics, reflecting the inherent complexity of localized biomechanical data. Discussion

This project illustrates the successful application of deep learning to model fatigue and predict injury risk in a real-world sports setting. Key challenges included managing the variability in biomechanical signals and optimizing model performance through careful feature engineering. The integration of temporal dynamics and asymmetry features was critical in capturing the underlying physiological responses. Future work may explore attention mechanisms or hybrid architectures to further refine predictive accuracy. Conclusion

By combining real athlete data with simulated physiological metrics, this capstone project provides a novel approach to predicting fatigue and injury risks in basketball players. The dual-pipeline strategy (regression and classification) along with modular integration of preprocessing and feature engineering modules establishes a robust framework that is transparent, reproducible, and adaptable for future research and practical deployment. References



### Resources

DataCamp Tutorial: Introduction to SHAP Values for Machine Learning Interpretability

DataCamp Tutorial: Mastering Bayesian Optimization in Data Science

Fatigue Analysis Study, DOI: 10.1016/j.engfracmech.2020.107402

Injury Prediction Study, DOI: 10.52082/jssm.2024.537

Nature Articles:

    Factors Leading to Athlete Burnout

    Dataset for Fatigue Analysis during Shoulder Rotations



















EXAMPLE:
-------------------------------------

Writing a great story for data science projects - spring 2025

This is a Report Template Quarto
Author

Students names (Advisor: Dr. Cohen)
Published

January 14, 2025

Slides: slides.html ( Go to slides.qmd to edit)
Important

Remember: Your goal is to make your audience understand and care about your findings. By crafting a compelling story, you can effectively communicate the value of your data science project.

Carefully read this template since it has instructions and tips to writing!
Introduction

The introduction should:

    Develop a storyline that captures attention and maintains interest.

    Your audience is your peers

    Clearly state the problem or question you’re addressing.

    Introduce why it is relevant needs.

    Provide an overview of your approach.

Example of writing including citing references:

This is an introduction to ….. regression, which is a non-parametric estimator that estimates the conditional expectation of two variables which is random. The goal of a kernel regression is to discover the non-linear relationship between two random variables. To discover the non-linear relationship, kernel estimator or kernel smoothing is the main method to estimate the curve for non-parametric statistics. In kernel estimator, weight function is known as kernel function (Efromovich 2008). Cite this paper (Bro and Smilde 2014). The GEE (Wang 2014). The PCA (Daffertshofer et al. 2004). Topology can be used in machine learning (Adams and Moy 2021)

This is my work and I want to add more work…
Methods

    Detail the models or algorithms used.

    Justify your choices based on the problem and data.

The common non-parametric regression model is
, where can be defined as the sum of the regression function value for . Here is unknown and some errors. With the help of this definition, we can create the estimation for local averaging i.e. can be estimated with the product of average and is near to

. In other words, this means that we are discovering the line through the data points with the help of surrounding data points. The estimation formula is printed below (R Core Team 2019):

is the sum of weights that belongs to all real numbers. Weights are positive numbers and small if is far from

.

Another equation:

Analysis and Results
Data Exploration and Visualization

    Describe your data sources and collection process.

    Present initial findings and insights through visualizations.

    Highlight unexpected patterns or anomalies.

A study was conducted to determine how…
Code

Code

state 	abb 	region 	population 	total
Alabama 	AL 	South 	4779736 	135
Alaska 	AK 	West 	710231 	19
Arizona 	AZ 	West 	6392017 	232
Arkansas 	AR 	South 	2915918 	93
California 	CA 	West 	37253956 	1257
Colorado 	CO 	West 	5029196 	65
Code

Modeling and Results

    Explain your data preprocessing and cleaning steps.

    Present your key findings in a clear and concise manner.

    Use visuals to support your claims.

    Tell a story about what the data reveals.

Conclusion

    Summarize your key findings.

    Discuss the implications of your results.

