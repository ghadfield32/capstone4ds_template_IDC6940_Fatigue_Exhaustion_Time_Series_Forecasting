[
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Capstone Project: Modeling Fatigue and Injury Risk in Baseball Pitching",
    "section": "",
    "text": "Abstract\nIn this capstone project, we leverage real athlete data from Driveline Baseball alongside novel sensor measurements to predict fatigue and joint injury risks in baseball pitchers. Using an LSTM-based recurrent neural network (RNN) architecture, the project combines biomechanical data with simulated physiological metrics. Two parallel pipelines—one for regression (predicting trial exhaustion rates) and another for classification (identifying joint injury risk)—are developed. This work integrates advanced feature engineering, temporal dynamics, and modular data preprocessing, offering robust insights for injury prevention and performance analytics. Introduction\nRecent advances in sports science have underscored the importance of combining biomechanical and physiological data for injury prevention. In my internship at Driveline Baseball, the dataset was upgraded to include real athlete data. To further enhance the analysis, this project incorporates EMG sensors to capture muscle contraction, acceleration, and gyroscopic measurements during the pitching motion. These additional measurements—placed on the flexor carpi radialis (FCR) and other key muscles—aim to improve the prediction of ulnar collateral ligament (UCL) injuries.\nTwo resources support this work:\nThe raw sensor data is being compiled and will be available at emg_fatigue_analysis.\n\nA pre-established pipeline for LSTM-based fatigue prediction is available at LSTM RNN Pipeline.\nLiterature Review\nThe literature indicates that predicting fatigue and injury risk in athletes requires an integration of biomechanical outputs with physiological signals. Key findings from previous studies include:\nAthlete Burnout: Research has shown that burnout is influenced by multiple factors (e.g., stress, training load, support systems) that vary among athletes. Customizing training and recovery protocols based on individual warning signs may mitigate injury risks.\n\nFatigue Data Collection: Detailed datasets have been published to capture muscle activity, motion capture data, and self-reported fatigue levels during shoulder rotations. These resources serve as a foundation for building predictive algorithms.\n\nMethodological Advances: Recent studies have applied neural network architectures to model fatigue—such as a fully-connected network for predicting crack growth in metals [DOI: 10.1016/j.engfracmech.2020.107402]—and used combined physical and physiological workload metrics to forecast injury risk in professional soccer players [DOI: 10.52082/jssm.2024.537].\nThese studies, along with tutorials on SHAP values and Bayesian optimization from DataCamp, inform our approach to feature engineering and model selection. Methodology Data Loading and Preprocessing\nThe project begins by merging a CSV file containing trial-level measurements (e.g., joint energy and power) with participant metadata using unique identifiers like trial_id and player_participant_id. Rigorous data cleaning (including imputation and removal of missing values) is performed with comprehensive logging and debugging routines. Feature Engineering\nKey features derived in this project include:\nJoint Metrics: Aggregated joint energy and power are computed to serve as primary indicators of physical output.\n\nSimulated Physiological Measures: A simulated heart rate is calculated as a function of mean and joint energy. In addition, “fake body” metrics (sleep quality, sleep duration, resting heart rate, heart rate variability, and stress index) are introduced to mimic wearable sensor data.\n\nTemporal Dynamics: Lag features (e.g., previous trial exhaustion) and rolling statistics (moving averages, volatility measures) capture trends across trials. The trial exhaustion rate is defined as the change in exhaustion per trial.\n\nAsymmetry Features: Differences between left and right joint metrics are measured to detect imbalances that may predispose athletes to injury.\nWorkout Simulation\nTo mimic the progression of fatigue:\nWorkout 1: Contains the original 125 trials.\n\nWorkout 2: Is a duplicate of the original trials but simulates gradual deterioration in fake body metrics (e.g., lower sleep quality, higher resting heart rate) by adding a workout_id and trial counter.\nThese two datasets are concatenated to form a comprehensive dataset for subsequent modeling. Predictive Modeling Pipelines Pipeline 1: Regression for Predicting Trial Exhaustion Rate\nInput Features: Aggregated joint metrics, simulated physiological features, and temporal features.\n\nModel: A baseline linear regression model is used, with future plans to incorporate Random Forests, Gradient Boosting, or LSTM networks.\n\nEvaluation: Model performance is assessed using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R², along with visualizations comparing predicted versus actual exhaustion rates.\nPipeline 2: Classification for Predicting Joint Injury Risk\nInput Features: Joint-specific metrics, asymmetry measurements, and cumulative load indicators.\n\nLabeling: Trials are classified as high injury risk if a rolling sum of joint stress exceeds a threshold (e.g., the 75th percentile).\n\nModel: Initially, logistic regression or decision tree classifiers are employed. Future work may involve Random Forests or neural network-based methods.\n\nEvaluation: Metrics such as accuracy, precision, recall, F1-score, and ROC-AUC are used, supplemented by feature importance analyses using SHAP values.\nIntegration and Modularity\nBoth pipelines share common preprocessing and feature engineering modules, ensuring that the workflow is modular and reproducible. Visualization tools—including histograms, correlation matrices, and temporal trend plots—are used throughout the analysis to validate each transformation step. Experimental Results\nThe LSTM-based regression model for fatigue prediction demonstrated promising results:\nMSE: 0.00596\n\nMAE: 0.01762\n\nR² Score: 0.91808\nSimilarly, the injury risk classifier achieved strong performance:\nOverall Accuracy: 98.16%\n\nPrecision: 93.84%\n\nRecall: 99.77%\n\nF1 Score: 96.72%\nJoint-specific models yielded varying metrics, reflecting the inherent complexity of localized biomechanical data. Discussion\nThis project illustrates the successful application of deep learning to model fatigue and predict injury risk in a real-world sports setting. Key challenges included managing the variability in biomechanical signals and optimizing model performance through careful feature engineering. The integration of temporal dynamics and asymmetry features was critical in capturing the underlying physiological responses. Future work may explore attention mechanisms or hybrid architectures to further refine predictive accuracy. Conclusion\nBy combining real athlete data with simulated physiological metrics, this capstone project provides a novel approach to predicting fatigue and injury risks in baseball pitchers. The dual-pipeline strategy (regression and classification) along with modular integration of preprocessing and feature engineering modules establishes a robust framework that is transparent, reproducible, and adaptable for future research and practical deployment. References\nDataCamp Tutorial: Introduction to SHAP Values for Machine Learning Interpretability\n\nDataCamp Tutorial: Mastering Bayesian Optimization in Data Science\n\nFatigue Analysis Study, DOI: 10.1016/j.engfracmech.2020.107402\n\nInjury Prediction Study, DOI: 10.52082/jssm.2024.537\n\nNature Articles:\n\n    Factors Leading to Athlete Burnout\n\n    Dataset for Fatigue Analysis during Shoulder Rotations"
  },
  {
    "objectID": "final_notebooks/lstm_rnn_energy_predict_granular_dataset_final_project.html",
    "href": "final_notebooks/lstm_rnn_energy_predict_granular_dataset_final_project.html",
    "title": "Final full idea put together",
    "section": "",
    "text": "Load Data\n\nimport numpy as np\nimport pandas as pd\nimport json\nimport sys\nimport logging\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    mean_absolute_error, r2_score, accuracy_score,\n    precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n)\nimport shap\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n\n\n###############################################################################\n# HELPER FUNCTION FOR DEBUG OUTPUTS\n###############################################################################\ndef _print_debug_info(step_name, df, new_columns=None, debug=False):\n    \"\"\"\n    Prints debug information about a DataFrame after a processing step.\n    \n    When debug=True, prints:\n      - The step name.\n      - The DataFrame shape.\n      - If new_columns is provided (a list of column names), prints for each:\n          • Data type and a sample of unique values (up to 5).\n    When debug=False, prints a single-line message indicating step completion.\n    \"\"\"\n    if debug:\n        logging.info(f\"Step [{step_name}]: DataFrame shape = {df.shape}\")\n        if new_columns:\n            logging.info(f\"New columns added: {new_columns}\")\n            for col in new_columns:\n                sample = df[col].dropna().unique()[:5]\n                logging.info(f\" - {col}: dtype={df[col].dtype}, sample values={sample}\")\n    else:\n        logging.info(f\"Step [{step_name}] completed.\")\n\n\n###############################################################################\n# FUNCTION DEFINITIONS\n###############################################################################\ndef load_data(csv_path, json_path, participant_id='P0001', debug=False):\n    \"\"\"\n    Loads the main dataset and participant information, then merges them.\n    \n    Parameters:\n      - csv_path (str): Path to the main CSV file.\n      - json_path (str): Path to the participant information JSON file.\n      - participant_id (str): Participant identifier.\n      - debug (bool): If True, prints detailed debug info.\n    \n    Returns:\n      - data (pd.DataFrame): Merged DataFrame.\n    \"\"\"\n    # Load main dataset\n    try:\n        data = pd.read_csv(csv_path)\n        logging.info(f\"Loaded data from {csv_path} with shape {data.shape}\")\n    except FileNotFoundError:\n        logging.error(f\"File not found: {csv_path}\")\n        sys.exit(1)\n    except Exception as e:\n        logging.error(f\"Error loading {csv_path}: {e}\")\n        sys.exit(1)\n    \n    data['participant_id'] = participant_id\n    logging.info(f\"Added 'participant_id' column with value '{participant_id}'\")\n    \n    # Load participant info\n    try:\n        with open(json_path, 'r') as file:\n            participant_info = json.load(file)\n        participant_df = pd.DataFrame([participant_info])\n        logging.info(f\"Loaded participant information from {json_path}\")\n    except FileNotFoundError:\n        logging.error(f\"File not found: {json_path}\")\n        sys.exit(1)\n    except json.JSONDecodeError:\n        logging.error(f\"Invalid JSON format in {json_path}\")\n        sys.exit(1)\n    except Exception as e:\n        logging.error(f\"Error loading {json_path}: {e}\")\n        sys.exit(1)\n    \n    data = pd.merge(data, participant_df, on='participant_id', how='left')\n    logging.info(f\"Merged participant data. New shape: {data.shape}\")\n    _print_debug_info(\"load_data\", data, debug=debug)\n    return data\n\ndef calculate_joint_angles(df, connections, debug=False):\n    \"\"\"\n    Calculates joint angles from coordinate data using vector mathematics.\n    \n    Parameters:\n        df (pd.DataFrame): DataFrame containing joint coordinates.\n        connections (list): Joint connections defining biomechanical segments.\n        debug (bool): Enable debug logging.\n        \n    Returns:\n        df (pd.DataFrame): Updated DataFrame with new angle columns.\n    \"\"\"\n    angle_columns = []\n    \n    # Define angle calculation points for key joints\n    # Note: The new \"KNEE\" definition uses hip, knee, and ankle as the points.\n    angle_definitions = {\n        'SHOULDER': {\n            'left': ['L_HIP', 'L_SHOULDER', 'L_ELBOW'],\n            'right': ['R_HIP', 'R_SHOULDER', 'R_ELBOW']\n        },\n        'HIP': {\n            'left': ['L_SHOULDER', 'L_HIP', 'L_KNEE'],\n            'right': ['R_SHOULDER', 'R_HIP', 'R_KNEE']\n        },\n        'KNEE': {\n            'left': ['L_HIP', 'L_KNEE', 'L_ANKLE'],\n            'right': ['R_HIP', 'R_KNEE', 'R_ANKLE']\n        },\n        'ANKLE': {\n            'left': ['L_KNEE', 'L_ANKLE', 'L_5THTOE'],\n            'right': ['R_KNEE', 'R_ANKLE', 'R_5THTOE']\n        }\n    }\n\n    for joint, sides in angle_definitions.items():\n        for side in ['left', 'right']:\n            points = sides[side]\n            prefix = 'L' if side == 'left' else 'R'\n            \n            # Build list of required coordinate columns for this calculation\n            required_cols = []\n            for point in points:\n                required_cols += [f'{point}_x', f'{point}_y', f'{point}_z']\n                \n            if all(col in df.columns for col in required_cols):\n                # Calculate the vectors needed for the angle\n                vec1 = df[[f'{points[0]}_x', f'{points[0]}_y', f'{points[0]}_z']].values - \\\n                       df[[f'{points[1]}_x', f'{points[1]}_y', f'{points[1]}_z']].values\n                vec2 = df[[f'{points[2]}_x', f'{points[2]}_y', f'{points[2]}_z']].values - \\\n                       df[[f'{points[1]}_x', f'{points[1]}_y', f'{points[1]}_z']].values\n\n                # Compute the dot product and the norms of the vectors\n                dot_product = np.sum(vec1 * vec2, axis=1)\n                norm_product = np.linalg.norm(vec1, axis=1) * np.linalg.norm(vec2, axis=1)\n                \n                # Compute the angle (in degrees) and add a small epsilon to avoid division by zero\n                angles = np.degrees(np.arccos(dot_product / (norm_product + 1e-8)))\n                \n                col_name = f'{prefix}_{joint}_angle'\n                df[col_name] = angles\n                angle_columns.append(col_name)\n                \n                if debug:\n                    logging.info(f\"Calculated {col_name} with mean: {angles.mean():.2f}°\")\n            else:\n                logging.warning(f\"Missing coordinates for {prefix}_{joint} angle calculation\")\n\n    _print_debug_info(\"calculate_joint_angles\", df, new_columns=angle_columns, debug=debug)\n    return df\n\n\n\ndef prepare_joint_features(data, debug=False):\n    \"\"\"\n    Aggregates joint-level energy and power, creates additional biomechanical features,\n    and adds new features:\n      - energy_acceleration: instantaneous rate of change of joint_energy.\n      - ankle_power_ratio: ratio of left to right ankle ongoing power.\n      - Additional asymmetry metrics for shoulders, hips, ankles, wrists, and feet.\n      - Power ratios for all joint pairs.\n      - Side-Specific Range-of-Motion (ROM) metrics (ROM, deviation, and binary extreme flag).\n      - Removal of the wrist_angle_release column if present.\n    \n    Parameters:\n      - data (pd.DataFrame): Input DataFrame.\n      - debug (bool): If True, prints detailed debug outputs.\n    \n    Returns:\n      - data (pd.DataFrame): Updated DataFrame with new features.\n    \"\"\"\n    step = \"prepare_joint_features\"\n    new_cols = []\n    connections = [\n        (\"R_EYE\", \"L_EYE\"), (\"R_EYE\", \"NOSE\"), (\"L_EYE\", \"NOSE\"),\n        (\"R_EYE\", \"R_EAR\"), (\"L_EYE\", \"L_EAR\"), (\"R_SHOULDER\", \"L_SHOULDER\"),\n        (\"R_SHOULDER\", \"R_ELBOW\"), (\"L_SHOULDER\", \"L_ELBOW\"), (\"R_ELBOW\", \"R_WRIST\"),\n        (\"L_ELBOW\", \"L_WRIST\"), (\"R_SHOULDER\", \"R_HIP\"), (\"L_SHOULDER\", \"L_HIP\"),\n        (\"R_HIP\", \"L_HIP\"), (\"R_HIP\", \"R_KNEE\"), (\"L_HIP\", \"L_KNEE\"),\n        (\"R_KNEE\", \"R_ANKLE\"), (\"L_KNEE\", \"L_ANKLE\"), (\"R_WRIST\", \"R_1STFINGER\"),\n        (\"R_WRIST\", \"R_5THFINGER\"), (\"L_WRIST\", \"L_1STFINGER\"), (\"L_WRIST\", \"L_5THFINGER\"),\n        (\"R_ANKLE\", \"R_1STTOE\"), (\"R_ANKLE\", \"R_5THTOE\"), (\"L_ANKLE\", \"L_1STTOE\"),\n        (\"L_ANKLE\", \"L_5THTOE\"), (\"R_ANKLE\", \"R_CALC\"), (\"L_ANKLE\", \"L_CALC\"),\n        (\"R_1STTOE\", \"R_5THTOE\"), (\"L_1STTOE\", \"L_5THTOE\"), (\"R_1STTOE\", \"R_CALC\"),\n        (\"L_1STTOE\", \"L_CALC\"), (\"R_5THTOE\", \"R_CALC\"), (\"L_5THTOE\", \"L_CALC\"),\n        (\"R_1STFINGER\", \"R_5THFINGER\"), (\"L_1STFINGER\", \"L_5THFINGER\")\n    ]\n    # Compute joint angles first.\n    data = calculate_joint_angles(data, connections, debug=debug)\n    \n    # Rename participant anthropometrics if available.\n    if 'height_in_meters' in data.columns and 'weight__in_kg' in data.columns:\n        data['player_height_in_meters'] = data['height_in_meters']\n        data['player_weight__in_kg'] = data['weight__in_kg']\n        data.drop(['height_in_meters', 'weight__in_kg'], axis=1, inplace=True, errors='ignore')\n        new_cols.extend(['player_height_in_meters', 'player_weight__in_kg'])\n        logging.info(\"Renamed participant anthropometrics.\")\n    else:\n        logging.warning(\"Participant anthropometric columns not found during renaming.\")\n\n    # Identify joint energy and power columns.\n    joint_energy_columns = [col for col in data.columns if '_energy' in col and not ('by_trial' in col or 'overall' in col)]\n    print(\"Joint energy columns: \", joint_energy_columns)\n    joint_power_columns = [col for col in data.columns if '_ongoing_power' in col]\n    print(\"Joint power columns: \", joint_power_columns)\n    print(\"All angle columns: \", [col for col in data.columns if 'angle' in col])\n    logging.info(f\"Identified {len(joint_energy_columns)} joint energy and {len(joint_power_columns)} joint power columns.\")\n    if not joint_energy_columns:\n        logging.error(\"No joint energy columns found. Check naming conventions.\")\n        sys.exit(1)\n    if not joint_power_columns:\n        logging.error(\"No joint power columns found. Check naming conventions.\")\n        sys.exit(1)\n    \n    # Create aggregated columns.\n    data['joint_energy'] = data[joint_energy_columns].sum(axis=1)\n    data['joint_power'] = data[joint_power_columns].sum(axis=1)\n    new_cols.extend(['joint_energy', 'joint_power'])\n    logging.info(\"Created aggregated 'joint_energy' and 'joint_power'.\")\n\n    # --- NEW FEATURE: Energy Acceleration ---\n    if 'continuous_frame_time' in data.columns:\n        time_diff = data['continuous_frame_time'].diff().replace(0, 1e-6)  # Avoid division by zero\n        data['energy_acceleration'] = data['joint_energy'].diff() / time_diff\n        data['energy_acceleration'] = data['energy_acceleration'].replace([np.inf, -np.inf], np.nan)\n        new_cols.append('energy_acceleration')\n        logging.info(\"Created 'energy_acceleration' as derivative of joint_energy over time.\")\n    else:\n        logging.error(\"Missing 'continuous_frame_time' for energy_acceleration calculation.\")\n        sys.exit(1)\n    \n    # --- NEW FEATURE: Ankle Power Ratio ---\n    # For power, look for the '_ongoing_power' suffix.\n    if 'L_ANKLE_ongoing_power' in data.columns and 'R_ANKLE_ongoing_power' in data.columns:\n        data['ankle_power_ratio'] = data['L_ANKLE_ongoing_power'] / (data['R_ANKLE_ongoing_power'] + 1e-6)\n        new_cols.append('ankle_power_ratio')\n        logging.info(\"Created 'ankle_power_ratio' feature comparing left to right ankle ongoing power.\")\n    else:\n        logging.warning(\"Ankle ongoing power columns not found; 'ankle_power_ratio' not created.\")\n\n    # --- NEW FEATURES: Additional Asymmetry Metrics ---\n    additional_asymmetry_joints = ['hip', 'ankle', 'wrist', 'elbow', 'knee', '1stfinger', '5thfinger'] #, '1sttoe', '5thtoe' &lt; ADD WHEN WE ADD TO DATA LOAD AND PREPARE IN MODULE %%writefile ml/feature_engineering/energy_exhaustion_metrics.py\n    for joint in additional_asymmetry_joints:\n        # Use joint.upper() for energy columns.\n        left_col = f\"L_{joint.upper()}_energy\"\n        right_col = f\"R_{joint.upper()}_energy\"\n        if left_col in data.columns and right_col in data.columns:\n            col_name = f\"{joint}_asymmetry\"\n            data[col_name] = np.abs(data[left_col] - data[right_col])\n            new_cols.append(col_name)\n            logging.info(f\"Created asymmetry feature: {col_name}\")\n        else:\n            logging.warning(f\"Columns {left_col} and/or {right_col} not found; skipping {joint}_asymmetry.\")\n\n    # --- NEW FEATURES: Power Ratios for All Joints ---\n    joints_for_power_ratio = additional_asymmetry_joints.copy()\n    if 'knee' not in joints_for_power_ratio:\n        joints_for_power_ratio.append('knee')\n    for joint in joints_for_power_ratio:\n        if joint == 'foot':\n            left_col = 'left_foot_power'\n            right_col = 'right_foot_power'\n        else:\n            # Construct expected column names with the suffix '_ongoing_power'\n            left_col = f\"L_{joint.upper()}_ongoing_power\"\n            right_col = f\"R_{joint.upper()}_ongoing_power\"\n        # Debug: log the expected column names.\n        logging.debug(f\"Expecting power columns: {left_col} and {right_col}\")\n        if left_col in data.columns and right_col in data.columns:\n            ratio_col = f\"{joint}_power_ratio\"\n            data[ratio_col] = data[left_col] / (data[right_col] + 1e-6)\n            new_cols.append(ratio_col)\n            logging.info(f\"Created power ratio feature: {ratio_col} using columns {left_col} and {right_col}\")\n        else:\n            logging.warning(f\"Columns {left_col} and/or {right_col} not found; skipping {joint}_power_ratio.\")\n\n\n\n    # --- NEW FEATURES: Side-Specific Range-of-Motion (ROM) Metrics ---\n    # For angles, the dataset uses joint, e.g., \"L_shoulder_angle\".\n    rom_joints = {\n        'KNEE': {'min': 120, 'max': 135},\n        'SHOULDER': {'min': 0,  'max': 150},\n        'HIP': {'min': 0,  'max': 120},\n        'ANKLE': {'min': 0,  'max': 20},\n        'WRIST': {'min': 0,  'max': 80}\n    }\n    for joint, thresholds in rom_joints.items():\n        for side in ['L', 'R']:\n            angle_col = f\"{side}_{joint}_angle\"\n            if angle_col in data.columns:\n                rom_col = f\"{side}_{joint}_ROM\"\n                data[rom_col] = data.groupby('trial_id')[angle_col].transform(lambda x: x.max() - x.min())\n                new_cols.append(rom_col)\n                logging.info(f\"Computed ROM for {side} {joint} as {rom_col}\")\n\n                deviation_col = f\"{side}_{joint}_ROM_deviation\"\n                normal_min = thresholds['min']\n                normal_max = thresholds['max']\n                data[deviation_col] = np.maximum(0, normal_min - data[rom_col]) + np.maximum(0, data[rom_col] - normal_max)\n                new_cols.append(deviation_col)\n                logging.info(f\"Computed ROM deviation for {side} {joint} as {deviation_col}\")\n\n                extreme_col = f\"{side}_{joint}_ROM_extreme\"\n                data[extreme_col] = ((data[rom_col] &lt; normal_min) | (data[rom_col] &gt; normal_max)).astype(int)\n                new_cols.append(extreme_col)\n                logging.info(f\"Created binary flag for {side} {joint} ROM extremes: {extreme_col}\")\n            else:\n                logging.info(f\"Angle column '{angle_col}' not found; skipping ROM metrics for {side} {joint}.\")\n\n    # --- Removal of Non-Contributing Features ---\n    if 'wrist_angle_release' in data.columns:\n        data.drop(columns=['wrist_angle_release'], inplace=True)\n        logging.info(\"Dropped 'wrist_angle_release' column as it is not helpful for the model.\")\n    \n    # --- Sort Data ---\n    if 'continuous_frame_time' in data.columns and 'participant_id' in data.columns:\n        data.sort_values(by=['participant_id', 'continuous_frame_time'], inplace=True)\n        data.reset_index(drop=True, inplace=True)\n        logging.info(\"Sorted data by 'participant_id' and 'continuous_frame_time'.\")\n    else:\n        logging.error(\"Missing required columns for sorting ('participant_id', 'continuous_frame_time').\")\n        sys.exit(1)\n\n    # --- Create Exhaustion Rate ---\n    if 'by_trial_exhaustion_score' in data.columns and 'by_trial_time' in data.columns:\n        data['exhaustion_rate'] = data['by_trial_exhaustion_score'].diff() / data['by_trial_time'].diff()\n        print(\"print all the columns with by_trial_exhaustion_score: \", [col for col in data.columns if 'by_trial_exhaustion_score' in col])\n        new_cols.append('exhaustion_rate')\n        logging.info(\"Created 'exhaustion_rate' feature.\")\n    else:\n        logging.error(\"Missing columns for 'exhaustion_rate' calculation.\")\n        sys.exit(1)\n    \n    # --- Create Simulated Heart Rate ---\n    if 'by_trial_exhaustion_score' in data.columns and 'joint_energy' in data.columns:\n        data['simulated_HR'] = 60 + (data['by_trial_exhaustion_score'] * 1.5) + (data['joint_energy'] * 0.3)\n        new_cols.append('simulated_HR')\n        logging.info(\"Created 'simulated_HR' feature.\")\n    else:\n        logging.error(\"Missing columns for 'simulated_HR' calculation.\")\n        sys.exit(1)\n    \n    _print_debug_info(step, data, new_columns=new_cols, debug=debug)\n    return data\n\n\n\ndef feature_engineering(data, window_size=5, debug=False):\n    \"\"\"Optimized feature engineering with vectorized operations.\"\"\"\n    step = \"feature_engineering\"\n    new_cols = []\n    rolling_window = 20\n    required_columns = {\n        'base': ['by_trial_exhaustion_score', 'joint_power', \n                'simulated_HR', 'continuous_frame_time'],\n        'joints': ['by_trial_time']\n    }\n    \n    # Validate columns upfront\n    missing = [col for col in required_columns['base'] if col not in data.columns]\n    if missing:\n        logging.error(f\"Missing required columns: {missing}\")\n        sys.exit(1)\n\n    # Vectorized temporal features\n    data['time_since_start'] = data['continuous_frame_time'] - data['continuous_frame_time'].min()\n    new_cols.append('time_since_start')\n    \n    # For ball-related columns, fill with 0 when not in play\n    ball_cols = ['ball_speed', 'ball_velocity_x', 'ball_velocity_y', 'ball_velocity_z']\n    data[ball_cols] = data[ball_cols].fillna(0)\n\n    # For motion columns (dx, dy, dz), forward-fill missing values\n    motion_cols = ['dx', 'dy', 'dz']\n    data[motion_cols] = data[motion_cols].fillna(method='ffill').fillna(0)\n\n    # For rolling features, use min_periods=1 to avoid NaNs in early rows\n    roll_config = {\n        'power_avg_5': ('joint_power', 'mean'),\n        'rolling_power_std': ('joint_power', 'std'),\n        'rolling_hr_mean': ('simulated_HR', 'mean')\n    }\n    for new_col, (base_col, func) in roll_config.items():\n        data[new_col] = getattr(data[base_col].rolling(window_size, min_periods=1), func)()  # &lt;-- Add min_periods\n\n    # Optimized expanding quantile calculation\n    def safe_expanding_quantile(s):\n        return s.expanding().quantile(0.75).shift().fillna(0)\n    # --- OPTIONAL NEW FEATURE: Rolling Energy Standard Deviation ---\n    if 'joint_energy' in data.columns:\n        data['rolling_energy_std'] = data['joint_energy'].rolling(window=window_size, min_periods=1).std(ddof=0)\n        logging.info(f\"Created 'rolling_energy_std' with sample: {data['rolling_energy_std'].head(10).tolist()}\")\n        logging.info(f\"Created 'rolling_energy_std' with window {window_size}.\")\n    else:\n        logging.warning(\"Column 'joint_energy' missing for 'rolling_energy_std'.\")\n    new_cols.append('rolling_energy_std')\n    \n    # Vectorized exhaustion features\n    data['exhaustion_lag1'] = data['by_trial_exhaustion_score'].shift(1)\n    data['ema_exhaustion'] = data['by_trial_exhaustion_score'].ewm(span=10, adjust=False).mean()\n    data['rolling_exhaustion'] = data['by_trial_exhaustion_score'].rolling(rolling_window, min_periods=1).sum()\n    \n    # Vectorized injury risk calculation\n    data['injury_risk'] = (data['rolling_exhaustion'] &gt; safe_expanding_quantile(data['rolling_exhaustion'])).astype(int)\n    new_cols += ['exhaustion_lag1', 'ema_exhaustion', 'rolling_exhaustion', 'injury_risk']\n\n    # Joint features using vectorized operations\n    joints = ['ANKLE', 'WRIST', 'ELBOW', 'KNEE', 'HIP']\n    sides = ['L', 'R']\n    \n    # Precompute time diffs once for all joints\n    dt = data['by_trial_time'].diff().replace(0, np.nan)\n    \n    for joint in joints:\n        for side in sides:\n            joint_name = f\"{side}_{joint}\"\n            score_col = f'{joint_name}_energy_by_trial_exhaustion_score'\n            \n            if score_col not in data.columns:\n                continue\n                \n            # Vectorized joint features\n            data[f'{joint_name}_exhaustion_rate'] = data[score_col].diff() / dt\n            data[f'{joint_name}_rolling_exhaustion'] = data[score_col].rolling(rolling_window, min_periods=1).sum()\n            \n            # Vectorized quantile comparison\n            rolling_series = data[f'{joint_name}_rolling_exhaustion']\n            data[f'{joint_name}_injury_risk'] = (rolling_series &gt; safe_expanding_quantile(rolling_series)).astype(int)\n            \n            new_cols.extend([\n                f'{joint_name}_exhaustion_rate',\n                f'{joint_name}_rolling_exhaustion',\n                f'{joint_name}_injury_risk'\n            ])\n\n    # Selective NA dropping for lag features only\n    data.dropna(subset=['exhaustion_lag1'], inplace=True)\n    \n    if debug:\n        _print_debug_info(step, data, new_columns=new_cols, debug=debug)\n    \n    return data\n\ndef make_exhaustion_monotonic_and_time_to_zero(data):\n    # (A) Cumulative exhaustion example\n    data['cumulative_exhaustion'] = (\n        data.groupby('participant_id')['by_trial_exhaustion_score']\n            .cumsum()\n    )\n    \n    # (B) Invert the raw exhaustion so that 1=Fresh, 0=Exhausted\n    data['remaining_capacity'] = 1.0 - data['by_trial_exhaustion_score']\n    \n    # (C) Compute \"time to 0 exhaustion\"\n    data = data.sort_values(['participant_id', 'continuous_frame_time']).reset_index(drop=True)\n    times = data['continuous_frame_time'].values\n    exhaustion = data['by_trial_exhaustion_score'].values\n    time_to_zero = np.full(len(data), np.nan)\n    \n    for i in range(len(data)):\n        if exhaustion[i] &lt;= 0.0:\n            time_to_zero[i] = 0.0\n        else:\n            future_idxs = np.where(exhaustion[i:] &lt;= 0.0)[0]\n            if len(future_idxs) &gt; 0:\n                j = i + future_idxs[0]\n                time_to_zero[i] = times[j] - times[i]\n            else:\n                # If it never reaches 0 in the future, leave it as NaN or set a default\n                time_to_zero[i] = np.nan\n\n    data['time_to_zero_exhaustion'] = time_to_zero\n    \n    return data\n\n\n\ndef add_simulated_player_metrics(df, window=5, debug=False):\n    \"\"\"\n    Adds simulated player metrics to mimic heart rate and fatigue.\n    \n    New Metrics:\n      - simulated_HR_fake: Alternative simulated heart rate.\n      - fatigue_index_fake: Combined fatigue index.\n      - fatigue_rate_fake: Frame-by-frame rate of change of fatigue_index_fake.\n      - HR_variability_fake: Rolling standard deviation of simulated_HR_fake.\n    \n    Parameters:\n      - df (pd.DataFrame): DataFrame with required columns (e.g., by_trial_exhaustion_score, joint_energy, overall_exhaustion_score, dt).\n      - window (int): Rolling window size for HR variability.\n      - debug (bool): If True, prints detailed debug outputs.\n    \n    Returns:\n      - df (pd.DataFrame): DataFrame with new simulated metrics.\n    \"\"\"\n    step = \"add_simulated_player_metrics\"\n    new_cols = []\n    \n    # Use maximum joint_energy for scaling\n    max_joint_energy = df['joint_energy'].max() if 'joint_energy' in df.columns else 1\n    df['simulated_HR_fake'] = 60 + (df['by_trial_exhaustion_score'] * 2.0) + ((df['joint_energy'] / max_joint_energy) * 20)\n    new_cols.append('simulated_HR_fake')\n    \n    df['fatigue_index_fake'] = df['overall_exhaustion_score'] + ((df['simulated_HR_fake'] - 60) / 100)\n    new_cols.append('fatigue_index_fake')\n    \n    df['fatigue_rate_fake'] = df['fatigue_index_fake'].diff() / df['dt']\n    df['fatigue_rate_fake'] = df['fatigue_rate_fake'].fillna(0)\n    new_cols.append('fatigue_rate_fake')\n    \n    df['HR_variability_fake'] = df['simulated_HR_fake'].rolling(window=window, min_periods=1).std()\n    new_cols.append('HR_variability_fake')\n    \n    _print_debug_info(step, df, new_columns=new_cols, debug=debug)\n    return df\n\n\ndef joint_specific_analysis(data, joint_energy_columns, debug=False):\n    \"\"\"\n    Performs joint-specific analysis including:\n      - Energy distribution per joint.\n      - Injury risk analysis for each joint.\n      - Cumulative energy accumulation patterns.\n    \n    Parameters:\n      - data (pd.DataFrame): Input DataFrame.\n      - joint_energy_columns (list): List of joint energy column names.\n      - debug (bool): If True, prints debug information.\n    \"\"\"\n    step = \"joint_specific_analysis\"\n    # Energy distribution across joints\n    joint_energy_melted = data[joint_energy_columns].melt(var_name='Joint', value_name='Energy')\n    plt.figure(figsize=(15, 8))\n    order = joint_energy_melted.groupby('Joint')['Energy'].median().sort_values().index\n    sns.boxplot(x='Joint', y='Energy', data=joint_energy_melted, order=order)\n    plt.title('Joint Energy Distributions (Sorted by Median Energy)')\n    plt.xticks(rotation=45)\n    plt.show()\n    if debug:\n        logging.info(\"Displayed boxplot for joint energy distributions.\")\n    else:\n        logging.info(\"Energy distribution plot displayed.\")\n    \n    # Injury risk analysis: only run if 'injury_risk' exists.\n    if 'injury_risk' not in data.columns:\n        logging.warning(\"Column 'injury_risk' not found; skipping injury risk analysis in joint_specific_analysis.\")\n    else:\n        num_plots = len(joint_energy_columns)\n        ncols = 4\n        nrows = int(np.ceil(num_plots / ncols))\n        plt.figure(figsize=(15, 10))\n        for i, joint in enumerate(joint_energy_columns, 1):\n            plt.subplot(nrows, ncols, i)\n            sns.boxplot(x='injury_risk', y=joint, data=data)\n            plt.title(f'{joint.split(\"_\")[0].title()} Energy')\n            plt.tight_layout()\n        plt.suptitle('Joint Energy Distributions by Injury Risk', y=1.02)\n        plt.show()\n        if debug:\n            logging.info(\"Displayed injury risk analysis plots for joint energy.\")\n        else:\n            logging.info(\"Injury risk analysis plots displayed.\")\n    \n    # Cumulative energy accumulation patterns\n    joint_cumulative = data.groupby('participant_id')[joint_energy_columns].cumsum()\n    joint_cumulative['time'] = data['continuous_frame_time']\n    joint_cumulative_melted = joint_cumulative.melt(id_vars='time', var_name='Joint', value_name='Cumulative Energy')\n    plt.figure(figsize=(15, 8))\n    sns.lineplot(x='time', y='Cumulative Energy', hue='Joint', \n                 data=joint_cumulative_melted, estimator='median', errorbar=None)\n    plt.title('Cumulative Joint Energy Over Time (Median Across Participants)')\n    plt.xlabel('Time (s)')\n    plt.ylabel('Cumulative Energy')\n    plt.show()\n    if debug:\n        logging.info(\"Displayed cumulative joint energy plot.\")\n    else:\n        logging.info(\"Cumulative energy plot displayed.\")\n    \n    _print_debug_info(step, data, debug=debug)\n\n\ndef movement_pattern_analysis(data, debug=False):\n    \"\"\"\n    Performs movement pattern analysis:\n      - Angular velocity histograms with KDE.\n      - Asymmetry analysis via pairplot.\n    \n    Parameters:\n      - data (pd.DataFrame): Input DataFrame.\n      - debug (bool): If True, prints debug information.\n    \"\"\"\n    step = \"movement_pattern_analysis\"\n    # Angular velocity analysis\n    angular_columns = [col for col in data.columns if '_angular_velocity' in col]\n    if angular_columns:\n        fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 15))\n        axes = axes.flatten()\n        for ax, col in zip(axes, angular_columns):\n            sns.histplot(data[col], ax=ax, kde=True)\n            ax.set_title(f'{col.split(\"_\")[0].title()} Angular Velocity')\n        for j in range(len(angular_columns), len(axes)):\n            fig.delaxes(axes[j])\n        plt.tight_layout()\n        plt.show()\n        logging.info(\"Displayed angular velocity histograms.\")\n    else:\n        logging.info(\"No angular velocity columns found.\")\n    \n    # Asymmetry analysis\n    asymmetry_metrics = [col for col in data.columns if 'asymmetry' in col]\n    if 'injury_risk' in data.columns and asymmetry_metrics:\n        sns.pairplot(data[asymmetry_metrics + ['injury_risk']], hue='injury_risk', corner=True)\n        plt.suptitle('Joint Asymmetry Relationships with Injury Risk', y=1.02)\n        plt.show()\n        logging.info(\"Displayed asymmetry pairplot.\")\n    else:\n        logging.info(\"Required columns for asymmetry analysis not found.\")\n    \n    _print_debug_info(step, data, debug=debug)\n\n\ndef temporal_analysis_enhancements(data, debug=False):\n    \"\"\"\n    Performs temporal analysis enhancements:\n      - Computes lagged correlations between joint energy and exhaustion score.\n      - Plots autocorrelation of joint energy.\n    \n    Parameters:\n      - data (pd.DataFrame): Input DataFrame.\n      - debug (bool): If True, prints debug information.\n    \"\"\"\n    step = \"temporal_analysis_enhancements\"\n    max_lag = 10\n    lagged_corrs = []\n    for lag in range(1, max_lag + 1):\n        corr_val = data['joint_energy'].corr(data['by_trial_exhaustion_score'].shift(lag))\n        lagged_corrs.append(corr_val)\n    plt.figure(figsize=(10, 6))\n    plt.plot(range(1, max_lag + 1), lagged_corrs, marker='o')\n    plt.title('Lagged Correlation Between Joint Energy and Exhaustion Score')\n    plt.xlabel('Time Lag (periods)')\n    plt.ylabel('Correlation Coefficient')\n    plt.grid(True)\n    plt.show()\n    \n    from statsmodels.graphics.tsaplots import plot_acf\n    plt.figure(figsize=(12, 6))\n    plot_acf(data['joint_energy'].dropna(), lags=50, alpha=0.05)\n    plt.title('Joint Energy Autocorrelation')\n    plt.xlabel('Lags')\n    plt.ylabel('Autocorrelation')\n    plt.show()\n    \n    _print_debug_info(step, data, debug=debug)\n\n\ndef multivariate_analysis(data, joint_energy_columns, debug=False):\n    \"\"\"\n    Performs multivariate analysis separately for left- and right-sided joints:\n      - 3D visualization of joint energy interactions for each side.\n      - KMeans clustering on selected features for each side.\n    \n    Parameters:\n      - data (pd.DataFrame): Input DataFrame.\n      - joint_energy_columns (list): List of all joint energy columns.\n      - debug (bool): If True, prints debug information.\n    \"\"\"\n    step = \"multivariate_analysis\"\n\n    # --- 3D Visualization: Left Side ---\n    required_left = ['L_ELBOW_energy', 'L_KNEE_energy', 'L_ANKLE_energy', 'injury_risk']\n    if all(col in data.columns for col in required_left):\n        from mpl_toolkits.mplot3d import Axes3D\n        fig = plt.figure(figsize=(12, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        scatter = ax.scatter(data['L_ELBOW_energy'], \n                             data['L_KNEE_energy'], \n                             data['L_ANKLE_energy'], \n                             c=data['injury_risk'],\n                             cmap='viridis',\n                             alpha=0.6)\n        ax.set_xlabel('L Elbow Energy')\n        ax.set_ylabel('L Knee Energy')\n        ax.set_zlabel('L Ankle Energy')\n        plt.title('3D Joint Energy Space (Left Side) with Injury Risk Coloring')\n        plt.colorbar(scatter, label='Injury Risk')\n        plt.show()\n    else:\n        logging.info(\"Required left-side columns for 3D analysis not found; skipping left side 3D plot.\")\n\n    # --- 3D Visualization: Right Side ---\n    required_right = ['R_ELBOW_energy', 'R_KNEE_energy', 'R_ANKLE_energy', 'injury_risk']\n    if all(col in data.columns for col in required_right):\n        from mpl_toolkits.mplot3d import Axes3D\n        fig = plt.figure(figsize=(12, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        scatter = ax.scatter(data['R_ELBOW_energy'], \n                             data['R_KNEE_energy'], \n                             data['R_ANKLE_energy'], \n                             c=data['injury_risk'],\n                             cmap='viridis',\n                             alpha=0.6)\n        ax.set_xlabel('R Elbow Energy')\n        ax.set_ylabel('R Knee Energy')\n        ax.set_zlabel('R Ankle Energy')\n        plt.title('3D Joint Energy Space (Right Side) with Injury Risk Coloring')\n        plt.colorbar(scatter, label='Injury Risk')\n        plt.show()\n    else:\n        logging.info(\"Required right-side columns for 3D analysis not found; skipping right side 3D plot.\")\n\n    # --- Clustering Analysis: Left Side ---\n    left_features = ['L_ELBOW_energy', 'L_KNEE_energy', 'L_ANKLE_energy']\n    # Optionally include asymmetry features if desired (they compare L vs R)\n    left_features = [feat for feat in left_features if feat in data.columns]\n    if left_features:\n        from sklearn.cluster import KMeans\n        from sklearn.preprocessing import StandardScaler\n        X_left = data[left_features].dropna()\n        X_left_scaled = StandardScaler().fit_transform(X_left)\n        kmeans_left = KMeans(n_clusters=3, random_state=42).fit(X_left_scaled)\n        data.loc[X_left.index, 'left_movement_cluster'] = kmeans_left.labels_\n        plt.figure(figsize=(10, 6))\n        sns.scatterplot(x='L_ELBOW_energy', y='L_KNEE_energy', hue='left_movement_cluster', \n                        data=data, palette='viridis', alpha=0.6)\n        plt.title('Left Side Movement Clusters in Elbow-Knee Energy Space')\n        plt.xlabel('L Elbow Energy')\n        plt.ylabel('L Knee Energy')\n        plt.show()\n    else:\n        logging.info(\"Not enough left-side features available for clustering analysis.\")\n\n    # --- Clustering Analysis: Right Side ---\n    right_features = ['R_ELBOW_energy', 'R_KNEE_energy', 'R_ANKLE_energy']\n    right_features = [feat for feat in right_features if feat in data.columns]\n    if right_features:\n        from sklearn.cluster import KMeans\n        from sklearn.preprocessing import StandardScaler\n        X_right = data[right_features].dropna()\n        X_right_scaled = StandardScaler().fit_transform(X_right)\n        kmeans_right = KMeans(n_clusters=3, random_state=42).fit(X_right_scaled)\n        data.loc[X_right.index, 'right_movement_cluster'] = kmeans_right.labels_\n        plt.figure(figsize=(10, 6))\n        sns.scatterplot(x='R_ELBOW_energy', y='R_KNEE_energy', hue='right_movement_cluster', \n                        data=data, palette='viridis', alpha=0.6)\n        plt.title('Right Side Movement Clusters in Elbow-Knee Energy Space')\n        plt.xlabel('R Elbow Energy')\n        plt.ylabel('R Knee Energy')\n        plt.show()\n    else:\n        logging.info(\"Not enough right-side features available for clustering analysis.\")\n\n    _print_debug_info(step, data, debug=debug)\n\n\n\ndef statistical_testing(data, joint_energy_columns, debug=False):\n    \"\"\"\n    Performs Mann-Whitney U tests on each joint energy metric between low and high injury risk groups.\n    \n    Parameters:\n      - data (pd.DataFrame): Input DataFrame.\n      - joint_energy_columns (list): List of joint energy column names.\n      - debug (bool): If True, prints detailed test outputs.\n    \n    Returns:\n      - results_df (pd.DataFrame): Summary table of test statistics.\n    \"\"\"\n    from scipy.stats import mannwhitneyu\n    step = \"statistical_testing\"\n    results = []\n    for joint in joint_energy_columns:\n        if joint in data.columns and 'injury_risk' in data.columns:\n            low_risk = data[data['injury_risk'] == 0][joint]\n            high_risk = data[data['injury_risk'] == 1][joint]\n            stat, p = mannwhitneyu(low_risk, high_risk, alternative='two-sided')\n            effect_size = stat / (len(low_risk) * len(high_risk)) if (len(low_risk) * len(high_risk)) &gt; 0 else np.nan\n            results.append({\n                'Joint': joint.split('_')[0],\n                'U Statistic': stat,\n                'p-value': p,\n                'Effect Size': effect_size\n            })\n    results_df = pd.DataFrame(results).sort_values('p-value')\n    logging.info(\"Mann-Whitney U Test Results:\")\n    logging.info(results_df)\n    _print_debug_info(step, data, debug=debug)\n    return results_df\n\n\n\n\n\n###############################################################################\n# MAIN SCRIPT\n###############################################################################\n\nif __name__ == \"__main__\":\n    # Run the main pipeline with debug output enabled.\n\n    debug=False\n \n    # \"\"\"\n    # Main processing pipeline:\n    #   1. Loads and merges data.\n    #   2. Prepares joint features.\n    #   3. Performs feature engineering.\n    #   4. Adds simulated player metrics.\n    #   5. Executes various analyses (joint-specific, movement pattern, temporal, multivariate, statistical, and fatigue-injury interaction).\n    \n    # Parameters:\n    #   - debug (bool): Controls verbose debug output.\n    #   - csv_path (str): Path to input CSV file.\n    #   - json_path (str): Path to participant info JSON.\n    # \"\"\"\n    csv_path=\"../../data/processed/final_granular_dataset.csv\"\n    json_path=\"../../data/basketball/freethrow/participant_information.json\"\n    data = load_data(csv_path, json_path, debug=debug)\n    data = prepare_joint_features(data, debug=debug)\n    data = feature_engineering(data, debug=debug)\n    print(data.columns.tolist())\n    # data = add_simulated_player_metrics(data, window=5, debug=debug)\n    \n\n    # For demonstration, define features/targets (you can adjust these as needed)\n    features_exhaustion = [\n        'joint_power', \n        'joint_energy', \n        'elbow_asymmetry',  \n        'wrist_angle', \n        'exhaustion_lag1', \n        'power_avg_5',\n        'simulated_HR',\n        'player_height_in_meters',\n        'player_weight__in_kg'\n    ]\n    target_exhaustion = 'by_trial_exhaustion_score'\n    features_injury = [\n        'joint_power', \n        'joint_energy', \n        'elbow_asymmetry',  \n        'knee_asymmetry', \n        'wrist_angle', \n        'exhaustion_lag1', \n        'power_avg_5',\n        'simulated_HR',\n        'player_height_in_meters',\n        'player_weight__in_kg'\n    ]\n    target_injury = 'injury_risk'\n    \n    # Identify joint energy columns (excluding the aggregated 'joint_energy')\n    joint_energy_columns = [\n        col for col in data.columns\n        if '_energy' in col and not ('by_trial' in col or 'overall' in col) and col != 'joint_energy'\n    ]\n    logging.info(f\"Joint Energy Columns after excluding 'joint_energy' ({len(joint_energy_columns)}): {joint_energy_columns}\")\n    \n    # Execute analysis functions\n    joint_specific_analysis(data, joint_energy_columns, debug=debug)\n    movement_pattern_analysis(data, debug=debug)\n    temporal_analysis_enhancements(data, debug=debug)\n    multivariate_analysis(data, joint_energy_columns, debug=debug)\n    statistical_testing(data, joint_energy_columns, debug=debug)\n     \n    logging.info(\"Processing pipeline completed successfully.\")\n\nINFO: Loaded data from ../../data/processed/final_granular_dataset.csv with shape (16047, 214)\nINFO: Added 'participant_id' column with value 'P0001'\nINFO: Loaded participant information from ../../data/basketball/freethrow/participant_information.json\nINFO: Merged participant data. New shape: (16047, 217)\nINFO: Step [load_data] completed.\nINFO: Step [calculate_joint_angles] completed.\nINFO: Renamed participant anthropometrics.\nINFO: Identified 15 joint energy and 14 joint power columns.\nINFO: Created aggregated 'joint_energy' and 'joint_power'.\nINFO: Created 'energy_acceleration' as derivative of joint_energy over time.\nINFO: Created 'ankle_power_ratio' feature comparing left to right ankle ongoing power.\nINFO: Created asymmetry feature: hip_asymmetry\nINFO: Created asymmetry feature: ankle_asymmetry\nINFO: Created asymmetry feature: wrist_asymmetry\nINFO: Created asymmetry feature: elbow_asymmetry\nINFO: Created asymmetry feature: knee_asymmetry\nINFO: Created asymmetry feature: 1stfinger_asymmetry\nINFO: Created asymmetry feature: 5thfinger_asymmetry\nINFO: Created power ratio feature: hip_power_ratio using columns L_HIP_ongoing_power and R_HIP_ongoing_power\nINFO: Created power ratio feature: ankle_power_ratio using columns L_ANKLE_ongoing_power and R_ANKLE_ongoing_power\nINFO: Created power ratio feature: wrist_power_ratio using columns L_WRIST_ongoing_power and R_WRIST_ongoing_power\nINFO: Created power ratio feature: elbow_power_ratio using columns L_ELBOW_ongoing_power and R_ELBOW_ongoing_power\nINFO: Created power ratio feature: knee_power_ratio using columns L_KNEE_ongoing_power and R_KNEE_ongoing_power\nINFO: Created power ratio feature: 1stfinger_power_ratio using columns L_1STFINGER_ongoing_power and R_1STFINGER_ongoing_power\nINFO: Created power ratio feature: 5thfinger_power_ratio using columns L_5THFINGER_ongoing_power and R_5THFINGER_ongoing_power\nINFO: Computed ROM for L KNEE as L_KNEE_ROM\nINFO: Computed ROM deviation for L KNEE as L_KNEE_ROM_deviation\nINFO: Created binary flag for L KNEE ROM extremes: L_KNEE_ROM_extreme\nINFO: Computed ROM for R KNEE as R_KNEE_ROM\nINFO: Computed ROM deviation for R KNEE as R_KNEE_ROM_deviation\nINFO: Created binary flag for R KNEE ROM extremes: R_KNEE_ROM_extreme\nINFO: Computed ROM for L SHOULDER as L_SHOULDER_ROM\nINFO: Computed ROM deviation for L SHOULDER as L_SHOULDER_ROM_deviation\nINFO: Created binary flag for L SHOULDER ROM extremes: L_SHOULDER_ROM_extreme\nINFO: Computed ROM for R SHOULDER as R_SHOULDER_ROM\nINFO: Computed ROM deviation for R SHOULDER as R_SHOULDER_ROM_deviation\nINFO: Created binary flag for R SHOULDER ROM extremes: R_SHOULDER_ROM_extreme\nINFO: Computed ROM for L HIP as L_HIP_ROM\nINFO: Computed ROM deviation for L HIP as L_HIP_ROM_deviation\nINFO: Created binary flag for L HIP ROM extremes: L_HIP_ROM_extreme\nINFO: Computed ROM for R HIP as R_HIP_ROM\nINFO: Computed ROM deviation for R HIP as R_HIP_ROM_deviation\nINFO: Created binary flag for R HIP ROM extremes: R_HIP_ROM_extreme\nINFO: Computed ROM for L ANKLE as L_ANKLE_ROM\nINFO: Computed ROM deviation for L ANKLE as L_ANKLE_ROM_deviation\nINFO: Created binary flag for L ANKLE ROM extremes: L_ANKLE_ROM_extreme\nINFO: Computed ROM for R ANKLE as R_ANKLE_ROM\nINFO: Computed ROM deviation for R ANKLE as R_ANKLE_ROM_deviation\nINFO: Created binary flag for R ANKLE ROM extremes: R_ANKLE_ROM_extreme\nINFO: Angle column 'L_WRIST_angle' not found; skipping ROM metrics for L WRIST.\nINFO: Angle column 'R_WRIST_angle' not found; skipping ROM metrics for R WRIST.\nINFO: Sorted data by 'participant_id' and 'continuous_frame_time'.\nINFO: Created 'exhaustion_rate' feature.\nINFO: Created 'simulated_HR' feature.\nINFO: Step [prepare_joint_features] completed.\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:394: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data[motion_cols] = data[motion_cols].fillna(method='ffill').fillna(0)\nINFO: Created 'rolling_energy_std' with sample: [0.0, 0.6225242794725895, 0.592331668013902, 0.5469698974921113, 0.5031647476376774, 0.0346469804150002, 0.05501279562072104, 0.06384083445684284, 0.05698938811919827, 0.039917330417864196]\nINFO: Created 'rolling_energy_std' with window 5.\n\n\nJoint energy columns:  ['L_ANKLE_energy', 'R_ANKLE_energy', 'L_KNEE_energy', 'R_KNEE_energy', 'L_HIP_energy', 'R_HIP_energy', 'L_ELBOW_energy', 'R_ELBOW_energy', 'L_WRIST_energy', 'R_WRIST_energy', 'L_1STFINGER_energy', 'R_1STFINGER_energy', 'L_5THFINGER_energy', 'R_5THFINGER_energy', 'total_energy']\nJoint power columns:  ['L_ANKLE_ongoing_power', 'R_ANKLE_ongoing_power', 'L_KNEE_ongoing_power', 'R_KNEE_ongoing_power', 'L_HIP_ongoing_power', 'R_HIP_ongoing_power', 'L_ELBOW_ongoing_power', 'R_ELBOW_ongoing_power', 'L_WRIST_ongoing_power', 'R_WRIST_ongoing_power', 'L_1STFINGER_ongoing_power', 'L_5THFINGER_ongoing_power', 'R_1STFINGER_ongoing_power', 'R_5THFINGER_ongoing_power']\nAll angle columns:  ['entry_angle', 'elbow_angle', 'wrist_angle', 'knee_angle', 'initial_release_angle', 'calculated_release_angle', 'angle_difference', 'optimal_release_angle', 'L_SHOULDER_angle', 'R_SHOULDER_angle', 'L_HIP_angle', 'R_HIP_angle', 'L_KNEE_angle', 'R_KNEE_angle', 'L_ANKLE_angle', 'R_ANKLE_angle']\nprint all the columns with by_trial_exhaustion_score:  ['by_trial_exhaustion_score', 'L_ANKLE_energy_by_trial_exhaustion_score', 'R_ANKLE_energy_by_trial_exhaustion_score', 'L_KNEE_energy_by_trial_exhaustion_score', 'R_KNEE_energy_by_trial_exhaustion_score', 'L_HIP_energy_by_trial_exhaustion_score', 'R_HIP_energy_by_trial_exhaustion_score', 'L_ELBOW_energy_by_trial_exhaustion_score', 'R_ELBOW_energy_by_trial_exhaustion_score', 'L_WRIST_energy_by_trial_exhaustion_score', 'R_WRIST_energy_by_trial_exhaustion_score', 'L_1STFINGER_energy_by_trial_exhaustion_score', 'R_1STFINGER_energy_by_trial_exhaustion_score', 'L_5THFINGER_energy_by_trial_exhaustion_score', 'R_5THFINGER_energy_by_trial_exhaustion_score']\n\n\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_rolling_exhaustion'] = data[score_col].rolling(rolling_window, min_periods=1).sum()\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:447: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_injury_risk'] = (rolling_series &gt; safe_expanding_quantile(rolling_series)).astype(int)\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:442: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_exhaustion_rate'] = data[score_col].diff() / dt\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_rolling_exhaustion'] = data[score_col].rolling(rolling_window, min_periods=1).sum()\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:447: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_injury_risk'] = (rolling_series &gt; safe_expanding_quantile(rolling_series)).astype(int)\nINFO: Joint Energy Columns after excluding 'joint_energy' (16): ['L_ANKLE_energy', 'R_ANKLE_energy', 'L_KNEE_energy', 'R_KNEE_energy', 'L_HIP_energy', 'R_HIP_energy', 'L_ELBOW_energy', 'R_ELBOW_energy', 'L_WRIST_energy', 'R_WRIST_energy', 'L_1STFINGER_energy', 'R_1STFINGER_energy', 'L_5THFINGER_energy', 'R_5THFINGER_energy', 'total_energy', 'rolling_energy_std']\n\n\n['trial_id', 'result', 'landing_x', 'landing_y', 'entry_angle', 'frame_time', 'ball_x', 'ball_y', 'ball_z', 'R_EYE_x', 'R_EYE_y', 'R_EYE_z', 'L_EYE_x', 'L_EYE_y', 'L_EYE_z', 'NOSE_x', 'NOSE_y', 'NOSE_z', 'R_EAR_x', 'R_EAR_y', 'R_EAR_z', 'L_EAR_x', 'L_EAR_y', 'L_EAR_z', 'R_SHOULDER_x', 'R_SHOULDER_y', 'R_SHOULDER_z', 'L_SHOULDER_x', 'L_SHOULDER_y', 'L_SHOULDER_z', 'R_ELBOW_x', 'R_ELBOW_y', 'R_ELBOW_z', 'L_ELBOW_x', 'L_ELBOW_y', 'L_ELBOW_z', 'R_WRIST_x', 'R_WRIST_y', 'R_WRIST_z', 'L_WRIST_x', 'L_WRIST_y', 'L_WRIST_z', 'R_HIP_x', 'R_HIP_y', 'R_HIP_z', 'L_HIP_x', 'L_HIP_y', 'L_HIP_z', 'R_KNEE_x', 'R_KNEE_y', 'R_KNEE_z', 'L_KNEE_x', 'L_KNEE_y', 'L_KNEE_z', 'R_ANKLE_x', 'R_ANKLE_y', 'R_ANKLE_z', 'L_ANKLE_x', 'L_ANKLE_y', 'L_ANKLE_z', 'R_1STFINGER_x', 'R_1STFINGER_y', 'R_1STFINGER_z', 'R_5THFINGER_x', 'R_5THFINGER_y', 'R_5THFINGER_z', 'L_1STFINGER_x', 'L_1STFINGER_y', 'L_1STFINGER_z', 'L_5THFINGER_x', 'L_5THFINGER_y', 'L_5THFINGER_z', 'R_1STTOE_x', 'R_1STTOE_y', 'R_1STTOE_z', 'R_5THTOE_x', 'R_5THTOE_y', 'R_5THTOE_z', 'L_1STTOE_x', 'L_1STTOE_y', 'L_1STTOE_z', 'L_5THTOE_x', 'L_5THTOE_y', 'L_5THTOE_z', 'R_CALC_x', 'R_CALC_y', 'R_CALC_z', 'L_CALC_x', 'L_CALC_y', 'L_CALC_z', 'ball_speed', 'ball_velocity_x', 'ball_velocity_y', 'ball_velocity_z', 'overall_ball_velocity', 'ball_direction_x', 'ball_direction_y', 'ball_direction_z', 'computed_ball_velocity_x', 'computed_ball_velocity_y', 'computed_ball_velocity_z', 'dist_ball_R_1STFINGER', 'dist_ball_R_5THFINGER', 'dist_ball_L_1STFINGER', 'dist_ball_L_5THFINGER', 'ball_in_hands', 'shooting_motion', 'avg_shoulder_height', 'release_point_filter', 'dt', 'dx', 'dy', 'dz', 'L_ANKLE_ongoing_power', 'R_ANKLE_ongoing_power', 'L_KNEE_ongoing_power', 'R_KNEE_ongoing_power', 'L_HIP_ongoing_power', 'R_HIP_ongoing_power', 'L_ELBOW_ongoing_power', 'R_ELBOW_ongoing_power', 'L_WRIST_ongoing_power', 'R_WRIST_ongoing_power', 'L_1STFINGER_ongoing_power', 'L_5THFINGER_ongoing_power', 'R_1STFINGER_ongoing_power', 'R_5THFINGER_ongoing_power', 'elbow_angle', 'wrist_angle', 'knee_angle', 'player_height_in_meters', 'player_height_ft', 'initial_release_angle', 'calculated_release_angle', 'angle_difference', 'distance_to_basket', 'optimal_release_angle', 'by_trial_time', 'continuous_frame_time', 'L_ANKLE_energy', 'R_ANKLE_energy', 'L_KNEE_energy', 'R_KNEE_energy', 'L_HIP_energy', 'R_HIP_energy', 'L_ELBOW_energy', 'R_ELBOW_energy', 'L_WRIST_energy', 'R_WRIST_energy', 'L_1STFINGER_energy', 'R_1STFINGER_energy', 'L_5THFINGER_energy', 'R_5THFINGER_energy', 'total_energy', 'by_trial_energy', 'by_trial_exhaustion_score', 'overall_cumulative_energy', 'overall_exhaustion_score', 'L_ANKLE_energy_by_trial', 'L_ANKLE_energy_by_trial_exhaustion_score', 'L_ANKLE_energy_overall_cumulative', 'L_ANKLE_energy_overall_exhaustion_score', 'R_ANKLE_energy_by_trial', 'R_ANKLE_energy_by_trial_exhaustion_score', 'R_ANKLE_energy_overall_cumulative', 'R_ANKLE_energy_overall_exhaustion_score', 'L_KNEE_energy_by_trial', 'L_KNEE_energy_by_trial_exhaustion_score', 'L_KNEE_energy_overall_cumulative', 'L_KNEE_energy_overall_exhaustion_score', 'R_KNEE_energy_by_trial', 'R_KNEE_energy_by_trial_exhaustion_score', 'R_KNEE_energy_overall_cumulative', 'R_KNEE_energy_overall_exhaustion_score', 'L_HIP_energy_by_trial', 'L_HIP_energy_by_trial_exhaustion_score', 'L_HIP_energy_overall_cumulative', 'L_HIP_energy_overall_exhaustion_score', 'R_HIP_energy_by_trial', 'R_HIP_energy_by_trial_exhaustion_score', 'R_HIP_energy_overall_cumulative', 'R_HIP_energy_overall_exhaustion_score', 'L_ELBOW_energy_by_trial', 'L_ELBOW_energy_by_trial_exhaustion_score', 'L_ELBOW_energy_overall_cumulative', 'L_ELBOW_energy_overall_exhaustion_score', 'R_ELBOW_energy_by_trial', 'R_ELBOW_energy_by_trial_exhaustion_score', 'R_ELBOW_energy_overall_cumulative', 'R_ELBOW_energy_overall_exhaustion_score', 'L_WRIST_energy_by_trial', 'L_WRIST_energy_by_trial_exhaustion_score', 'L_WRIST_energy_overall_cumulative', 'L_WRIST_energy_overall_exhaustion_score', 'R_WRIST_energy_by_trial', 'R_WRIST_energy_by_trial_exhaustion_score', 'R_WRIST_energy_overall_cumulative', 'R_WRIST_energy_overall_exhaustion_score', 'L_1STFINGER_energy_by_trial', 'L_1STFINGER_energy_by_trial_exhaustion_score', 'L_1STFINGER_energy_overall_cumulative', 'L_1STFINGER_energy_overall_exhaustion_score', 'R_1STFINGER_energy_by_trial', 'R_1STFINGER_energy_by_trial_exhaustion_score', 'R_1STFINGER_energy_overall_cumulative', 'R_1STFINGER_energy_overall_exhaustion_score', 'L_5THFINGER_energy_by_trial', 'L_5THFINGER_energy_by_trial_exhaustion_score', 'L_5THFINGER_energy_overall_cumulative', 'L_5THFINGER_energy_overall_exhaustion_score', 'R_5THFINGER_energy_by_trial', 'R_5THFINGER_energy_by_trial_exhaustion_score', 'R_5THFINGER_energy_overall_cumulative', 'R_5THFINGER_energy_overall_exhaustion_score', 'participant_id', 'L_SHOULDER_angle', 'R_SHOULDER_angle', 'L_HIP_angle', 'R_HIP_angle', 'L_KNEE_angle', 'R_KNEE_angle', 'L_ANKLE_angle', 'R_ANKLE_angle', 'player_weight__in_kg', 'joint_energy', 'joint_power', 'energy_acceleration', 'ankle_power_ratio', 'hip_asymmetry', 'ankle_asymmetry', 'wrist_asymmetry', 'elbow_asymmetry', 'knee_asymmetry', '1stfinger_asymmetry', '5thfinger_asymmetry', 'hip_power_ratio', 'wrist_power_ratio', 'elbow_power_ratio', 'knee_power_ratio', '1stfinger_power_ratio', '5thfinger_power_ratio', 'L_KNEE_ROM', 'L_KNEE_ROM_deviation', 'L_KNEE_ROM_extreme', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM_extreme', 'L_SHOULDER_ROM', 'L_SHOULDER_ROM_deviation', 'L_SHOULDER_ROM_extreme', 'R_SHOULDER_ROM', 'R_SHOULDER_ROM_deviation', 'R_SHOULDER_ROM_extreme', 'L_HIP_ROM', 'L_HIP_ROM_deviation', 'L_HIP_ROM_extreme', 'R_HIP_ROM', 'R_HIP_ROM_deviation', 'R_HIP_ROM_extreme', 'L_ANKLE_ROM', 'L_ANKLE_ROM_deviation', 'L_ANKLE_ROM_extreme', 'R_ANKLE_ROM', 'R_ANKLE_ROM_deviation', 'R_ANKLE_ROM_extreme', 'exhaustion_rate', 'simulated_HR', 'time_since_start', 'power_avg_5', 'rolling_power_std', 'rolling_hr_mean', 'rolling_energy_std', 'exhaustion_lag1', 'ema_exhaustion', 'rolling_exhaustion', 'injury_risk', 'L_ANKLE_exhaustion_rate', 'L_ANKLE_rolling_exhaustion', 'L_ANKLE_injury_risk', 'R_ANKLE_exhaustion_rate', 'R_ANKLE_rolling_exhaustion', 'R_ANKLE_injury_risk', 'L_WRIST_exhaustion_rate', 'L_WRIST_rolling_exhaustion', 'L_WRIST_injury_risk', 'R_WRIST_exhaustion_rate', 'R_WRIST_rolling_exhaustion', 'R_WRIST_injury_risk', 'L_ELBOW_exhaustion_rate', 'L_ELBOW_rolling_exhaustion', 'L_ELBOW_injury_risk', 'R_ELBOW_exhaustion_rate', 'R_ELBOW_rolling_exhaustion', 'R_ELBOW_injury_risk', 'L_KNEE_exhaustion_rate', 'L_KNEE_rolling_exhaustion', 'L_KNEE_injury_risk', 'R_KNEE_exhaustion_rate', 'R_KNEE_rolling_exhaustion', 'R_KNEE_injury_risk', 'L_HIP_exhaustion_rate', 'L_HIP_rolling_exhaustion', 'L_HIP_injury_risk', 'R_HIP_exhaustion_rate', 'R_HIP_rolling_exhaustion', 'R_HIP_injury_risk']\n\n\n\n\n\n\n\n\n\nINFO: Energy distribution plot displayed.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\nINFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n\n\n\n\n\n\n\n\n\nINFO: Injury risk analysis plots displayed.\n\n\n\n\n\n\n\n\n\nINFO: Cumulative energy plot displayed.\nINFO: Step [joint_specific_analysis] completed.\nINFO: No angular velocity columns found.\n\n\n\n\n\n\n\n\n\nINFO: Displayed asymmetry pairplot.\nINFO: Step [movement_pattern_analysis] completed.\n\n\n\n\n\n\n\n\n\n&lt;Figure size 1200x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nINFO: Step [temporal_analysis_enhancements] completed.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:742: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data.loc[X_left.index, 'left_movement_cluster'] = kmeans_left.labels_\n\n\n\n\n\n\n\n\n\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:762: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data.loc[X_right.index, 'right_movement_cluster'] = kmeans_right.labels_\n\n\n\n\n\n\n\n\n\nINFO: Step [multivariate_analysis] completed.\nINFO: Mann-Whitney U Test Results:\nINFO:       Joint  U Statistic        p-value  Effect Size\n5         R   15510670.5   0.000000e+00     0.302223\n6         L   10089392.5   0.000000e+00     0.196590\n7         R   15218604.0   0.000000e+00     0.296532\n8         L   15772759.5   0.000000e+00     0.307329\n14    total   15160889.0   0.000000e+00     0.295407\n4         L   16110172.0  5.298836e-291     0.313904\n1         R   16111873.5  6.336392e-291     0.313937\n2         L   16422890.0  2.133726e-272     0.319997\n0         L   16594942.5  1.931523e-262     0.323350\n10        L   16695748.0  1.142095e-256     0.325314\n3         R   16717178.5  1.874515e-255     0.325731\n12        L   17010556.0  4.163121e-239     0.331448\n15  rolling   17114343.0  1.870689e-233     0.333470\n9         R   20151904.0   3.549291e-98     0.392656\n11        R   21567895.0   4.991695e-55     0.420247\n13        R   21715797.0   2.990407e-51     0.423129\nINFO: Step [statistical_testing] completed.\nINFO: Processing pipeline completed successfully.\n\n\n\n\nFeature Engineering\n\nimport numpy as np\nimport pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nimport sys\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.inspection import permutation_importance\nimport shap\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom joblib import Parallel, delayed\n\nlogging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n\ndef save_top_features(results, output_dir=\"feature_lists\", n_top=10):\n    \"\"\"\n    Saves top features for each target to pickle files.\n    \n    Parameters:\n      - results (dict): Results dictionary from feature importance analysis.\n                        Keys are target names and values are tuples (combined DataFrame, model).\n      - output_dir (str): Directory to save feature lists.\n      - n_top (int): Number of top features to consider.\n      \n    The function selects the top n features based on consensus ranking.\n    If any of the selected top features have 0 importance in either Permutation Importance or SHAP,\n    those features are filtered out. The final list of features may contain fewer than n_top features.\n    \"\"\"\n    Path(output_dir).mkdir(parents=True, exist_ok=True)\n    for target, (combined, _) in results.items():\n        if 'Consensus_Rank' not in combined.columns:\n            combined['Consensus_Rank'] = (\n                combined['Perm_Importance'].rank(ascending=False) +\n                combined['RFE_Rank'] +\n                combined['SHAP_Importance'].rank(ascending=False)\n            )\n        valid_features = combined[\n            (combined['Perm_Importance'] &gt; 0) | (combined['SHAP_Importance'] &gt; 0)\n        ]\n        if valid_features.empty:\n            logging.warning(f\"No features with positive importance for {target}\")\n            continue\n        top_n = valid_features.nsmallest(n_top, 'Consensus_Rank')\n        filtered_top_features = top_n[\n            (top_n['Perm_Importance'] &gt; 0) & (top_n['SHAP_Importance'] &gt; 0)\n        ]\n        top_features = filtered_top_features['Feature'].tolist()\n        filename = Path(output_dir) / f\"{target}_model_feature_list.pkl\"\n        pd.to_pickle(top_features, filename)\n        logging.info(f\"Saved top features for {target} to {filename}: {top_features}\")\n\ndef perform_feature_importance_analysis(data, features, target, n_features_to_select=5, debug=False):\n    \"\"\"\n    Performs feature importance analysis using Permutation Importance, RFE, and SHAP.\n    \n    Steps:\n      1. Prepare the data (handle missing values and split into training/testing sets).\n      2. Train a RandomForestRegressor (with fewer trees for improved efficiency).\n      3. Compute Permutation Importance (with fewer repeats).\n      4. Perform Recursive Feature Elimination (RFE) on the training data.\n      5. Merge results into one combined DataFrame.\n      6. Compute SHAP values using a subsample of the test set for faster approximation.\n      7. Optionally, produce debug plots if debug=True.\n    \n    Returns:\n      - combined (pd.DataFrame): DataFrame containing permutation importance, RFE rankings, and SHAP importance.\n      - rf (RandomForestRegressor): The fitted model.\n    \"\"\"\n    X = data[features].fillna(method='ffill').fillna(method='bfill')\n    y = data[target].fillna(method='ffill').fillna(method='bfill')\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n    rf = RandomForestRegressor(n_estimators=50, random_state=42)  # Reduced from 100\n    rf.fit(X_train, y_train)\n    perm_result = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42)  # Reduced from 30\n    perm_df = pd.DataFrame({\n        'Feature': features,\n        'Perm_Importance': perm_result.importances_mean\n    })\n    rfe_selector = RFE(estimator=rf, n_features_to_select=n_features_to_select, step=1)\n    rfe_selector.fit(X_train, y_train)\n    rfe_df = pd.DataFrame({\n        'Feature': features,\n        'RFE_Rank': rfe_selector.ranking_,\n        'RFE_Support': rfe_selector.support_\n    })\n    combined = perm_df.merge(rfe_df, on='Feature')\n    explainer = shap.TreeExplainer(rf)\n    sample_size = min(100, X_test.shape[0])\n    X_test_sampled = X_test.sample(sample_size, random_state=42)\n    shap_values = explainer.shap_values(X_test_sampled)\n    shap_abs = np.abs(shap_values).mean(axis=0)\n    shap_df = pd.DataFrame({\n        'Feature': features,\n        'SHAP_Importance': shap_abs\n    })\n    combined = combined.merge(shap_df, on='Feature')\n    if debug:\n        plt.figure(figsize=(10, 6))\n        sns.barplot(x='Perm_Importance', y='Feature', data=combined.nlargest(20, 'Perm_Importance'))\n        plt.title('Top Permutation Importances')\n        plt.xlabel('Mean Permutation Importance')\n        plt.ylabel('Feature')\n        plt.show()\n        shap.summary_plot(shap_values, X_test_sampled, plot_type=\"bar\", max_display=20)\n    return combined, rf\n\ndef analyze_and_display_top_features(results, n_top=5):\n    \"\"\"\n    For each target in the results dictionary, extracts and displays the top features based on:\n      - Permutation Importance\n      - RFE (only the features selected by RFE support)\n      - SHAP Importance\n      - A consensus ranking calculated from the three metrics.\n    \n    Parameters:\n      - results (dict): A dictionary where keys are target names and values are tuples:\n                          (combined DataFrame, fitted model).\n      - n_top (int): Number of top features to display for each method.\n    \n    This function prints the top features for each target.\n    \"\"\"\n    for target, (combined, _) in results.items():\n        print(f\"\\n=== Feature Analysis for Target: {target.upper()} ===\")\n        perm_top = combined.nlargest(n_top, 'Perm_Importance')['Feature'].tolist()\n        rfe_top = combined[combined['RFE_Support']]['Feature'].tolist()\n        shap_top = combined.nlargest(n_top, 'SHAP_Importance')['Feature'].tolist()\n        combined['Consensus_Rank'] = (\n            combined['Perm_Importance'].rank(ascending=False) +\n            combined['RFE_Rank'] +\n            combined['SHAP_Importance'].rank(ascending=False)\n        )\n        consensus_top = combined.nsmallest(n_top, 'Consensus_Rank')['Feature'].tolist()\n        print(f\"Permutation Top {n_top}: {perm_top}\")\n        print(f\"RFE Selected Features: {rfe_top}\")\n        print(f\"SHAP Top {n_top}: {shap_top}\")\n        print(f\"Consensus Top {n_top}: {consensus_top}\")\n\ndef check_for_invalid_values(df):\n    \"\"\"Check DataFrame for inf/na values and extreme magnitudes\"\"\"\n    numeric_df = df.select_dtypes(include=[np.number])\n    inf_mask = numeric_df.isin([np.inf, -np.inf])\n    if inf_mask.any().any():\n        logging.error(f\"Found infinite values in columns: {numeric_df.columns[inf_mask.any()].tolist()}\")\n    na_mask = numeric_df.isna()\n    if na_mask.any().any():\n        logging.error(f\"Found NA values in columns: {numeric_df.columns[na_mask.any()].tolist()}\")\n    extreme_mask = (numeric_df.abs() &gt; 1e30).any(axis=1)\n    if extreme_mask.any():\n        logging.error(f\"Found extreme values (&gt;1e30) in rows: {numeric_df.index[extreme_mask].tolist()}\")\n    return inf_mask.sum().sum() + na_mask.sum().sum() + extreme_mask.sum()\n\ndef analyze_joint_injury_features(results, joint, n_top=10):\n    \"\"\"\n    Aggregates feature importance metrics for a specific joint injury model.\n    \n    This function looks for keys in the results dictionary that correspond\n    to the given joint (e.g. keys containing '_ANKLE_injury_risk') and then\n    aggregates the metrics across the different sides (e.g. L and R). The\n    aggregation is done by averaging the numeric importance metrics and taking\n    the logical OR for the RFE support.\n    \n    After aggregation, a consensus ranking is computed and the top features\n    (filtered to remove any features with zero in either Permutation or SHAP importance)\n    are returned.\n    \n    Parameters:\n      - results (dict): Dictionary of results from feature importance analysis.\n                        Keys are target names and values are tuples (combined DataFrame, model).\n      - joint (str): The joint name (e.g. \"ANKLE\") for which to aggregate the models.\n      - n_top (int): Number of top features to select.\n      \n    Returns:\n      - top_features (list): List of aggregated top features for the given joint.\n      - agg_df (pd.DataFrame): The aggregated dataframe of feature importance metrics.\n    \"\"\"\n    joint_keys = [key for key in results if f\"_{joint}_injury_risk\" in key]\n    if not joint_keys:\n        logging.warning(f\"No injury models found for joint: {joint}\")\n        return [], None\n    df_list = []\n    for key in joint_keys:\n        combined_df, _ = results[key]\n        df_list.append(combined_df.copy())\n    concat_df = pd.concat(df_list, axis=0)\n    agg_df = concat_df.groupby(\"Feature\", as_index=False).agg({\n        'Perm_Importance': 'mean',\n        'SHAP_Importance': 'mean',\n        'RFE_Rank': 'mean',\n        'RFE_Support': 'max'\n    })\n    agg_df['Consensus_Rank'] = (\n        agg_df['Perm_Importance'].rank(ascending=False) +\n        agg_df['RFE_Rank'].rank(ascending=True) +\n        agg_df['SHAP_Importance'].rank(ascending=False)\n    )\n    agg_df = agg_df.sort_values(\"Consensus_Rank\")\n    top_n = agg_df.nsmallest(n_top, \"Consensus_Rank\")\n    filtered_top = top_n[\n        (top_n['Perm_Importance'] &gt; 0) & (top_n['SHAP_Importance'] &gt; 0)\n    ]\n    top_features = filtered_top['Feature'].tolist()\n    logging.info(f\"Aggregated top features for joint {joint}: {top_features}\")\n    return top_features, agg_df\n\nif __name__ == \"__main__\":\n    debug = True\n    csv_path = \"../../data/processed/final_granular_dataset.csv\"\n    json_path = \"../../data/basketball/freethrow/participant_information.json\"\n    output_dir = \"../../data/Deep_Learning_Final\"  # Directory for saving feature lists\n    \n    # Load and process the data (assumed to be defined externally)\n    data = load_data(csv_path, json_path, debug=debug)\n    data = prepare_joint_features(data, debug=debug)\n    data = feature_engineering(data, debug=debug)\n    print(data.columns.tolist())\n    \n    # Check for invalid values before model fitting\n    invalid_count = check_for_invalid_values(data)\n    if invalid_count &gt; 0:\n        logging.error(\"Invalid values detected in feature matrix\")\n        sys.exit(1)\n    \n    # Define your complete features list (as before)\n    features = [\n        'joint_energy', 'joint_power', 'energy_acceleration',\n        'elbow_asymmetry', 'hip_asymmetry', 'ankle_asymmetry', 'wrist_asymmetry', 'knee_asymmetry', '1stfinger_asymmetry', '5thfinger_asymmetry',\n        'elbow_power_ratio', 'hip_power_ratio', 'ankle_power_ratio', 'wrist_power_ratio', 'knee_power_ratio', '1stfinger_power_ratio', '5thfinger_power_ratio',\n        'L_KNEE_ROM', 'L_KNEE_ROM_deviation', 'L_KNEE_ROM_extreme',\n        'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM_extreme',\n        'L_SHOULDER_ROM', 'L_SHOULDER_ROM_deviation', 'L_SHOULDER_ROM_extreme',\n        'R_SHOULDER_ROM', 'R_SHOULDER_ROM_deviation', 'R_SHOULDER_ROM_extreme',\n        'L_HIP_ROM', 'L_HIP_ROM_deviation', 'L_HIP_ROM_extreme',\n        'R_HIP_ROM', 'R_HIP_ROM_deviation', 'R_HIP_ROM_extreme',\n        'L_ANKLE_ROM', 'L_ANKLE_ROM_deviation', 'L_ANKLE_ROM_extreme',\n        'R_ANKLE_ROM', 'R_ANKLE_ROM_deviation', 'R_ANKLE_ROM_extreme',\n        'exhaustion_lag1', 'power_avg_5', 'rolling_power_std', 'rolling_hr_mean',\n        'time_since_start', 'ema_exhaustion', 'rolling_exhaustion', 'rolling_energy_std',\n        'simulated_HR',\n        'player_height_in_meters', 'player_weight__in_kg'\n    ]\n    \n    # Define target variables.\n    targets = ['by_trial_exhaustion_score', 'injury_risk']\n    joints = ['ANKLE', 'WRIST', 'ELBOW', 'KNEE', 'HIP']\n    for joint in joints:\n        for side in ['L', 'R']:\n            targets.append(f\"{side}_{joint}_injury_risk\")\n    \n    # Validate that all required features and targets exist in the data.\n    missing_features = [feat for feat in features if feat not in data.columns]\n    missing_targets = [t for t in targets if t not in data.columns]\n    if missing_features:\n        logging.error(f\"Missing features: {missing_features}\")\n        sys.exit(1)\n    if missing_targets:\n        logging.error(f\"Missing target variables: {missing_targets}\")\n        sys.exit(1)\n    else:\n        logging.info(\"All required features and target variables are present.\")\n    \n    # Use parallel processing to perform feature importance analysis for each target concurrently.\n    results_list = Parallel(n_jobs=-1)(\n        delayed(perform_feature_importance_analysis)(data, features, target, debug=debug)\n        for target in targets\n    )\n    results = {target: res for target, res in zip(targets, results_list)}\n    \n    # Display the top features for each target\n    analyze_and_display_top_features(results, n_top=10)\n    \n    # Save the top features for each target to pickle files\n    save_top_features(results, output_dir=output_dir, n_top=10)\n    \n    # Aggregate and display joint injury models per joint\n    for joint in joints:\n        top_features, agg_df = analyze_joint_injury_features(results, joint, n_top=10)\n        if top_features:\n            logging.info(f\"Aggregated top features for joint {joint}: {top_features}\")\n            filename = Path(output_dir) / f\"{joint}_aggregated_feature_importance.pkl\"\n            pd.to_pickle(agg_df, filename)\n            logging.info(f\"Saved aggregated feature importance for joint {joint} to {filename}\")\n\nINFO: Loaded data from ../../data/processed/final_granular_dataset.csv with shape (16047, 214)\nINFO: Added 'participant_id' column with value 'P0001'\nINFO: Loaded participant information from ../../data/basketball/freethrow/participant_information.json\nINFO: Merged participant data. New shape: (16047, 217)\nINFO: Step [load_data]: DataFrame shape = (16047, 217)\nINFO: Calculated L_SHOULDER_angle with mean: 37.07°\nINFO: Calculated R_SHOULDER_angle with mean: 41.72°\nINFO: Calculated L_HIP_angle with mean: 157.79°\nINFO: Calculated R_HIP_angle with mean: 155.49°\nINFO: Calculated L_KNEE_angle with mean: 157.21°\nINFO: Calculated R_KNEE_angle with mean: 152.18°\nINFO: Calculated L_ANKLE_angle with mean: 113.75°\nINFO: Calculated R_ANKLE_angle with mean: 114.63°\nINFO: Step [calculate_joint_angles]: DataFrame shape = (16047, 225)\nINFO: New columns added: ['L_SHOULDER_angle', 'R_SHOULDER_angle', 'L_HIP_angle', 'R_HIP_angle', 'L_KNEE_angle', 'R_KNEE_angle', 'L_ANKLE_angle', 'R_ANKLE_angle']\nINFO:  - L_SHOULDER_angle: dtype=float64, sample values=[21.60539187 22.06901465 22.36025929 22.40661102 22.35603223]\nINFO:  - R_SHOULDER_angle: dtype=float64, sample values=[19.7439164  19.99288757 20.17556749 20.32850063 20.41384808]\nINFO:  - L_HIP_angle: dtype=float64, sample values=[166.66216865 167.54930512 168.38412077 169.13603097 169.77674873]\nINFO:  - R_HIP_angle: dtype=float64, sample values=[172.36581725 169.3001433  166.60177841 164.42775916 163.15032681]\nINFO:  - L_KNEE_angle: dtype=float64, sample values=[159.60787091 160.63620962 161.7064911  162.70735335 163.68010105]\nINFO:  - R_KNEE_angle: dtype=float64, sample values=[144.02241138 138.83820789 135.23462182 133.60754574 134.17926352]\nINFO:  - L_ANKLE_angle: dtype=float64, sample values=[116.19078287 117.19419756 118.10095304 118.75673954 119.58404627]\nINFO:  - R_ANKLE_angle: dtype=float64, sample values=[116.77875188 115.72547317 114.66825566 113.3630418  112.54700118]\nINFO: Renamed participant anthropometrics.\nINFO: Identified 15 joint energy and 14 joint power columns.\nINFO: Created aggregated 'joint_energy' and 'joint_power'.\nINFO: Created 'energy_acceleration' as derivative of joint_energy over time.\nINFO: Created 'ankle_power_ratio' feature comparing left to right ankle ongoing power.\nINFO: Created asymmetry feature: hip_asymmetry\nINFO: Created asymmetry feature: ankle_asymmetry\nINFO: Created asymmetry feature: wrist_asymmetry\nINFO: Created asymmetry feature: elbow_asymmetry\nINFO: Created asymmetry feature: knee_asymmetry\nINFO: Created asymmetry feature: 1stfinger_asymmetry\nINFO: Created asymmetry feature: 5thfinger_asymmetry\nINFO: Created power ratio feature: hip_power_ratio using columns L_HIP_ongoing_power and R_HIP_ongoing_power\nINFO: Created power ratio feature: ankle_power_ratio using columns L_ANKLE_ongoing_power and R_ANKLE_ongoing_power\nINFO: Created power ratio feature: wrist_power_ratio using columns L_WRIST_ongoing_power and R_WRIST_ongoing_power\nINFO: Created power ratio feature: elbow_power_ratio using columns L_ELBOW_ongoing_power and R_ELBOW_ongoing_power\nINFO: Created power ratio feature: knee_power_ratio using columns L_KNEE_ongoing_power and R_KNEE_ongoing_power\nINFO: Created power ratio feature: 1stfinger_power_ratio using columns L_1STFINGER_ongoing_power and R_1STFINGER_ongoing_power\nINFO: Created power ratio feature: 5thfinger_power_ratio using columns L_5THFINGER_ongoing_power and R_5THFINGER_ongoing_power\nINFO: Computed ROM for L KNEE as L_KNEE_ROM\nINFO: Computed ROM deviation for L KNEE as L_KNEE_ROM_deviation\nINFO: Created binary flag for L KNEE ROM extremes: L_KNEE_ROM_extreme\nINFO: Computed ROM for R KNEE as R_KNEE_ROM\nINFO: Computed ROM deviation for R KNEE as R_KNEE_ROM_deviation\nINFO: Created binary flag for R KNEE ROM extremes: R_KNEE_ROM_extreme\nINFO: Computed ROM for L SHOULDER as L_SHOULDER_ROM\nINFO: Computed ROM deviation for L SHOULDER as L_SHOULDER_ROM_deviation\nINFO: Created binary flag for L SHOULDER ROM extremes: L_SHOULDER_ROM_extreme\nINFO: Computed ROM for R SHOULDER as R_SHOULDER_ROM\nINFO: Computed ROM deviation for R SHOULDER as R_SHOULDER_ROM_deviation\nINFO: Created binary flag for R SHOULDER ROM extremes: R_SHOULDER_ROM_extreme\nINFO: Computed ROM for L HIP as L_HIP_ROM\n\n\nJoint energy columns:  ['L_ANKLE_energy', 'R_ANKLE_energy', 'L_KNEE_energy', 'R_KNEE_energy', 'L_HIP_energy', 'R_HIP_energy', 'L_ELBOW_energy', 'R_ELBOW_energy', 'L_WRIST_energy', 'R_WRIST_energy', 'L_1STFINGER_energy', 'R_1STFINGER_energy', 'L_5THFINGER_energy', 'R_5THFINGER_energy', 'total_energy']\nJoint power columns:  ['L_ANKLE_ongoing_power', 'R_ANKLE_ongoing_power', 'L_KNEE_ongoing_power', 'R_KNEE_ongoing_power', 'L_HIP_ongoing_power', 'R_HIP_ongoing_power', 'L_ELBOW_ongoing_power', 'R_ELBOW_ongoing_power', 'L_WRIST_ongoing_power', 'R_WRIST_ongoing_power', 'L_1STFINGER_ongoing_power', 'L_5THFINGER_ongoing_power', 'R_1STFINGER_ongoing_power', 'R_5THFINGER_ongoing_power']\nAll angle columns:  ['entry_angle', 'elbow_angle', 'wrist_angle', 'knee_angle', 'initial_release_angle', 'calculated_release_angle', 'angle_difference', 'optimal_release_angle', 'L_SHOULDER_angle', 'R_SHOULDER_angle', 'L_HIP_angle', 'R_HIP_angle', 'L_KNEE_angle', 'R_KNEE_angle', 'L_ANKLE_angle', 'R_ANKLE_angle']\n\n\nINFO: Computed ROM deviation for L HIP as L_HIP_ROM_deviation\nINFO: Created binary flag for L HIP ROM extremes: L_HIP_ROM_extreme\nINFO: Computed ROM for R HIP as R_HIP_ROM\nINFO: Computed ROM deviation for R HIP as R_HIP_ROM_deviation\nINFO: Created binary flag for R HIP ROM extremes: R_HIP_ROM_extreme\nINFO: Computed ROM for L ANKLE as L_ANKLE_ROM\nINFO: Computed ROM deviation for L ANKLE as L_ANKLE_ROM_deviation\nINFO: Created binary flag for L ANKLE ROM extremes: L_ANKLE_ROM_extreme\nINFO: Computed ROM for R ANKLE as R_ANKLE_ROM\nINFO: Computed ROM deviation for R ANKLE as R_ANKLE_ROM_deviation\nINFO: Created binary flag for R ANKLE ROM extremes: R_ANKLE_ROM_extreme\nINFO: Angle column 'L_WRIST_angle' not found; skipping ROM metrics for L WRIST.\nINFO: Angle column 'R_WRIST_angle' not found; skipping ROM metrics for R WRIST.\nINFO: Sorted data by 'participant_id' and 'continuous_frame_time'.\nINFO: Created 'exhaustion_rate' feature.\nINFO: Created 'simulated_HR' feature.\nINFO: Step [prepare_joint_features]: DataFrame shape = (16047, 267)\nINFO: New columns added: ['player_height_in_meters', 'player_weight__in_kg', 'joint_energy', 'joint_power', 'energy_acceleration', 'ankle_power_ratio', 'hip_asymmetry', 'ankle_asymmetry', 'wrist_asymmetry', 'elbow_asymmetry', 'knee_asymmetry', '1stfinger_asymmetry', '5thfinger_asymmetry', 'hip_power_ratio', 'ankle_power_ratio', 'wrist_power_ratio', 'elbow_power_ratio', 'knee_power_ratio', '1stfinger_power_ratio', '5thfinger_power_ratio', 'L_KNEE_ROM', 'L_KNEE_ROM_deviation', 'L_KNEE_ROM_extreme', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM_extreme', 'L_SHOULDER_ROM', 'L_SHOULDER_ROM_deviation', 'L_SHOULDER_ROM_extreme', 'R_SHOULDER_ROM', 'R_SHOULDER_ROM_deviation', 'R_SHOULDER_ROM_extreme', 'L_HIP_ROM', 'L_HIP_ROM_deviation', 'L_HIP_ROM_extreme', 'R_HIP_ROM', 'R_HIP_ROM_deviation', 'R_HIP_ROM_extreme', 'L_ANKLE_ROM', 'L_ANKLE_ROM_deviation', 'L_ANKLE_ROM_extreme', 'R_ANKLE_ROM', 'R_ANKLE_ROM_deviation', 'R_ANKLE_ROM_extreme', 'exhaustion_rate', 'simulated_HR']\nINFO:  - player_height_in_meters: dtype=float64, sample values=[1.91]\nINFO:  - player_weight__in_kg: dtype=float64, sample values=[90.7]\nINFO:  - joint_energy: dtype=float64, sample values=[0.         1.24504856 1.26769572 1.27596309 1.24122093]\nINFO:  - joint_power: dtype=float64, sample values=[ 0.         18.86437211 19.2075109  18.76416304 18.80637774]\nINFO:  - energy_acceleration: dtype=float64, sample values=[ 0.03772874  0.00068628  0.00024316 -0.00105279 -0.00193555]\nINFO:  - ankle_power_ratio: dtype=float64, sample values=[0.         0.04922415 0.03166691 0.04290572 0.03725055]\nINFO:  - hip_asymmetry: dtype=float64, sample values=[0.         0.01136788 0.01341974 0.01384676 0.01642692]\nINFO:  - ankle_asymmetry: dtype=float64, sample values=[0.         0.09462489 0.11441502 0.12814345 0.14156018]\nINFO:  - wrist_asymmetry: dtype=float64, sample values=[0.         0.00470701 0.00259394 0.00382874 0.00900069]\nINFO:  - elbow_asymmetry: dtype=float64, sample values=[0.         0.0239616  0.01633813 0.01263925 0.0120038 ]\nINFO:  - knee_asymmetry: dtype=float64, sample values=[0.         0.12061726 0.11370624 0.0958499  0.07531242]\nINFO:  - 1stfinger_asymmetry: dtype=float64, sample values=[0.         0.00462894 0.00358597 0.00835639 0.01393676]\nINFO:  - 5thfinger_asymmetry: dtype=float64, sample values=[0.         0.00906876 0.00535429 0.00715568 0.01116826]\nINFO:  - hip_power_ratio: dtype=float64, sample values=[0.         0.74516814 0.69886924 0.68432046 0.64373336]\nINFO:  - ankle_power_ratio: dtype=float64, sample values=[0.         0.04922415 0.03166691 0.04290572 0.03725055]\nINFO:  - wrist_power_ratio: dtype=float64, sample values=[0.         0.89402977 0.94064628 0.91239215 0.79490791]\nINFO:  - elbow_power_ratio: dtype=float64, sample values=[0.         0.352389   0.56734365 0.68912505 0.72023539]\nINFO:  - knee_power_ratio: dtype=float64, sample values=[0.         0.03660208 0.01500412 0.03344499 0.06341159]\nINFO:  - 1stfinger_power_ratio: dtype=float64, sample values=[0.         0.8973365  0.92009387 0.82159711 0.70123266]\nINFO:  - 5thfinger_power_ratio: dtype=float64, sample values=[0.         0.81829684 0.8863865  0.84370078 0.74034267]\nINFO:  - L_KNEE_ROM: dtype=float64, sample values=[52.00092712 53.68236675 54.04526663 53.31592037 49.12814203]\nINFO:  - L_KNEE_ROM_deviation: dtype=float64, sample values=[67.99907288 66.31763325 65.95473337 66.68407963 70.87185797]\nINFO:  - L_KNEE_ROM_extreme: dtype=int32, sample values=[1]\nINFO:  - R_KNEE_ROM: dtype=float64, sample values=[52.46491718 57.16166718 55.28397109 60.32702297 59.65659628]\nINFO:  - R_KNEE_ROM_deviation: dtype=float64, sample values=[67.53508282 62.83833282 64.71602891 59.67297703 60.34340372]\nINFO:  - R_KNEE_ROM_extreme: dtype=int32, sample values=[1]\nINFO:  - L_SHOULDER_ROM: dtype=float64, sample values=[106.59807383 109.54498215 108.02057817 111.7412054  108.67548157]\nINFO:  - L_SHOULDER_ROM_deviation: dtype=float64, sample values=[0.]\nINFO:  - L_SHOULDER_ROM_extreme: dtype=int32, sample values=[0]\nINFO:  - R_SHOULDER_ROM: dtype=float64, sample values=[127.36630171 132.42520607 131.55366227 126.88154535 124.04488661]\nINFO:  - R_SHOULDER_ROM_deviation: dtype=float64, sample values=[0.]\nINFO:  - R_SHOULDER_ROM_extreme: dtype=int32, sample values=[0]\nINFO:  - L_HIP_ROM: dtype=float64, sample values=[41.87334176 42.69399027 44.29157825 43.33340404 39.10888539]\nINFO:  - L_HIP_ROM_deviation: dtype=float64, sample values=[0.]\nINFO:  - L_HIP_ROM_extreme: dtype=int32, sample values=[0]\nINFO:  - R_HIP_ROM: dtype=float64, sample values=[51.00676746 53.8922429  56.17856317 53.15755447 50.23341005]\nINFO:  - R_HIP_ROM_deviation: dtype=float64, sample values=[0.]\nINFO:  - R_HIP_ROM_extreme: dtype=int32, sample values=[0]\nINFO:  - L_ANKLE_ROM: dtype=float64, sample values=[32.32505371 32.99123382 38.821896   35.45367686 32.1162011 ]\nINFO:  - L_ANKLE_ROM_deviation: dtype=float64, sample values=[12.32505371 12.99123382 18.821896   15.45367686 12.1162011 ]\nINFO:  - L_ANKLE_ROM_extreme: dtype=int32, sample values=[1]\nINFO:  - R_ANKLE_ROM: dtype=float64, sample values=[39.81071151 45.54250042 45.70572465 43.1338381  39.83072086]\nINFO:  - R_ANKLE_ROM_deviation: dtype=float64, sample values=[19.81071151 25.54250042 25.70572465 23.1338381  19.83072086]\nINFO:  - R_ANKLE_ROM_extreme: dtype=int32, sample values=[1]\nINFO:  - exhaustion_rate: dtype=float64, sample values=[0.00025383 0.00025845 0.00025248 0.00025305 0.00024003]\nINFO:  - simulated_HR: dtype=float64, sample values=[60.         60.38607909 60.4056663  60.421023   60.42312625]\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_36748\\333979470.py:394: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data[motion_cols] = data[motion_cols].fillna(method='ffill').fillna(0)\nINFO: Created 'rolling_energy_std' with sample: [0.0, 0.6225242794725895, 0.592331668013902, 0.5469698974921113, 0.5031647476376774, 0.0346469804150002, 0.05501279562072104, 0.06384083445684284, 0.05698938811919827, 0.039917330417864196]\nINFO: Created 'rolling_energy_std' with window 5.\n\n\nprint all the columns with by_trial_exhaustion_score:  ['by_trial_exhaustion_score', 'L_ANKLE_energy_by_trial_exhaustion_score', 'R_ANKLE_energy_by_trial_exhaustion_score', 'L_KNEE_energy_by_trial_exhaustion_score', 'R_KNEE_energy_by_trial_exhaustion_score', 'L_HIP_energy_by_trial_exhaustion_score', 'R_HIP_energy_by_trial_exhaustion_score', 'L_ELBOW_energy_by_trial_exhaustion_score', 'R_ELBOW_energy_by_trial_exhaustion_score', 'L_WRIST_energy_by_trial_exhaustion_score', 'R_WRIST_energy_by_trial_exhaustion_score', 'L_1STFINGER_energy_by_trial_exhaustion_score', 'R_1STFINGER_energy_by_trial_exhaustion_score', 'L_5THFINGER_energy_by_trial_exhaustion_score', 'R_5THFINGER_energy_by_trial_exhaustion_score']\n\n\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_36748\\333979470.py:443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_rolling_exhaustion'] = data[score_col].rolling(rolling_window, min_periods=1).sum()\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_36748\\333979470.py:447: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_injury_risk'] = (rolling_series &gt; safe_expanding_quantile(rolling_series)).astype(int)\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_36748\\333979470.py:442: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_exhaustion_rate'] = data[score_col].diff() / dt\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_36748\\333979470.py:443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_rolling_exhaustion'] = data[score_col].rolling(rolling_window, min_periods=1).sum()\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_36748\\333979470.py:447: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_injury_risk'] = (rolling_series &gt; safe_expanding_quantile(rolling_series)).astype(int)\nINFO: Step [feature_engineering]: DataFrame shape = (16046, 306)\nINFO: New columns added: ['time_since_start', 'rolling_energy_std', 'exhaustion_lag1', 'ema_exhaustion', 'rolling_exhaustion', 'injury_risk', 'L_ANKLE_exhaustion_rate', 'L_ANKLE_rolling_exhaustion', 'L_ANKLE_injury_risk', 'R_ANKLE_exhaustion_rate', 'R_ANKLE_rolling_exhaustion', 'R_ANKLE_injury_risk', 'L_WRIST_exhaustion_rate', 'L_WRIST_rolling_exhaustion', 'L_WRIST_injury_risk', 'R_WRIST_exhaustion_rate', 'R_WRIST_rolling_exhaustion', 'R_WRIST_injury_risk', 'L_ELBOW_exhaustion_rate', 'L_ELBOW_rolling_exhaustion', 'L_ELBOW_injury_risk', 'R_ELBOW_exhaustion_rate', 'R_ELBOW_rolling_exhaustion', 'R_ELBOW_injury_risk', 'L_KNEE_exhaustion_rate', 'L_KNEE_rolling_exhaustion', 'L_KNEE_injury_risk', 'R_KNEE_exhaustion_rate', 'R_KNEE_rolling_exhaustion', 'R_KNEE_injury_risk', 'L_HIP_exhaustion_rate', 'L_HIP_rolling_exhaustion', 'L_HIP_injury_risk', 'R_HIP_exhaustion_rate', 'R_HIP_rolling_exhaustion', 'R_HIP_injury_risk']\nINFO:  - time_since_start: dtype=int64, sample values=[ 33  66 100 133 166]\nINFO:  - rolling_energy_std: dtype=float64, sample values=[0.62252428 0.59233167 0.5469699  0.50316475 0.03464698]\nINFO:  - exhaustion_lag1: dtype=float64, sample values=[0.         0.00837635 0.01690506 0.02548939 0.03383998]\nINFO:  - ema_exhaustion: dtype=float64, sample values=[0.00152297 0.00431971 0.00816875 0.01283624 0.01809526]\nINFO:  - rolling_exhaustion: dtype=float64, sample values=[0.00837635 0.0252814  0.05077079 0.08461077 0.12637162]\nINFO:  - injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - L_ANKLE_exhaustion_rate: dtype=float64, sample values=[1.23696376e-04 9.44746676e-05 1.40780774e-04 1.38296753e-04\n 7.98456673e-05]\nINFO:  - L_ANKLE_rolling_exhaustion: dtype=float64, sample values=[0.00408198 0.01128162 0.02326782 0.0398178  0.05900269]\nINFO:  - L_ANKLE_injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - R_ANKLE_exhaustion_rate: dtype=float64, sample values=[0.00142576 0.00169269 0.00186164 0.00210643 0.00218641]\nINFO:  - R_ANKLE_rolling_exhaustion: dtype=float64, sample values=[0.04704999 0.14995866 0.316163   0.5518794  0.85974725]\nINFO:  - R_ANKLE_injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - L_WRIST_exhaustion_rate: dtype=float64, sample values=[0.00017214 0.0001782  0.00016777 0.00015122 0.00012138]\nINFO:  - L_WRIST_rolling_exhaustion: dtype=float64, sample values=[0.00568072 0.01724215 0.03450767 0.05676355 0.08302483]\nINFO:  - L_WRIST_injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - R_WRIST_exhaustion_rate: dtype=float64, sample values=[0.00016915 0.00016642 0.00016153 0.00016712 0.00016516]\nINFO:  - R_WRIST_rolling_exhaustion: dtype=float64, sample values=[0.00558186 0.01665573 0.03322162 0.05530248 0.08283351]\nINFO:  - R_WRIST_injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - L_ELBOW_exhaustion_rate: dtype=float64, sample values=[7.85882352e-05 1.29133648e-04 1.63909048e-04 1.86266503e-04\n 1.94752627e-04]\nINFO:  - L_ELBOW_rolling_exhaustion: dtype=float64, sample values=[0.00259341 0.00944823 0.02187596 0.04045049 0.06545185]\nINFO:  - L_ELBOW_injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - R_ELBOW_exhaustion_rate: dtype=float64, sample values=[0.00018342 0.0001872  0.00019562 0.00021271 0.0002313 ]\nINFO:  - R_ELBOW_rolling_exhaustion: dtype=float64, sample values=[0.00605294 0.01828356 0.03716539 0.06306649 0.09660057]\nINFO:  - R_ELBOW_injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - L_KNEE_exhaustion_rate: dtype=float64, sample values=[5.75663372e-05 2.17580303e-05 4.04380603e-05 6.40539068e-05\n 7.43178217e-05]\nINFO:  - L_KNEE_rolling_exhaustion: dtype=float64, sample values=[0.00189969 0.00451739 0.00850999 0.01461637 0.02317523]\nINFO:  - L_KNEE_injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - R_KNEE_exhaustion_rate: dtype=float64, sample values=[0.00140049 0.0012913  0.00107665 0.00089948 0.00066695]\nINFO:  - R_KNEE_rolling_exhaustion: dtype=float64, sample values=[0.04621615 0.13504507 0.26048023 0.41559839 0.59272603]\nINFO:  - R_KNEE_injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - L_HIP_exhaustion_rate: dtype=float64, sample values=[0.00039011 0.0003655  0.0003419  0.00034833 0.00035827]\nINFO:  - L_HIP_rolling_exhaustion: dtype=float64, sample values=[0.01287351 0.03780854 0.07436817 0.12242266 0.18230005]\nINFO:  - L_HIP_injury_risk: dtype=int32, sample values=[1 0]\nINFO:  - R_HIP_exhaustion_rate: dtype=float64, sample values=[0.00049068 0.00049019 0.00046828 0.00050717 0.00051545]\nINFO:  - R_HIP_rolling_exhaustion: dtype=float64, sample values=[0.01619242 0.04856097 0.09685115 0.16187792 0.24391457]\nINFO:  - R_HIP_injury_risk: dtype=int32, sample values=[1 0]\n\n\n['trial_id', 'result', 'landing_x', 'landing_y', 'entry_angle', 'frame_time', 'ball_x', 'ball_y', 'ball_z', 'R_EYE_x', 'R_EYE_y', 'R_EYE_z', 'L_EYE_x', 'L_EYE_y', 'L_EYE_z', 'NOSE_x', 'NOSE_y', 'NOSE_z', 'R_EAR_x', 'R_EAR_y', 'R_EAR_z', 'L_EAR_x', 'L_EAR_y', 'L_EAR_z', 'R_SHOULDER_x', 'R_SHOULDER_y', 'R_SHOULDER_z', 'L_SHOULDER_x', 'L_SHOULDER_y', 'L_SHOULDER_z', 'R_ELBOW_x', 'R_ELBOW_y', 'R_ELBOW_z', 'L_ELBOW_x', 'L_ELBOW_y', 'L_ELBOW_z', 'R_WRIST_x', 'R_WRIST_y', 'R_WRIST_z', 'L_WRIST_x', 'L_WRIST_y', 'L_WRIST_z', 'R_HIP_x', 'R_HIP_y', 'R_HIP_z', 'L_HIP_x', 'L_HIP_y', 'L_HIP_z', 'R_KNEE_x', 'R_KNEE_y', 'R_KNEE_z', 'L_KNEE_x', 'L_KNEE_y', 'L_KNEE_z', 'R_ANKLE_x', 'R_ANKLE_y', 'R_ANKLE_z', 'L_ANKLE_x', 'L_ANKLE_y', 'L_ANKLE_z', 'R_1STFINGER_x', 'R_1STFINGER_y', 'R_1STFINGER_z', 'R_5THFINGER_x', 'R_5THFINGER_y', 'R_5THFINGER_z', 'L_1STFINGER_x', 'L_1STFINGER_y', 'L_1STFINGER_z', 'L_5THFINGER_x', 'L_5THFINGER_y', 'L_5THFINGER_z', 'R_1STTOE_x', 'R_1STTOE_y', 'R_1STTOE_z', 'R_5THTOE_x', 'R_5THTOE_y', 'R_5THTOE_z', 'L_1STTOE_x', 'L_1STTOE_y', 'L_1STTOE_z', 'L_5THTOE_x', 'L_5THTOE_y', 'L_5THTOE_z', 'R_CALC_x', 'R_CALC_y', 'R_CALC_z', 'L_CALC_x', 'L_CALC_y', 'L_CALC_z', 'ball_speed', 'ball_velocity_x', 'ball_velocity_y', 'ball_velocity_z', 'overall_ball_velocity', 'ball_direction_x', 'ball_direction_y', 'ball_direction_z', 'computed_ball_velocity_x', 'computed_ball_velocity_y', 'computed_ball_velocity_z', 'dist_ball_R_1STFINGER', 'dist_ball_R_5THFINGER', 'dist_ball_L_1STFINGER', 'dist_ball_L_5THFINGER', 'ball_in_hands', 'shooting_motion', 'avg_shoulder_height', 'release_point_filter', 'dt', 'dx', 'dy', 'dz', 'L_ANKLE_ongoing_power', 'R_ANKLE_ongoing_power', 'L_KNEE_ongoing_power', 'R_KNEE_ongoing_power', 'L_HIP_ongoing_power', 'R_HIP_ongoing_power', 'L_ELBOW_ongoing_power', 'R_ELBOW_ongoing_power', 'L_WRIST_ongoing_power', 'R_WRIST_ongoing_power', 'L_1STFINGER_ongoing_power', 'L_5THFINGER_ongoing_power', 'R_1STFINGER_ongoing_power', 'R_5THFINGER_ongoing_power', 'elbow_angle', 'wrist_angle', 'knee_angle', 'player_height_in_meters', 'player_height_ft', 'initial_release_angle', 'calculated_release_angle', 'angle_difference', 'distance_to_basket', 'optimal_release_angle', 'by_trial_time', 'continuous_frame_time', 'L_ANKLE_energy', 'R_ANKLE_energy', 'L_KNEE_energy', 'R_KNEE_energy', 'L_HIP_energy', 'R_HIP_energy', 'L_ELBOW_energy', 'R_ELBOW_energy', 'L_WRIST_energy', 'R_WRIST_energy', 'L_1STFINGER_energy', 'R_1STFINGER_energy', 'L_5THFINGER_energy', 'R_5THFINGER_energy', 'total_energy', 'by_trial_energy', 'by_trial_exhaustion_score', 'overall_cumulative_energy', 'overall_exhaustion_score', 'L_ANKLE_energy_by_trial', 'L_ANKLE_energy_by_trial_exhaustion_score', 'L_ANKLE_energy_overall_cumulative', 'L_ANKLE_energy_overall_exhaustion_score', 'R_ANKLE_energy_by_trial', 'R_ANKLE_energy_by_trial_exhaustion_score', 'R_ANKLE_energy_overall_cumulative', 'R_ANKLE_energy_overall_exhaustion_score', 'L_KNEE_energy_by_trial', 'L_KNEE_energy_by_trial_exhaustion_score', 'L_KNEE_energy_overall_cumulative', 'L_KNEE_energy_overall_exhaustion_score', 'R_KNEE_energy_by_trial', 'R_KNEE_energy_by_trial_exhaustion_score', 'R_KNEE_energy_overall_cumulative', 'R_KNEE_energy_overall_exhaustion_score', 'L_HIP_energy_by_trial', 'L_HIP_energy_by_trial_exhaustion_score', 'L_HIP_energy_overall_cumulative', 'L_HIP_energy_overall_exhaustion_score', 'R_HIP_energy_by_trial', 'R_HIP_energy_by_trial_exhaustion_score', 'R_HIP_energy_overall_cumulative', 'R_HIP_energy_overall_exhaustion_score', 'L_ELBOW_energy_by_trial', 'L_ELBOW_energy_by_trial_exhaustion_score', 'L_ELBOW_energy_overall_cumulative', 'L_ELBOW_energy_overall_exhaustion_score', 'R_ELBOW_energy_by_trial', 'R_ELBOW_energy_by_trial_exhaustion_score', 'R_ELBOW_energy_overall_cumulative', 'R_ELBOW_energy_overall_exhaustion_score', 'L_WRIST_energy_by_trial', 'L_WRIST_energy_by_trial_exhaustion_score', 'L_WRIST_energy_overall_cumulative', 'L_WRIST_energy_overall_exhaustion_score', 'R_WRIST_energy_by_trial', 'R_WRIST_energy_by_trial_exhaustion_score', 'R_WRIST_energy_overall_cumulative', 'R_WRIST_energy_overall_exhaustion_score', 'L_1STFINGER_energy_by_trial', 'L_1STFINGER_energy_by_trial_exhaustion_score', 'L_1STFINGER_energy_overall_cumulative', 'L_1STFINGER_energy_overall_exhaustion_score', 'R_1STFINGER_energy_by_trial', 'R_1STFINGER_energy_by_trial_exhaustion_score', 'R_1STFINGER_energy_overall_cumulative', 'R_1STFINGER_energy_overall_exhaustion_score', 'L_5THFINGER_energy_by_trial', 'L_5THFINGER_energy_by_trial_exhaustion_score', 'L_5THFINGER_energy_overall_cumulative', 'L_5THFINGER_energy_overall_exhaustion_score', 'R_5THFINGER_energy_by_trial', 'R_5THFINGER_energy_by_trial_exhaustion_score', 'R_5THFINGER_energy_overall_cumulative', 'R_5THFINGER_energy_overall_exhaustion_score', 'participant_id', 'L_SHOULDER_angle', 'R_SHOULDER_angle', 'L_HIP_angle', 'R_HIP_angle', 'L_KNEE_angle', 'R_KNEE_angle', 'L_ANKLE_angle', 'R_ANKLE_angle', 'player_weight__in_kg', 'joint_energy', 'joint_power', 'energy_acceleration', 'ankle_power_ratio', 'hip_asymmetry', 'ankle_asymmetry', 'wrist_asymmetry', 'elbow_asymmetry', 'knee_asymmetry', '1stfinger_asymmetry', '5thfinger_asymmetry', 'hip_power_ratio', 'wrist_power_ratio', 'elbow_power_ratio', 'knee_power_ratio', '1stfinger_power_ratio', '5thfinger_power_ratio', 'L_KNEE_ROM', 'L_KNEE_ROM_deviation', 'L_KNEE_ROM_extreme', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM_extreme', 'L_SHOULDER_ROM', 'L_SHOULDER_ROM_deviation', 'L_SHOULDER_ROM_extreme', 'R_SHOULDER_ROM', 'R_SHOULDER_ROM_deviation', 'R_SHOULDER_ROM_extreme', 'L_HIP_ROM', 'L_HIP_ROM_deviation', 'L_HIP_ROM_extreme', 'R_HIP_ROM', 'R_HIP_ROM_deviation', 'R_HIP_ROM_extreme', 'L_ANKLE_ROM', 'L_ANKLE_ROM_deviation', 'L_ANKLE_ROM_extreme', 'R_ANKLE_ROM', 'R_ANKLE_ROM_deviation', 'R_ANKLE_ROM_extreme', 'exhaustion_rate', 'simulated_HR', 'time_since_start', 'power_avg_5', 'rolling_power_std', 'rolling_hr_mean', 'rolling_energy_std', 'exhaustion_lag1', 'ema_exhaustion', 'rolling_exhaustion', 'injury_risk', 'L_ANKLE_exhaustion_rate', 'L_ANKLE_rolling_exhaustion', 'L_ANKLE_injury_risk', 'R_ANKLE_exhaustion_rate', 'R_ANKLE_rolling_exhaustion', 'R_ANKLE_injury_risk', 'L_WRIST_exhaustion_rate', 'L_WRIST_rolling_exhaustion', 'L_WRIST_injury_risk', 'R_WRIST_exhaustion_rate', 'R_WRIST_rolling_exhaustion', 'R_WRIST_injury_risk', 'L_ELBOW_exhaustion_rate', 'L_ELBOW_rolling_exhaustion', 'L_ELBOW_injury_risk', 'R_ELBOW_exhaustion_rate', 'R_ELBOW_rolling_exhaustion', 'R_ELBOW_injury_risk', 'L_KNEE_exhaustion_rate', 'L_KNEE_rolling_exhaustion', 'L_KNEE_injury_risk', 'R_KNEE_exhaustion_rate', 'R_KNEE_rolling_exhaustion', 'R_KNEE_injury_risk', 'L_HIP_exhaustion_rate', 'L_HIP_rolling_exhaustion', 'L_HIP_injury_risk', 'R_HIP_exhaustion_rate', 'R_HIP_rolling_exhaustion', 'R_HIP_injury_risk']\n\n\nINFO: All required features and target variables are present.\nINFO: Saved top features for by_trial_exhaustion_score to ..\\..\\data\\Deep_Learning_Final\\by_trial_exhaustion_score_model_feature_list.pkl: ['exhaustion_lag1', 'rolling_hr_mean', 'rolling_exhaustion', 'ema_exhaustion', 'wrist_power_ratio', 'simulated_HR', 'energy_acceleration', 'joint_energy', 'joint_power', '5thfinger_power_ratio']\nINFO: Saved top features for injury_risk to ..\\..\\data\\Deep_Learning_Final\\injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'ema_exhaustion', '5thfinger_power_ratio', 'exhaustion_lag1', 'simulated_HR', '1stfinger_asymmetry', 'knee_asymmetry', 'hip_asymmetry', 'knee_power_ratio']\nINFO: Saved top features for L_ANKLE_injury_risk to ..\\..\\data\\Deep_Learning_Final\\L_ANKLE_injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'ema_exhaustion', 'rolling_hr_mean', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM', 'exhaustion_lag1', 'L_ANKLE_ROM_deviation', 'R_SHOULDER_ROM', 'L_ANKLE_ROM', 'L_SHOULDER_ROM']\nINFO: Saved top features for R_ANKLE_injury_risk to ..\\..\\data\\Deep_Learning_Final\\R_ANKLE_injury_risk_model_feature_list.pkl: ['ema_exhaustion', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'ankle_asymmetry', 'rolling_hr_mean', '1stfinger_power_ratio', 'L_HIP_ROM', 'knee_asymmetry']\nINFO: Saved top features for L_WRIST_injury_risk to ..\\..\\data\\Deep_Learning_Final\\L_WRIST_injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'exhaustion_lag1', 'ema_exhaustion', 'power_avg_5', 'energy_acceleration', 'hip_asymmetry', 'knee_power_ratio', 'ankle_asymmetry', 'R_HIP_ROM']\nINFO: Saved top features for R_WRIST_injury_risk to ..\\..\\data\\Deep_Learning_Final\\R_WRIST_injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'simulated_HR', 'R_KNEE_ROM_deviation', 'power_avg_5', 'R_SHOULDER_ROM', 'joint_energy', 'knee_asymmetry', 'joint_power']\nINFO: Saved top features for L_ELBOW_injury_risk to ..\\..\\data\\Deep_Learning_Final\\L_ELBOW_injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'exhaustion_lag1', 'simulated_HR', 'ankle_asymmetry', 'rolling_hr_mean', '1stfinger_power_ratio', 'wrist_power_ratio', 'ema_exhaustion', 'energy_acceleration', 'L_HIP_ROM']\nINFO: Saved top features for R_ELBOW_injury_risk to ..\\..\\data\\Deep_Learning_Final\\R_ELBOW_injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'exhaustion_lag1', 'rolling_hr_mean', 'ema_exhaustion', 'simulated_HR', 'R_KNEE_ROM', 'knee_asymmetry', 'R_SHOULDER_ROM', 'power_avg_5', 'ankle_asymmetry']\nINFO: Saved top features for L_KNEE_injury_risk to ..\\..\\data\\Deep_Learning_Final\\L_KNEE_injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'ema_exhaustion', 'R_KNEE_ROM', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'simulated_HR', 'rolling_hr_mean', 'knee_asymmetry', 'L_ANKLE_ROM']\nINFO: Saved top features for R_KNEE_injury_risk to ..\\..\\data\\Deep_Learning_Final\\R_KNEE_injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM', 'L_SHOULDER_ROM', 'simulated_HR', 'knee_power_ratio', 'energy_acceleration']\nINFO: Saved top features for L_HIP_injury_risk to ..\\..\\data\\Deep_Learning_Final\\L_HIP_injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'ema_exhaustion', 'R_KNEE_ROM_deviation', 'exhaustion_lag1', 'R_KNEE_ROM', 'knee_asymmetry', 'rolling_hr_mean', 'simulated_HR', 'ankle_asymmetry', 'wrist_power_ratio']\nINFO: Saved top features for R_HIP_injury_risk to ..\\..\\data\\Deep_Learning_Final\\R_HIP_injury_risk_model_feature_list.pkl: ['rolling_exhaustion', 'exhaustion_lag1', 'ema_exhaustion', 'power_avg_5', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'energy_acceleration', 'rolling_hr_mean', 'knee_asymmetry', 'L_SHOULDER_ROM']\n\n\n\n=== Feature Analysis for Target: BY_TRIAL_EXHAUSTION_SCORE ===\nPermutation Top 10: ['exhaustion_lag1', 'rolling_hr_mean', 'ema_exhaustion', 'rolling_exhaustion', 'wrist_power_ratio', 'energy_acceleration', 'simulated_HR', '5thfinger_power_ratio', 'joint_power', 'elbow_power_ratio']\nRFE Selected Features: ['joint_energy', 'wrist_power_ratio', 'exhaustion_lag1', 'rolling_hr_mean', 'rolling_exhaustion']\nSHAP Top 10: ['exhaustion_lag1', 'rolling_hr_mean', 'rolling_exhaustion', 'ema_exhaustion', 'wrist_power_ratio', 'simulated_HR', 'energy_acceleration', 'joint_power', 'joint_energy', 'elbow_power_ratio']\nConsensus Top 10: ['exhaustion_lag1', 'rolling_hr_mean', 'rolling_exhaustion', 'ema_exhaustion', 'wrist_power_ratio', 'simulated_HR', 'energy_acceleration', 'joint_energy', 'joint_power', '5thfinger_power_ratio']\n\n=== Feature Analysis for Target: INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'ema_exhaustion', '5thfinger_power_ratio', 'simulated_HR', 'hip_asymmetry', 'exhaustion_lag1', 'knee_asymmetry', '1stfinger_asymmetry', 'joint_energy', 'ankle_power_ratio']\nRFE Selected Features: ['5thfinger_power_ratio', 'exhaustion_lag1', 'time_since_start', 'ema_exhaustion', 'rolling_exhaustion']\nSHAP Top 10: ['rolling_exhaustion', 'time_since_start', 'ema_exhaustion', 'exhaustion_lag1', '5thfinger_power_ratio', 'simulated_HR', 'elbow_power_ratio', 'R_SHOULDER_ROM', 'L_KNEE_ROM_deviation', 'R_HIP_ROM']\nConsensus Top 10: ['rolling_exhaustion', 'ema_exhaustion', '5thfinger_power_ratio', 'exhaustion_lag1', 'simulated_HR', '1stfinger_asymmetry', 'knee_asymmetry', 'time_since_start', 'hip_asymmetry', 'knee_power_ratio']\n\n=== Feature Analysis for Target: L_ANKLE_INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'R_KNEE_ROM_deviation', 'ema_exhaustion', 'R_KNEE_ROM', 'rolling_hr_mean', 'exhaustion_lag1', 'L_ANKLE_ROM', 'R_SHOULDER_ROM', 'L_ANKLE_ROM_deviation', 'L_SHOULDER_ROM']\nRFE Selected Features: ['R_KNEE_ROM', 'rolling_hr_mean', 'time_since_start', 'ema_exhaustion', 'rolling_exhaustion']\nSHAP Top 10: ['rolling_hr_mean', 'ema_exhaustion', 'rolling_exhaustion', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM', 'time_since_start', 'R_ANKLE_ROM', 'R_ANKLE_ROM_deviation', 'exhaustion_lag1', 'L_ANKLE_ROM_deviation']\nConsensus Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'rolling_hr_mean', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM', 'exhaustion_lag1', 'L_ANKLE_ROM_deviation', 'R_SHOULDER_ROM', 'L_ANKLE_ROM', 'L_SHOULDER_ROM']\n\n=== Feature Analysis for Target: R_ANKLE_INJURY_RISK ===\nPermutation Top 10: ['ema_exhaustion', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'knee_asymmetry', 'wrist_power_ratio', 'ankle_asymmetry', '1stfinger_power_ratio', 'rolling_hr_mean', 'elbow_asymmetry', 'energy_acceleration']\nRFE Selected Features: ['R_KNEE_ROM', 'R_ANKLE_ROM', 'exhaustion_lag1', 'time_since_start', 'ema_exhaustion']\nSHAP Top 10: ['ema_exhaustion', 'exhaustion_lag1', 'time_since_start', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'rolling_exhaustion', 'L_SHOULDER_ROM', 'simulated_HR', 'rolling_hr_mean', 'L_ANKLE_ROM_deviation']\nConsensus Top 10: ['ema_exhaustion', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'ankle_asymmetry', 'time_since_start', 'rolling_hr_mean', '1stfinger_power_ratio', 'L_HIP_ROM', 'R_KNEE_ROM', 'knee_asymmetry']\n\n=== Feature Analysis for Target: L_WRIST_INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'power_avg_5', '5thfinger_power_ratio', 'ankle_asymmetry', 'knee_power_ratio', 'energy_acceleration', 'ankle_power_ratio', 'elbow_asymmetry']\nRFE Selected Features: ['L_KNEE_ROM_deviation', 'exhaustion_lag1', 'power_avg_5', 'time_since_start', 'rolling_exhaustion']\nSHAP Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'time_since_start', 'exhaustion_lag1', 'power_avg_5', 'hip_asymmetry', 'ankle_power_ratio', 'energy_acceleration', 'R_HIP_ROM', 'R_ANKLE_ROM']\nConsensus Top 10: ['rolling_exhaustion', 'exhaustion_lag1', 'ema_exhaustion', 'power_avg_5', 'energy_acceleration', 'hip_asymmetry', 'knee_power_ratio', 'ankle_asymmetry', 'R_HIP_ROM', 'time_since_start']\n\n=== Feature Analysis for Target: R_WRIST_INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'simulated_HR', 'R_KNEE_ROM_deviation', 'knee_asymmetry', 'power_avg_5', 'joint_power', 'R_KNEE_ROM', 'R_SHOULDER_ROM']\nRFE Selected Features: ['exhaustion_lag1', 'time_since_start', 'ema_exhaustion', 'rolling_exhaustion', 'simulated_HR']\nSHAP Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'time_since_start', 'simulated_HR', 'power_avg_5', 'L_HIP_ROM', 'R_SHOULDER_ROM', 'joint_power', 'R_KNEE_ROM_deviation']\nConsensus Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'simulated_HR', 'R_KNEE_ROM_deviation', 'power_avg_5', 'R_SHOULDER_ROM', 'joint_energy', 'knee_asymmetry', 'joint_power']\n\n=== Feature Analysis for Target: L_ELBOW_INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'exhaustion_lag1', 'rolling_hr_mean', 'ankle_asymmetry', 'simulated_HR', 'energy_acceleration', '1stfinger_power_ratio', 'wrist_power_ratio', '5thfinger_power_ratio', 'R_SHOULDER_ROM']\nRFE Selected Features: ['L_HIP_ROM', 'R_ANKLE_ROM_deviation', 'exhaustion_lag1', 'time_since_start', 'rolling_exhaustion']\nSHAP Top 10: ['rolling_exhaustion', 'time_since_start', 'exhaustion_lag1', 'rolling_hr_mean', 'simulated_HR', 'ankle_asymmetry', 'ema_exhaustion', 'wrist_power_ratio', 'L_HIP_ROM', 'L_KNEE_ROM_deviation']\nConsensus Top 10: ['rolling_exhaustion', 'exhaustion_lag1', 'simulated_HR', 'ankle_asymmetry', 'rolling_hr_mean', '1stfinger_power_ratio', 'wrist_power_ratio', 'ema_exhaustion', 'energy_acceleration', 'L_HIP_ROM']\n\n=== Feature Analysis for Target: R_ELBOW_INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'exhaustion_lag1', 'rolling_hr_mean', 'ema_exhaustion', 'simulated_HR', 'knee_asymmetry', 'R_SHOULDER_ROM', 'ankle_asymmetry', 'R_KNEE_ROM_deviation', 'power_avg_5']\nRFE Selected Features: ['exhaustion_lag1', 'rolling_hr_mean', 'time_since_start', 'ema_exhaustion', 'rolling_exhaustion']\nSHAP Top 10: ['rolling_exhaustion', 'time_since_start', 'exhaustion_lag1', 'ema_exhaustion', 'rolling_hr_mean', 'simulated_HR', 'R_HIP_ROM', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'power_avg_5']\nConsensus Top 10: ['rolling_exhaustion', 'exhaustion_lag1', 'rolling_hr_mean', 'ema_exhaustion', 'simulated_HR', 'R_KNEE_ROM', 'knee_asymmetry', 'R_SHOULDER_ROM', 'power_avg_5', 'ankle_asymmetry']\n\n=== Feature Analysis for Target: L_KNEE_INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'simulated_HR', 'exhaustion_lag1', 'rolling_hr_mean', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'hip_asymmetry', 'ankle_asymmetry', 'L_ANKLE_ROM_deviation']\nRFE Selected Features: ['R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'exhaustion_lag1', 'time_since_start', 'rolling_exhaustion']\nSHAP Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'exhaustion_lag1', 'rolling_hr_mean', 'time_since_start', 'simulated_HR', 'knee_asymmetry', 'R_HIP_ROM']\nConsensus Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'R_KNEE_ROM', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'simulated_HR', 'rolling_hr_mean', 'knee_asymmetry', 'time_since_start', 'L_ANKLE_ROM']\n\n=== Feature Analysis for Target: R_KNEE_INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'simulated_HR', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'knee_asymmetry', 'L_SHOULDER_ROM', 'knee_power_ratio', 'energy_acceleration']\nRFE Selected Features: ['joint_power', 'R_KNEE_ROM_deviation', 'time_since_start', 'ema_exhaustion', 'rolling_exhaustion']\nSHAP Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'simulated_HR', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'time_since_start', 'R_KNEE_ROM', 'joint_power', 'joint_energy', 'L_SHOULDER_ROM']\nConsensus Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM', 'L_SHOULDER_ROM', 'simulated_HR', 'knee_power_ratio', 'time_since_start', 'energy_acceleration']\n\n=== Feature Analysis for Target: L_HIP_INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'knee_asymmetry', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'ankle_asymmetry', 'rolling_hr_mean', '5thfinger_power_ratio', 'simulated_HR']\nRFE Selected Features: ['R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'exhaustion_lag1', 'time_since_start', 'rolling_exhaustion']\nSHAP Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'R_KNEE_ROM_deviation', 'time_since_start', 'R_KNEE_ROM', 'exhaustion_lag1', 'knee_asymmetry', 'rolling_hr_mean', 'simulated_HR', 'energy_acceleration']\nConsensus Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'R_KNEE_ROM_deviation', 'exhaustion_lag1', 'R_KNEE_ROM', 'knee_asymmetry', 'rolling_hr_mean', 'simulated_HR', 'ankle_asymmetry', 'wrist_power_ratio']\n\n=== Feature Analysis for Target: R_HIP_INJURY_RISK ===\nPermutation Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'power_avg_5', 'ankle_asymmetry', '1stfinger_power_ratio', 'energy_acceleration', 'rolling_hr_mean', 'R_KNEE_ROM', 'simulated_HR']\nRFE Selected Features: ['R_KNEE_ROM_deviation', 'exhaustion_lag1', 'power_avg_5', 'time_since_start', 'rolling_exhaustion']\nSHAP Top 10: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'time_since_start', 'power_avg_5', 'energy_acceleration', 'rolling_hr_mean', 'knee_asymmetry']\nConsensus Top 10: ['rolling_exhaustion', 'exhaustion_lag1', 'ema_exhaustion', 'power_avg_5', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'energy_acceleration', 'rolling_hr_mean', 'knee_asymmetry', 'L_SHOULDER_ROM']\n\n\nINFO: Aggregated top features for joint ANKLE: ['ema_exhaustion', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'rolling_exhaustion', 'exhaustion_lag1', 'rolling_hr_mean', 'ankle_asymmetry', 'R_SHOULDER_ROM', 'L_HIP_ROM']\nINFO: Aggregated top features for joint ANKLE: ['ema_exhaustion', 'R_KNEE_ROM', 'R_KNEE_ROM_deviation', 'rolling_exhaustion', 'exhaustion_lag1', 'rolling_hr_mean', 'ankle_asymmetry', 'R_SHOULDER_ROM', 'L_HIP_ROM']\nINFO: Saved aggregated feature importance for joint ANKLE to ..\\..\\data\\Deep_Learning_Final\\ANKLE_aggregated_feature_importance.pkl\nINFO: Aggregated top features for joint WRIST: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'power_avg_5', 'R_KNEE_ROM_deviation', 'simulated_HR', 'R_SHOULDER_ROM', 'energy_acceleration', 'hip_asymmetry']\nINFO: Aggregated top features for joint WRIST: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'power_avg_5', 'R_KNEE_ROM_deviation', 'simulated_HR', 'R_SHOULDER_ROM', 'energy_acceleration', 'hip_asymmetry']\nINFO: Saved aggregated feature importance for joint WRIST to ..\\..\\data\\Deep_Learning_Final\\WRIST_aggregated_feature_importance.pkl\nINFO: Aggregated top features for joint ELBOW: ['rolling_exhaustion', 'exhaustion_lag1', 'ema_exhaustion', 'simulated_HR', 'rolling_hr_mean', 'ankle_asymmetry', 'energy_acceleration', 'wrist_power_ratio', 'R_SHOULDER_ROM']\nINFO: Aggregated top features for joint ELBOW: ['rolling_exhaustion', 'exhaustion_lag1', 'ema_exhaustion', 'simulated_HR', 'rolling_hr_mean', 'ankle_asymmetry', 'energy_acceleration', 'wrist_power_ratio', 'R_SHOULDER_ROM']\nINFO: Saved aggregated feature importance for joint ELBOW to ..\\..\\data\\Deep_Learning_Final\\ELBOW_aggregated_feature_importance.pkl\nINFO: Aggregated top features for joint KNEE: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM', 'simulated_HR', 'L_SHOULDER_ROM', 'rolling_hr_mean', 'knee_asymmetry']\nINFO: Aggregated top features for joint KNEE: ['rolling_exhaustion', 'ema_exhaustion', 'exhaustion_lag1', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM', 'simulated_HR', 'L_SHOULDER_ROM', 'rolling_hr_mean', 'knee_asymmetry']\nINFO: Saved aggregated feature importance for joint KNEE to ..\\..\\data\\Deep_Learning_Final\\KNEE_aggregated_feature_importance.pkl\nINFO: Aggregated top features for joint HIP: ['rolling_exhaustion', 'exhaustion_lag1', 'ema_exhaustion', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM', 'power_avg_5', 'knee_asymmetry', 'rolling_hr_mean', 'simulated_HR', 'L_SHOULDER_ROM']\nINFO: Aggregated top features for joint HIP: ['rolling_exhaustion', 'exhaustion_lag1', 'ema_exhaustion', 'R_KNEE_ROM_deviation', 'R_KNEE_ROM', 'power_avg_5', 'knee_asymmetry', 'rolling_hr_mean', 'simulated_HR', 'L_SHOULDER_ROM']\nINFO: Saved aggregated feature importance for joint HIP to ..\\..\\data\\Deep_Learning_Final\\HIP_aggregated_feature_importance.pkl\n\n\n\n\nPreprocessing and Split (ensure that the preprocessing is correctly occuring to the right)\n\nimport numpy as np\nimport pandas as pd\nimport json\nimport sys\nimport logging\nfrom pathlib import Path\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    mean_absolute_error, r2_score, accuracy_score,\n    precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# ==================== UTILS ====================\ndef load_top_features(target, feature_dir=\"feature_lists\"):\n    \"\"\"\n    Loads the saved feature list for a specific target variable.\n    \n    Parameters:\n      - target (str): Target variable name.\n      - feature_dir (str): Directory containing feature lists.\n    \n    Returns:\n      - List of feature names.\n    \"\"\"\n    filename = Path(feature_dir) / f\"{target}_model_feature_list.pkl\"\n    \n    try:\n        features = pd.read_pickle(filename)\n        logging.info(f\"Loaded {len(features)} features for {target}\")\n        \n        # Verify features exist in data (assumes 'data' is already loaded in the global scope)\n        missing = [f for f in features if f not in data.columns]\n        if missing:\n            logging.error(f\"Missing features from {target} list: {missing}\")\n            sys.exit(1)\n            \n        return features\n    \n    except FileNotFoundError:\n        logging.error(f\"No feature list found for {target} at {filename}\")\n        sys.exit(1)\n        \ndef temporal_train_test_split(data, test_size=0.2):\n    \"\"\"Time-based split maintaining temporal order\"\"\"\n    split_idx = int(len(data) * (1 - test_size))\n    train_data = data.iloc[:split_idx]\n    test_data = data.iloc[split_idx:]\n    logging.info(f\"Performed temporal train-test split with test size = {test_size}\")\n    logging.info(f\"Training data shape: {train_data.shape}, Testing data shape: {test_data.shape}\")\n    return train_data, test_data\n\ndef scale_features(X_train, X_test):\n    \"\"\"\n    Scales features using StandardScaler.\n    \"\"\"\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    logging.info(\"Features have been scaled using StandardScaler.\")\n    return X_train_scaled, X_test_scaled, scaler\n\ndef create_sequences(X, y, timesteps):\n    \"\"\"\n    Creates sequences of data for LSTM input.\n    \"\"\"\n    X_seq, y_seq = [], []\n    for i in range(timesteps, len(X)):\n        X_seq.append(X[i-timesteps:i])\n        y_seq.append(y[i])\n    X_seq = np.array(X_seq)\n    y_seq = np.array(y_seq)\n    logging.info(f\"Created LSTM sequences: {X_seq.shape}, {y_seq.shape}\")\n    return X_seq, y_seq\n# ==================== TRAINING FUNCTIONS ====================\n\ndef train_exhaustion_model(train_data, test_data, features, timesteps, \n                           epochs=50, batch_size=32, early_stop_patience=5,\n                           num_lstm_layers=1, lstm_units=64, dropout_rate=0.2,\n                           dense_units=1, dense_activation=None):\n    \"\"\"\n    Trains the overall exhaustion model (regression) with a separate target scaler.\n\n    Parameters:\n      - train_data (DataFrame): Training set.\n      - test_data (DataFrame): Testing set.\n      - features (list): List of feature column names for exhaustion.\n      - timesteps (int): Number of past observations to include in each sequence.\n      - epochs (int): Number of training epochs.\n      - batch_size (int): Batch size for training.\n      - early_stop_patience (int): Patience for EarlyStopping callback.\n      - num_lstm_layers (int): Number of LSTM layers in the model.\n      - lstm_units (int): Number of units in each LSTM layer.\n      - dropout_rate (float): Dropout rate applied after each LSTM layer.\n      - dense_units (int): Number of units in the final Dense layer.\n      - dense_activation (str or None): Activation function for the Dense layer.\n      \n    Returns:\n      - model_exhaustion: Trained Keras model.\n      - scaler_exhaustion: Fitted scaler for the features.\n      - target_scaler: Fitted scaler for the target values.\n      - X_lstm_exhaustion_val, y_lstm_exhaustion_val: Validation sequences (targets are scaled).\n    \"\"\"\n    # Extract features and target from training and testing data\n    X_train = train_data[features].values\n    y_train = train_data['by_trial_exhaustion_score'].values\n    X_test = test_data[features].values\n    y_test = test_data['by_trial_exhaustion_score'].values\n\n    # Scale features using the existing helper function\n    X_train_scaled, X_test_scaled, scaler_exhaustion = scale_features(X_train, X_test)\n    \n    # ---- New: Scale the target (exhaustion scores) separately ----\n    from sklearn.preprocessing import StandardScaler\n    target_scaler = StandardScaler()\n    # Reshape y to 2D arrays for StandardScaler\n    y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1))\n    y_test_scaled = target_scaler.transform(y_test.reshape(-1, 1))\n    # ------------------------------------------------------------------\n\n    # Create sequences for LSTM input using the scaled features and scaled target values\n    X_lstm, y_lstm = create_sequences(X_train_scaled, y_train_scaled, timesteps)\n    X_lstm_val, y_lstm_val = create_sequences(X_test_scaled, y_test_scaled, timesteps)\n\n    # ---- Model Construction using an explicit Input layer and architecture hyperparameters ----\n    from tensorflow.keras import Input\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import LSTM, Dropout, Dense\n\n    model_exhaustion = Sequential()\n    # Define the input shape\n    model_exhaustion.add(Input(shape=(X_lstm.shape[1], X_lstm.shape[2])))\n    # Add LSTM layers with dropout (all but last LSTM layer return sequences)\n    for i in range(num_lstm_layers):\n        return_seq = True if i &lt; num_lstm_layers - 1 else False\n        model_exhaustion.add(LSTM(lstm_units, return_sequences=return_seq))\n        model_exhaustion.add(Dropout(dropout_rate))\n    # Final Dense layer for output (for regression, no activation by default)\n    model_exhaustion.add(Dense(dense_units, activation=dense_activation))\n    # ----------------------------------------------------------------------------------------------\n\n    model_exhaustion.compile(optimizer='adam', loss='mse')\n\n    from tensorflow.keras.callbacks import EarlyStopping\n    early_stop = EarlyStopping(monitor='val_loss', patience=early_stop_patience)\n\n    import logging\n    logging.info(\"Training overall exhaustion model...\")\n    model_exhaustion.fit(\n        X_lstm, y_lstm,\n        epochs=epochs, \n        batch_size=batch_size,\n        validation_data=(X_lstm_val, y_lstm_val),\n        callbacks=[early_stop]\n    )\n\n    # Return the model, the scaler for features, the separate target scaler, and validation sequences\n    return model_exhaustion, scaler_exhaustion, target_scaler, X_lstm_val, y_lstm_val\n\n\n\n\ndef train_injury_model(train_data, test_data, features, timesteps,\n                       epochs=50, batch_size=32,\n                       num_lstm_layers=1, lstm_units=64, dropout_rate=0.2,\n                       dense_units=1, dense_activation='sigmoid'):\n    \"\"\"\n    Trains the overall injury risk model.\n\n    Parameters:\n      - train_data (DataFrame): Training set.\n      - test_data (DataFrame): Testing set.\n      - features (list): List of feature column names for injury risk.\n      - timesteps (int): Number of past observations to include in each sequence.\n      - epochs (int): Number of training epochs.\n      - batch_size (int): Batch size for training.\n      - num_lstm_layers (int): Number of LSTM layers in the model.\n      - lstm_units (int): Number of units in each LSTM layer.\n      - dropout_rate (float): Dropout rate applied after each LSTM layer.\n      - dense_units (int): Number of units in the final Dense layer.\n      - dense_activation (str): Activation function for the Dense layer (default 'sigmoid' for classification).\n      \n    Returns:\n      - model_injury: Trained Keras model.\n      - scaler_injury: Fitted scaler for the features.\n      - X_lstm_injury_val, y_lstm_injury_val: Validation sequences.\n    \"\"\"\n    X_train = train_data[features].values\n    y_train = train_data['injury_risk'].values\n    X_test = test_data[features].values\n    y_test = test_data['injury_risk'].values\n\n    # Scale features\n    X_train_scaled, X_test_scaled, scaler_injury = scale_features(X_train, X_test)\n    # Create sequences for LSTM input\n    X_lstm, y_lstm = create_sequences(X_train_scaled, y_train, timesteps)\n    X_lstm_val, y_lstm_val = create_sequences(X_test_scaled, y_test, timesteps)\n\n    # ---- Updated Model Construction using an explicit Input layer and architecture hyperparameters ----\n    from tensorflow.keras import Input\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import LSTM, Dropout, Dense\n\n    model_injury = Sequential()\n    model_injury.add(Input(shape=(X_lstm.shape[1], X_lstm.shape[2])))\n    for i in range(num_lstm_layers):\n        return_seq = True if i &lt; num_lstm_layers - 1 else False\n        model_injury.add(LSTM(lstm_units, return_sequences=return_seq))\n        model_injury.add(Dropout(dropout_rate))\n    model_injury.add(Dense(dense_units, activation=dense_activation))\n    # ----------------------------------------------------------------------------------------------\n\n    model_injury.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    import logging\n    logging.info(\"Training overall injury risk model...\")\n    model_injury.fit(\n        X_lstm, y_lstm,\n        epochs=epochs, \n        batch_size=batch_size,\n        validation_data=(X_lstm_val, y_lstm_val)\n    )\n\n    return model_injury, scaler_injury, X_lstm_val, y_lstm_val\n# ==================== JOINT-SPECIFIC TRAINING FUNCTION ====================\n\n\n\ndef train_joint_models(train_data, test_data, joints, timesteps, feature_dir,\n                       epochs=50, batch_size=32,\n                       num_lstm_layers=1, lstm_units=64, dropout_rate=0.2,\n                       dense_units=1, dense_activation='sigmoid'):\n    \"\"\"\n    Trains injury risk models for multiple joints.\n\n    Parameters:\n      - train_data (DataFrame): Training set.\n      - test_data (DataFrame): Testing set.\n      - joints (list): List of joint names.\n      - timesteps (int): Number of past observations to include in each sequence.\n      - feature_dir (str): Directory containing feature lists.\n      - epochs (int): Number of training epochs.\n      - batch_size (int): Batch size for training.\n      - num_lstm_layers (int): Number of LSTM layers in the model.\n      - lstm_units (int): Number of units in each LSTM layer.\n      - dropout_rate (float): Dropout rate applied after each LSTM layer.\n      - dense_units (int): Number of units in the final Dense layer.\n      - dense_activation (str): Activation function for the Dense layer.\n      \n    Returns:\n      - joint_models (dict): Dictionary with joint model info.\n    \"\"\"\n    import logging\n    from tensorflow.keras import Input\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import LSTM, Dropout, Dense\n    joint_models = {}\n\n    for joint in joints:\n        for side in ['L', 'R']:\n            target_joint = f\"{side}_{joint}_injury_risk\"\n            logging.info(f\"Training model for {target_joint}...\")\n\n            joint_features = load_top_features(target_joint, feature_dir=feature_dir)\n\n            X_train_joint = train_data[joint_features].values\n            y_train_joint = train_data[target_joint].values\n            X_test_joint = test_data[joint_features].values\n            y_test_joint = test_data[target_joint].values\n\n            # Scale features for the joint-specific model\n            X_train_scaled, X_test_scaled, scaler_joint = scale_features(X_train_joint, X_test_joint)\n            # Create sequences for LSTM input\n            X_lstm, y_lstm = create_sequences(X_train_scaled, y_train_joint, timesteps)\n            X_lstm_val, y_lstm_val = create_sequences(X_test_scaled, y_test_joint, timesteps)\n\n            # ---- Updated Model Construction using an explicit Input layer and architecture hyperparameters ----\n            model_joint = Sequential()\n            model_joint.add(Input(shape=(X_lstm.shape[1], X_lstm.shape[2])))\n            for i in range(num_lstm_layers):\n                return_seq = True if i &lt; num_lstm_layers - 1 else False\n                model_joint.add(LSTM(lstm_units, return_sequences=return_seq))\n                model_joint.add(Dropout(dropout_rate))\n            model_joint.add(Dense(dense_units, activation=dense_activation))\n            # ----------------------------------------------------------------------------------------------\n\n            model_joint.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n            model_joint.fit(\n                X_lstm, y_lstm,\n                epochs=epochs, \n                batch_size=batch_size,\n                validation_data=(X_lstm_val, y_lstm_val)\n            )\n\n            joint_models[target_joint] = {\n                'model': model_joint,\n                'features': joint_features,\n                'scaler': scaler_joint\n            }\n\n    import json\n    with open(\"loaded_features.json\", \"w\") as f:\n        json.dump({target: info['features'] for target, info in joint_models.items()}, f, indent=4)\n    logging.info(\"Saved loaded features list for each joint model to 'loaded_features.json'.\")\n\n    return joint_models\n\n\n\n\n# ==================== FORECASTING FUNCTION ====================\n\ndef forecast_and_plot_exhaustion(model, test_data, forecast_features, scaler_exhaustion, target_scaler, timesteps, future_steps=0, title=\"Exhaustion Forecast\"):\n    \"\"\"\n    Generates predictions for the exhaustion target using multi-feature input.\n    \n    This function extracts the same features used during training (e.g. a 10-dimensional input),\n    scales them with the features scaler (scaler_exhaustion), builds forecasting sequences, makes predictions,\n    and finally inverse-transforms the predictions using the target scaler.\n    \n    Parameters:\n      - model: Trained exhaustion Keras model.\n      - test_data (DataFrame): The test DataFrame containing all features.\n      - forecast_features (list): List of feature names used for forecasting (e.g. features_exhaustion).\n      - scaler_exhaustion: Fitted StandardScaler used to scale the features.\n      - target_scaler: Fitted StandardScaler used to scale the target values.\n      - timesteps (int): Number of past observations to include in each sequence.\n      - future_steps (int): Number of future time steps to forecast.\n                          (Note: Future forecasting is approximate since it assumes constant features.)\n      - title (str): Plot title.\n    \"\"\"\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    # Extract multi-dimensional input from test data\n    X_forecast = test_data[forecast_features].values  # shape (n, num_features)\n    \n    # Scale the features using the features scaler\n    X_forecast_scaled = scaler_exhaustion.transform(X_forecast)\n    \n    # Create sequences for forecasting using a dummy y array (since only X is needed)\n    X_seq, _ = create_sequences(X_forecast_scaled, np.zeros(len(X_forecast_scaled)), timesteps)\n    \n    # Make predictions on the scaled sequences\n    predictions_scaled = model.predict(X_seq)\n    # Inverse-transform predictions using the target scaler\n    predictions = target_scaler.inverse_transform(predictions_scaled)\n    \n    forecast_predictions_inv = None\n    if future_steps &gt; 0:\n        # For additional future steps, we assume the features remain constant.\n        # WARNING: This is an approximation.\n        current_sequence = X_seq[-1].copy()  # shape: (timesteps, num_features)\n        forecast_predictions = []\n        for _ in range(future_steps):\n            next_pred = model.predict(current_sequence.reshape(1, timesteps, current_sequence.shape[1]))\n            forecast_predictions.append(next_pred[0, 0])\n            # Update sequence: drop the first row and append the last row (assumed constant)\n            new_row = current_sequence[-1, :].copy()\n            current_sequence = np.vstack([current_sequence[1:], new_row])\n        forecast_predictions = np.array(forecast_predictions).reshape(-1, 1)\n        forecast_predictions_inv = target_scaler.inverse_transform(forecast_predictions)\n    \n    # Plot actual exhaustion scores versus predictions\n    plt.figure(figsize=(10, 6))\n    actual = test_data['by_trial_exhaustion_score'].values\n    plt.plot(range(timesteps, len(actual)), actual[timesteps:], color='red', label='Actual')\n    plt.plot(range(timesteps, len(actual)), predictions, color='blue', label='Predicted')\n    if forecast_predictions_inv is not None:\n        future_x = list(range(len(actual), len(actual) + future_steps))\n        plt.plot(future_x, forecast_predictions_inv, color='green', linestyle='--', label='Forecast')\n    plt.title(title)\n    plt.xlabel('Time')\n    plt.ylabel('Exhaustion Score')\n    plt.legend()\n    plt.show()\n\n\ndef forecast_and_plot_injury(model, test_data, forecast_features, scaler_injury, timesteps, future_steps=0, title=\"Injury Risk Forecast\"):\n    \"\"\"\n    Generates predictions for the injury risk model using multi-feature input.\n    \n    This function extracts the injury features from the test data, scales them using scaler_injury,\n    builds forecasting sequences, and makes predictions. Since this is a classification model,\n    it outputs probability predictions. These probabilities (or rounded binary classes) are compared\n    to the actual injury risk (assumed to be 0 or 1).\n    \n    Parameters:\n      - model: Trained injury risk Keras model.\n      - test_data (DataFrame): The test DataFrame containing all features.\n      - forecast_features (list): List of feature names used for forecasting (e.g. features_injury).\n      - scaler_injury: Fitted StandardScaler used to scale the injury features.\n      - timesteps (int): Number of past observations to include in each sequence.\n      - future_steps (int): Number of future time steps to forecast.\n                          (For classification, future forecasting is less common.)\n      - title (str): Plot title.\n    \"\"\"\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    # Extract multi-dimensional input for injury risk from test data\n    X_forecast = test_data[forecast_features].values  # shape (n, num_features)\n    \n    # Scale the features using the injury features scaler\n    X_forecast_scaled = scaler_injury.transform(X_forecast)\n    \n    # Create sequences for forecasting (dummy y used, since only X is needed)\n    X_seq, _ = create_sequences(X_forecast_scaled, np.zeros(len(X_forecast_scaled)), timesteps)\n    \n    # Predict probabilities on the sequences\n    predictions_prob = model.predict(X_seq)\n    # Convert probabilities to binary predictions (threshold=0.5)\n    predictions_class = (predictions_prob &gt;= 0.5).astype(int)\n    \n    forecast_predictions = None\n    if future_steps &gt; 0:\n        # For future steps, we assume features remain constant (approximation)\n        current_sequence = X_seq[-1].copy()  # shape: (timesteps, num_features)\n        forecast_predictions = []\n        for _ in range(future_steps):\n            next_pred = model.predict(current_sequence.reshape(1, timesteps, current_sequence.shape[1]))\n            forecast_predictions.append((next_pred[0, 0] &gt;= 0.5).astype(int))\n            new_row = current_sequence[-1, :].copy()\n            current_sequence = np.vstack([current_sequence[1:], new_row])\n        forecast_predictions = np.array(forecast_predictions)\n    \n    # Plot the actual injury risk versus predicted probability (or binary prediction)\n    plt.figure(figsize=(10, 6))\n    actual = test_data['injury_risk'].values\n    # For plotting, we align the sequences starting at index 'timesteps'\n    plt.plot(range(timesteps, len(actual)), actual[timesteps:], color='red', label='Actual')\n    plt.plot(range(timesteps, len(actual)), predictions_prob, color='blue', label='Predicted Probability')\n    if forecast_predictions is not None:\n        future_x = list(range(len(actual), len(actual) + future_steps))\n        plt.plot(future_x, forecast_predictions, color='green', linestyle='--', label='Forecasted Class')\n    plt.title(title)\n    plt.xlabel('Time')\n    plt.ylabel('Injury Risk')\n    plt.legend()\n    plt.show()\n\n\ndef forecast_and_plot_joint(joint_models, test_data, timesteps, future_steps=0):\n    \"\"\"\n    Generates forecasts for each joint model using their corresponding features and scalers.\n    \n    For each joint model in the joint_models dictionary (returned by train_joint_models),\n    this function extracts the joint-specific features from test_data, scales them using the model's scaler,\n    builds sequences, obtains predictions (probabilities), converts them to binary predictions,\n    and then plots the actual joint injury risk versus predicted values.\n    \n    Parameters:\n      - joint_models (dict): Dictionary where each key is a joint target name and each value is a dict \n                             containing 'model', 'features', and 'scaler'.\n      - test_data (DataFrame): The test DataFrame containing all features.\n      - timesteps (int): Number of past observations to include in each sequence.\n      - future_steps (int): Number of future time steps to forecast (optional).\n    \"\"\"\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    for target_joint, info in joint_models.items():\n        model_joint = info['model']\n        joint_features = info['features']\n        scaler_joint = info['scaler']\n        \n        # Extract joint-specific features from test data\n        X_forecast = test_data[joint_features].values  # shape (n, num_features)\n        # Scale the features\n        X_forecast_scaled = scaler_joint.transform(X_forecast)\n        # Create sequences for forecasting (dummy y used)\n        X_seq, _ = create_sequences(X_forecast_scaled, np.zeros(len(X_forecast_scaled)), timesteps)\n        \n        # Predict probabilities and convert to binary predictions\n        predictions_prob = model_joint.predict(X_seq)\n        predictions_class = (predictions_prob &gt;= 0.5).astype(int)\n        \n        forecast_predictions = None\n        if future_steps &gt; 0:\n            # Approximate forecasting by assuming constant features\n            current_sequence = X_seq[-1].copy()  # shape: (timesteps, num_features)\n            forecast_predictions = []\n            for _ in range(future_steps):\n                next_pred = model_joint.predict(current_sequence.reshape(1, timesteps, current_sequence.shape[1]))\n                forecast_predictions.append((next_pred[0, 0] &gt;= 0.5).astype(int))\n                new_row = current_sequence[-1, :].copy()\n                current_sequence = np.vstack([current_sequence[1:], new_row])\n            forecast_predictions = np.array(forecast_predictions)\n        \n        # Plot for this joint model\n        plt.figure(figsize=(10, 6))\n        actual = test_data[target_joint].values\n        plt.plot(range(timesteps, len(actual)), actual[timesteps:], color='red', label='Actual')\n        plt.plot(range(timesteps, len(actual)), predictions_prob, color='blue', label='Predicted Probability')\n        if forecast_predictions is not None:\n            future_x = list(range(len(actual), len(actual) + future_steps))\n            plt.plot(future_x, forecast_predictions, color='green', linestyle='--', label='Forecasted Class')\n        plt.title(f\"Forecast for {target_joint}\")\n        plt.xlabel('Time')\n        plt.ylabel('Injury Risk')\n        plt.legend()\n        plt.show()\n\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n\ndef summarize_exhaustion_model(model, X_val, y_val, target_scaler):\n    \"\"\"\n    Generates evaluation metrics for the exhaustion (regression) model.\n    \"\"\"\n    preds_scaled = model.predict(X_val)\n    preds = target_scaler.inverse_transform(preds_scaled)\n    y_true = target_scaler.inverse_transform(y_val)\n    \n    mse = mean_squared_error(y_true, preds)\n    mae = mean_absolute_error(y_true, preds)\n    r2 = r2_score(y_true, preds)\n    \n    return {\"MSE\": mse, \"MAE\": mae, \"R2 Score\": r2}\n\ndef summarize_classification_model(model, X_val, y_val):\n    \"\"\"\n    Generates evaluation metrics for a classification model.\n    \"\"\"\n    preds_prob = model.predict(X_val)\n    preds_class = (preds_prob &gt;= 0.5).astype(int)\n    \n    accuracy = accuracy_score(y_val, preds_class)\n    precision = precision_score(y_val, preds_class, zero_division=0)\n    recall = recall_score(y_val, preds_class, zero_division=0)\n    f1 = f1_score(y_val, preds_class, zero_division=0)\n    \n    return {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1}\n\ndef summarize_joint_models(joint_models, test_data, timesteps):\n    \"\"\"\n    Computes evaluation metrics for each joint model.\n    \"\"\"\n    summaries = {}\n    for target_joint, info in joint_models.items():\n        model_joint = info['model']\n        joint_features = info['features']\n        scaler_joint = info['scaler']\n        \n        X_joint = test_data[joint_features].values\n        y_joint = test_data[target_joint].values\n        \n        X_joint_scaled = scaler_joint.transform(X_joint)\n        X_seq, y_seq = create_sequences(X_joint_scaled, y_joint, timesteps)\n        \n        metrics = summarize_classification_model(model_joint, X_seq, y_seq)\n        summaries[target_joint] = metrics\n    return summaries\n\ndef summarize_all_models(model_exhaustion, X_val_exh, y_val_exh, target_scaler,\n                         model_injury, X_val_injury, y_val_injury,\n                         joint_models, test_data, timesteps, output_dir):\n    \"\"\"\n    Combines summaries from the exhaustion, injury, and joint models into a table.\n    \"\"\"\n    summary_data = []\n    exh_metrics = summarize_exhaustion_model(model_exhaustion, X_val_exh, y_val_exh, target_scaler)\n    summary_data.append({\n        \"Model\": \"Exhaustion Model\",\n        \"Type\": \"Regression\",\n        \"MSE\": exh_metrics.get(\"MSE\"),\n        \"MAE\": exh_metrics.get(\"MAE\"),\n        \"R2 Score\": exh_metrics.get(\"R2 Score\"),\n        \"Accuracy\": None,\n        \"Precision\": None,\n        \"Recall\": None,\n        \"F1 Score\": None\n    })\n    \n    injury_metrics = summarize_classification_model(model_injury, X_val_injury, y_val_injury)\n    summary_data.append({\n        \"Model\": \"Injury Model\",\n        \"Type\": \"Classification\",\n        \"MSE\": None,\n        \"MAE\": None,\n        \"R2 Score\": None,\n        \"Accuracy\": injury_metrics.get(\"Accuracy\"),\n        \"Precision\": injury_metrics.get(\"Precision\"),\n        \"Recall\": injury_metrics.get(\"Recall\"),\n        \"F1 Score\": injury_metrics.get(\"F1 Score\")\n    })\n    \n    joint_summaries = summarize_joint_models(joint_models, test_data, timesteps)\n    for target_joint, metrics in joint_summaries.items():\n        summary_data.append({\n            \"Model\": target_joint,\n            \"Type\": \"Classification\",\n            \"MSE\": None,\n            \"MAE\": None,\n            \"R2 Score\": None,\n            \"Accuracy\": metrics.get(\"Accuracy\"),\n            \"Precision\": metrics.get(\"Precision\"),\n            \"Recall\": metrics.get(\"Recall\"),\n            \"F1 Score\": metrics.get(\"F1 Score\")\n        })\n    \n    summary_df = pd.DataFrame(summary_data)\n    # Save the summary dataframe to a CSV file.\n    output_dir = output_dir\n    summary_df.to_csv(output_dir, index=False)\n    logging.info(f\"Saved model summary dataframe to {output_dir}\")\n    return summary_df\n    \n    return summary_df\n\n\n\n\nif __name__ == \"__main__\":\n    import logging\n    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n\n    # Data Loading and Preparation\n    csv_path = \"../../data/processed/final_granular_dataset.csv\"\n    json_path = \"../../data/basketball/freethrow/participant_information.json\"\n    feature_dir = \"../../data/Deep_Learning_Final\"\n    output_dir = \"../../data/Deep_Learning_Final/all_models_summary.csv\"\n    data = load_data(csv_path, json_path)\n    data = prepare_joint_features(data)\n    data = feature_engineering(data)\n    data = data.copy()  # Defragment DataFrame\n\n    features_exhaustion = load_top_features('by_trial_exhaustion_score', feature_dir=feature_dir)\n    features_injury = load_top_features('injury_risk', feature_dir=feature_dir)\n\n    train_data, test_data = temporal_train_test_split(data, test_size=0.2)\n    timesteps = 5\n\n    # Hyperparameters (training and architecture) are defined as before...\n    hyperparams = {\n        \"epochs\": 500,\n        \"batch_size\": 32,\n        \"early_stop_patience\": 5\n    }\n    arch_exhaustion = {\n        \"num_lstm_layers\": 1,\n        \"lstm_units\": 64,\n        \"dropout_rate\": 0.2,\n        \"dense_units\": 1,\n        \"dense_activation\": None\n    }\n    arch_injury = {\n        \"num_lstm_layers\": 1,\n        \"lstm_units\": 64,\n        \"dropout_rate\": 0.2,\n        \"dense_units\": 1,\n        \"dense_activation\": \"sigmoid\"\n    }\n\n    # Train models\n    model_exhaustion, scaler_exhaustion, target_scaler, X_val_exh, y_val_exh = train_exhaustion_model(\n        train_data, test_data, features_exhaustion, timesteps,\n        epochs=hyperparams[\"epochs\"],\n        batch_size=hyperparams[\"batch_size\"],\n        early_stop_patience=hyperparams[\"early_stop_patience\"],\n        num_lstm_layers=arch_exhaustion[\"num_lstm_layers\"],\n        lstm_units=arch_exhaustion[\"lstm_units\"],\n        dropout_rate=arch_exhaustion[\"dropout_rate\"],\n        dense_units=arch_exhaustion[\"dense_units\"],\n        dense_activation=arch_exhaustion[\"dense_activation\"]\n    )\n\n    model_injury, scaler_injury, X_val_injury, y_val_injury = train_injury_model(\n        train_data, test_data, features_injury, timesteps,\n        epochs=hyperparams[\"epochs\"],\n        batch_size=hyperparams[\"batch_size\"],\n        num_lstm_layers=arch_injury[\"num_lstm_layers\"],\n        lstm_units=arch_injury[\"lstm_units\"],\n        dropout_rate=arch_injury[\"dropout_rate\"],\n        dense_units=arch_injury[\"dense_units\"],\n        dense_activation=arch_injury[\"dense_activation\"]\n    )\n\n    joints = ['ANKLE', 'WRIST', 'ELBOW', 'KNEE', 'HIP']\n    joint_models = train_joint_models(\n        train_data, test_data, joints, timesteps, feature_dir,\n        epochs=hyperparams[\"epochs\"],\n        batch_size=hyperparams[\"batch_size\"],\n        num_lstm_layers=arch_injury[\"num_lstm_layers\"],\n        lstm_units=arch_injury[\"lstm_units\"],\n        dropout_rate=arch_injury[\"dropout_rate\"],\n        dense_units=arch_injury[\"dense_units\"],\n        dense_activation=arch_injury[\"dense_activation\"]\n    )\n\n    # ---- Forecasting for each model type ----\n\n    # Forecast for Exhaustion (Regression)\n    forecast_and_plot_exhaustion(\n        model=model_exhaustion,\n        test_data=test_data,\n        forecast_features=features_exhaustion,  # same features as used in training\n        scaler_exhaustion=scaler_exhaustion,\n        target_scaler=target_scaler,\n        timesteps=timesteps,\n        future_steps=50,\n        title=\"Overall Exhaustion Model Forecast\"\n    )\n\n    # Forecast for Injury Risk (Classification)\n    forecast_and_plot_injury(\n        model=model_injury,\n        test_data=test_data,\n        forecast_features=features_injury,  # features used for injury risk\n        scaler_injury=scaler_injury,\n        timesteps=timesteps,\n        future_steps=50,\n        title=\"Overall Injury Risk Forecast\"\n    )\n\n    # Forecast for Joint Models (Classification)\n    forecast_and_plot_joint(\n        joint_models=joint_models,\n        test_data=test_data,\n        timesteps=timesteps,\n        future_steps=50\n    )\n\n    # ----- NEW: Summarize Testing Results from the Different Models ----- #\n    summary_df = summarize_all_models(\n        model_exhaustion, X_val_exh, y_val_exh, target_scaler,\n        model_injury, X_val_injury, y_val_injury,\n        joint_models, test_data, timesteps, output_dir\n    )\n    print(\"=== Model Summaries ===\")\n    print(summary_df)\n\n\n\n    \n\nINFO: Loaded data from ../../data/processed/final_granular_dataset.csv with shape (16047, 214)\nINFO: Added 'participant_id' column with value 'P0001'\nINFO: Loaded participant information from ../../data/basketball/freethrow/participant_information.json\nINFO: Merged participant data. New shape: (16047, 217)\nINFO: Step [load_data] completed.\nINFO: Step [calculate_joint_angles] completed.\nINFO: Renamed participant anthropometrics.\nINFO: Identified 15 joint energy and 14 joint power columns.\nINFO: Created aggregated 'joint_energy' and 'joint_power'.\nINFO: Created 'energy_acceleration' as derivative of joint_energy over time.\nINFO: Created 'ankle_power_ratio' feature comparing left to right ankle ongoing power.\nINFO: Created asymmetry feature: hip_asymmetry\nINFO: Created asymmetry feature: ankle_asymmetry\nINFO: Created asymmetry feature: wrist_asymmetry\nINFO: Created asymmetry feature: elbow_asymmetry\nINFO: Created asymmetry feature: knee_asymmetry\nINFO: Created asymmetry feature: 1stfinger_asymmetry\nINFO: Created asymmetry feature: 5thfinger_asymmetry\nINFO: Created power ratio feature: hip_power_ratio using columns L_HIP_ongoing_power and R_HIP_ongoing_power\nINFO: Created power ratio feature: ankle_power_ratio using columns L_ANKLE_ongoing_power and R_ANKLE_ongoing_power\nINFO: Created power ratio feature: wrist_power_ratio using columns L_WRIST_ongoing_power and R_WRIST_ongoing_power\nINFO: Created power ratio feature: elbow_power_ratio using columns L_ELBOW_ongoing_power and R_ELBOW_ongoing_power\nINFO: Created power ratio feature: knee_power_ratio using columns L_KNEE_ongoing_power and R_KNEE_ongoing_power\nINFO: Created power ratio feature: 1stfinger_power_ratio using columns L_1STFINGER_ongoing_power and R_1STFINGER_ongoing_power\nINFO: Created power ratio feature: 5thfinger_power_ratio using columns L_5THFINGER_ongoing_power and R_5THFINGER_ongoing_power\nINFO: Computed ROM for L KNEE as L_KNEE_ROM\nINFO: Computed ROM deviation for L KNEE as L_KNEE_ROM_deviation\nINFO: Created binary flag for L KNEE ROM extremes: L_KNEE_ROM_extreme\nINFO: Computed ROM for R KNEE as R_KNEE_ROM\nINFO: Computed ROM deviation for R KNEE as R_KNEE_ROM_deviation\nINFO: Created binary flag for R KNEE ROM extremes: R_KNEE_ROM_extreme\nINFO: Computed ROM for L SHOULDER as L_SHOULDER_ROM\nINFO: Computed ROM deviation for L SHOULDER as L_SHOULDER_ROM_deviation\nINFO: Created binary flag for L SHOULDER ROM extremes: L_SHOULDER_ROM_extreme\nINFO: Computed ROM for R SHOULDER as R_SHOULDER_ROM\nINFO: Computed ROM deviation for R SHOULDER as R_SHOULDER_ROM_deviation\nINFO: Created binary flag for R SHOULDER ROM extremes: R_SHOULDER_ROM_extreme\nINFO: Computed ROM for L HIP as L_HIP_ROM\nINFO: Computed ROM deviation for L HIP as L_HIP_ROM_deviation\nINFO: Created binary flag for L HIP ROM extremes: L_HIP_ROM_extreme\nINFO: Computed ROM for R HIP as R_HIP_ROM\nINFO: Computed ROM deviation for R HIP as R_HIP_ROM_deviation\nINFO: Created binary flag for R HIP ROM extremes: R_HIP_ROM_extreme\nINFO: Computed ROM for L ANKLE as L_ANKLE_ROM\nINFO: Computed ROM deviation for L ANKLE as L_ANKLE_ROM_deviation\nINFO: Created binary flag for L ANKLE ROM extremes: L_ANKLE_ROM_extreme\nINFO: Computed ROM for R ANKLE as R_ANKLE_ROM\nINFO: Computed ROM deviation for R ANKLE as R_ANKLE_ROM_deviation\nINFO: Created binary flag for R ANKLE ROM extremes: R_ANKLE_ROM_extreme\nINFO: Angle column 'L_WRIST_angle' not found; skipping ROM metrics for L WRIST.\nINFO: Angle column 'R_WRIST_angle' not found; skipping ROM metrics for R WRIST.\nINFO: Sorted data by 'participant_id' and 'continuous_frame_time'.\nINFO: Created 'exhaustion_rate' feature.\nINFO: Created 'simulated_HR' feature.\nINFO: Step [prepare_joint_features] completed.\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:394: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data[motion_cols] = data[motion_cols].fillna(method='ffill').fillna(0)\nINFO: Created 'rolling_energy_std' with sample: [0.0, 0.6225242794725895, 0.592331668013902, 0.5469698974921113, 0.5031647476376774, 0.0346469804150002, 0.05501279562072104, 0.06384083445684284, 0.05698938811919827, 0.039917330417864196]\nINFO: Created 'rolling_energy_std' with window 5.\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_rolling_exhaustion'] = data[score_col].rolling(rolling_window, min_periods=1).sum()\n\n\nJoint energy columns:  ['L_ANKLE_energy', 'R_ANKLE_energy', 'L_KNEE_energy', 'R_KNEE_energy', 'L_HIP_energy', 'R_HIP_energy', 'L_ELBOW_energy', 'R_ELBOW_energy', 'L_WRIST_energy', 'R_WRIST_energy', 'L_1STFINGER_energy', 'R_1STFINGER_energy', 'L_5THFINGER_energy', 'R_5THFINGER_energy', 'total_energy']\nJoint power columns:  ['L_ANKLE_ongoing_power', 'R_ANKLE_ongoing_power', 'L_KNEE_ongoing_power', 'R_KNEE_ongoing_power', 'L_HIP_ongoing_power', 'R_HIP_ongoing_power', 'L_ELBOW_ongoing_power', 'R_ELBOW_ongoing_power', 'L_WRIST_ongoing_power', 'R_WRIST_ongoing_power', 'L_1STFINGER_ongoing_power', 'L_5THFINGER_ongoing_power', 'R_1STFINGER_ongoing_power', 'R_5THFINGER_ongoing_power']\nAll angle columns:  ['entry_angle', 'elbow_angle', 'wrist_angle', 'knee_angle', 'initial_release_angle', 'calculated_release_angle', 'angle_difference', 'optimal_release_angle', 'L_SHOULDER_angle', 'R_SHOULDER_angle', 'L_HIP_angle', 'R_HIP_angle', 'L_KNEE_angle', 'R_KNEE_angle', 'L_ANKLE_angle', 'R_ANKLE_angle']\nprint all the columns with by_trial_exhaustion_score:  ['by_trial_exhaustion_score', 'L_ANKLE_energy_by_trial_exhaustion_score', 'R_ANKLE_energy_by_trial_exhaustion_score', 'L_KNEE_energy_by_trial_exhaustion_score', 'R_KNEE_energy_by_trial_exhaustion_score', 'L_HIP_energy_by_trial_exhaustion_score', 'R_HIP_energy_by_trial_exhaustion_score', 'L_ELBOW_energy_by_trial_exhaustion_score', 'R_ELBOW_energy_by_trial_exhaustion_score', 'L_WRIST_energy_by_trial_exhaustion_score', 'R_WRIST_energy_by_trial_exhaustion_score', 'L_1STFINGER_energy_by_trial_exhaustion_score', 'R_1STFINGER_energy_by_trial_exhaustion_score', 'L_5THFINGER_energy_by_trial_exhaustion_score', 'R_5THFINGER_energy_by_trial_exhaustion_score']\n\n\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:447: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_injury_risk'] = (rolling_series &gt; safe_expanding_quantile(rolling_series)).astype(int)\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:442: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_exhaustion_rate'] = data[score_col].diff() / dt\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:443: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_rolling_exhaustion'] = data[score_col].rolling(rolling_window, min_periods=1).sum()\nC:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_28908\\333979470.py:447: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  data[f'{joint_name}_injury_risk'] = (rolling_series &gt; safe_expanding_quantile(rolling_series)).astype(int)\nINFO: Loaded 10 features for by_trial_exhaustion_score\nINFO: Loaded 9 features for injury_risk\nINFO: Performed temporal train-test split with test size = 0.2\nINFO: Training data shape: (12836, 306), Testing data shape: (3210, 306)\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 10), (12831, 1)\nINFO: Created LSTM sequences: (3205, 5, 10), (3205, 1)\nINFO: Training overall exhaustion model...\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.1902 - val_loss: 0.0843\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.0982 - val_loss: 0.0806\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.0824 - val_loss: 0.0803\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.0799 - val_loss: 0.0837\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.0643 - val_loss: 0.0834\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.0802 - val_loss: 0.0846\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.0736 - val_loss: 0.0840\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - loss: 0.0674 - val_loss: 0.0844\n\n\n\n\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 9), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\nINFO: Training overall injury risk model...\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.9350 - loss: 0.2301 - val_accuracy: 0.9803 - val_loss: 0.0500\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9767 - loss: 0.0831 - val_accuracy: 0.9885 - val_loss: 0.0368\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9765 - loss: 0.0798 - val_accuracy: 0.9850 - val_loss: 0.0413\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9767 - loss: 0.0785 - val_accuracy: 0.9860 - val_loss: 0.0429\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9790 - loss: 0.0744 - val_accuracy: 0.9788 - val_loss: 0.0639\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9795 - loss: 0.0694 - val_accuracy: 0.9813 - val_loss: 0.0548\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9777 - loss: 0.0746 - val_accuracy: 0.9900 - val_loss: 0.0324\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9775 - loss: 0.0735 - val_accuracy: 0.9863 - val_loss: 0.0398\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9756 - loss: 0.0783 - val_accuracy: 0.9838 - val_loss: 0.0456\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9781 - loss: 0.0752 - val_accuracy: 0.9919 - val_loss: 0.0253\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9803 - loss: 0.0696 - val_accuracy: 0.9941 - val_loss: 0.0250\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9791 - loss: 0.0740 - val_accuracy: 0.9897 - val_loss: 0.0349\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9781 - loss: 0.0763 - val_accuracy: 0.9885 - val_loss: 0.0319\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9813 - loss: 0.0658 - val_accuracy: 0.9844 - val_loss: 0.0457\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9801 - loss: 0.0674 - val_accuracy: 0.9841 - val_loss: 0.0424\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9781 - loss: 0.0701 - val_accuracy: 0.9772 - val_loss: 0.0687\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9763 - loss: 0.0765 - val_accuracy: 0.9878 - val_loss: 0.0362\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9790 - loss: 0.0699 - val_accuracy: 0.9872 - val_loss: 0.0392\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9784 - loss: 0.0748 - val_accuracy: 0.9800 - val_loss: 0.0583\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9789 - loss: 0.0702 - val_accuracy: 0.9825 - val_loss: 0.0474\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9807 - loss: 0.0636 - val_accuracy: 0.9778 - val_loss: 0.0610\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9807 - loss: 0.0667 - val_accuracy: 0.9903 - val_loss: 0.0330\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9779 - loss: 0.0706 - val_accuracy: 0.9872 - val_loss: 0.0326\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9799 - loss: 0.0695 - val_accuracy: 0.9872 - val_loss: 0.0397\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9797 - loss: 0.0693 - val_accuracy: 0.9885 - val_loss: 0.0325\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9807 - loss: 0.0687 - val_accuracy: 0.9819 - val_loss: 0.0567\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9839 - loss: 0.0567 - val_accuracy: 0.9881 - val_loss: 0.0402\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9779 - loss: 0.0717 - val_accuracy: 0.9760 - val_loss: 0.0747\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9779 - loss: 0.0705 - val_accuracy: 0.9881 - val_loss: 0.0369\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9793 - loss: 0.0690 - val_accuracy: 0.9903 - val_loss: 0.0292\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9806 - loss: 0.0653 - val_accuracy: 0.9919 - val_loss: 0.0278\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9784 - loss: 0.0686 - val_accuracy: 0.9866 - val_loss: 0.0395\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9802 - loss: 0.0633 - val_accuracy: 0.9934 - val_loss: 0.0279\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9785 - loss: 0.0695 - val_accuracy: 0.9856 - val_loss: 0.0390\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9805 - loss: 0.0621 - val_accuracy: 0.9869 - val_loss: 0.0405\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9796 - loss: 0.0666 - val_accuracy: 0.9819 - val_loss: 0.0562\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9804 - loss: 0.0641 - val_accuracy: 0.9828 - val_loss: 0.0445\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9821 - loss: 0.0580 - val_accuracy: 0.9856 - val_loss: 0.0438\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9804 - loss: 0.0599 - val_accuracy: 0.9850 - val_loss: 0.0479\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9817 - loss: 0.0598 - val_accuracy: 0.9906 - val_loss: 0.0326\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9808 - loss: 0.0668 - val_accuracy: 0.9838 - val_loss: 0.0468\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9818 - loss: 0.0580 - val_accuracy: 0.9872 - val_loss: 0.0386\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9820 - loss: 0.0614 - val_accuracy: 0.9878 - val_loss: 0.0330\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9830 - loss: 0.0595 - val_accuracy: 0.9872 - val_loss: 0.0367\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9821 - loss: 0.0623 - val_accuracy: 0.9947 - val_loss: 0.0227\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9803 - loss: 0.0650 - val_accuracy: 0.9878 - val_loss: 0.0386\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9824 - loss: 0.0557 - val_accuracy: 0.9872 - val_loss: 0.0370\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9831 - loss: 0.0559 - val_accuracy: 0.9813 - val_loss: 0.0575\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9802 - loss: 0.0659 - val_accuracy: 0.9844 - val_loss: 0.0477\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9832 - loss: 0.0544 - val_accuracy: 0.9888 - val_loss: 0.0351\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9810 - loss: 0.0590 - val_accuracy: 0.9872 - val_loss: 0.0423\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9813 - loss: 0.0563 - val_accuracy: 0.9810 - val_loss: 0.0545\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9827 - loss: 0.0561 - val_accuracy: 0.9944 - val_loss: 0.0244\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9836 - loss: 0.0548 - val_accuracy: 0.9881 - val_loss: 0.0384\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9837 - loss: 0.0516 - val_accuracy: 0.9816 - val_loss: 0.0514\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9840 - loss: 0.0526 - val_accuracy: 0.9853 - val_loss: 0.0428\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9824 - loss: 0.0564 - val_accuracy: 0.9891 - val_loss: 0.0312\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9821 - loss: 0.0573 - val_accuracy: 0.9863 - val_loss: 0.0428\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9818 - loss: 0.0570 - val_accuracy: 0.9863 - val_loss: 0.0416\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9839 - loss: 0.0533 - val_accuracy: 0.9910 - val_loss: 0.0303\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9814 - loss: 0.0572 - val_accuracy: 0.9872 - val_loss: 0.0429\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9819 - loss: 0.0576 - val_accuracy: 0.9853 - val_loss: 0.0531\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9830 - loss: 0.0544 - val_accuracy: 0.9891 - val_loss: 0.0381\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9825 - loss: 0.0527 - val_accuracy: 0.9903 - val_loss: 0.0327\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9846 - loss: 0.0463 - val_accuracy: 0.9838 - val_loss: 0.0511\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9825 - loss: 0.0549 - val_accuracy: 0.9894 - val_loss: 0.0318\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9830 - loss: 0.0519 - val_accuracy: 0.9856 - val_loss: 0.0424\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9828 - loss: 0.0545 - val_accuracy: 0.9844 - val_loss: 0.0471\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9835 - loss: 0.0495 - val_accuracy: 0.9856 - val_loss: 0.0481\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9838 - loss: 0.0483 - val_accuracy: 0.9872 - val_loss: 0.0374\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9844 - loss: 0.0496 - val_accuracy: 0.9910 - val_loss: 0.0307\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9817 - loss: 0.0566 - val_accuracy: 0.9891 - val_loss: 0.0345\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9835 - loss: 0.0529 - val_accuracy: 0.9841 - val_loss: 0.0487\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9832 - loss: 0.0526 - val_accuracy: 0.9835 - val_loss: 0.0512\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9827 - loss: 0.0515 - val_accuracy: 0.9853 - val_loss: 0.0429\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9818 - loss: 0.0518 - val_accuracy: 0.9863 - val_loss: 0.0470\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9852 - loss: 0.0460 - val_accuracy: 0.9878 - val_loss: 0.0407\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9842 - loss: 0.0486 - val_accuracy: 0.9894 - val_loss: 0.0322\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9843 - loss: 0.0480 - val_accuracy: 0.9860 - val_loss: 0.0433\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9841 - loss: 0.0518 - val_accuracy: 0.9891 - val_loss: 0.0345\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9833 - loss: 0.0525 - val_accuracy: 0.9847 - val_loss: 0.0447\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9814 - loss: 0.0516 - val_accuracy: 0.9832 - val_loss: 0.0518\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9833 - loss: 0.0521 - val_accuracy: 0.9903 - val_loss: 0.0318\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9847 - loss: 0.0474 - val_accuracy: 0.9778 - val_loss: 0.0875\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9839 - loss: 0.0475 - val_accuracy: 0.9866 - val_loss: 0.0422\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9847 - loss: 0.0442 - val_accuracy: 0.9878 - val_loss: 0.0399\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9855 - loss: 0.0453 - val_accuracy: 0.9881 - val_loss: 0.0370\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9838 - loss: 0.0466 - val_accuracy: 0.9850 - val_loss: 0.0507\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0426 - val_accuracy: 0.9906 - val_loss: 0.0305\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9835 - loss: 0.0490 - val_accuracy: 0.9794 - val_loss: 0.0787\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9837 - loss: 0.0485 - val_accuracy: 0.9828 - val_loss: 0.0633\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9844 - loss: 0.0459 - val_accuracy: 0.9825 - val_loss: 0.0582\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9822 - loss: 0.0513 - val_accuracy: 0.9807 - val_loss: 0.0683\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9833 - loss: 0.0466 - val_accuracy: 0.9850 - val_loss: 0.0420\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9853 - loss: 0.0462 - val_accuracy: 0.9860 - val_loss: 0.0435\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9822 - loss: 0.0489 - val_accuracy: 0.9894 - val_loss: 0.0319\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9848 - loss: 0.0418 - val_accuracy: 0.9866 - val_loss: 0.0477\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9845 - loss: 0.0429 - val_accuracy: 0.9844 - val_loss: 0.0489\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9845 - loss: 0.0426 - val_accuracy: 0.9853 - val_loss: 0.0508\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9852 - loss: 0.0414 - val_accuracy: 0.9850 - val_loss: 0.0469\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9839 - loss: 0.0440 - val_accuracy: 0.9828 - val_loss: 0.0526\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0388 - val_accuracy: 0.9885 - val_loss: 0.0313\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9842 - loss: 0.0426 - val_accuracy: 0.9822 - val_loss: 0.0661\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9835 - loss: 0.0425 - val_accuracy: 0.9860 - val_loss: 0.0408\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9881 - loss: 0.0347 - val_accuracy: 0.9881 - val_loss: 0.0309\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9849 - loss: 0.0424 - val_accuracy: 0.9850 - val_loss: 0.0552\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9859 - loss: 0.0387 - val_accuracy: 0.9897 - val_loss: 0.0301\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0387 - val_accuracy: 0.9856 - val_loss: 0.0475\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0386 - val_accuracy: 0.9856 - val_loss: 0.0517\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9849 - loss: 0.0386 - val_accuracy: 0.9853 - val_loss: 0.0480\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9852 - loss: 0.0413 - val_accuracy: 0.9910 - val_loss: 0.0297\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9834 - loss: 0.0408 - val_accuracy: 0.9832 - val_loss: 0.0586\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0347 - val_accuracy: 0.9832 - val_loss: 0.0548\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9868 - loss: 0.0350 - val_accuracy: 0.9850 - val_loss: 0.0550\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9870 - loss: 0.0361 - val_accuracy: 0.9853 - val_loss: 0.0395\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9836 - loss: 0.0428 - val_accuracy: 0.9828 - val_loss: 0.0598\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0349 - val_accuracy: 0.9881 - val_loss: 0.0349\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9876 - loss: 0.0329 - val_accuracy: 0.9897 - val_loss: 0.0325\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9867 - loss: 0.0343 - val_accuracy: 0.9816 - val_loss: 0.0651\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9855 - loss: 0.0394 - val_accuracy: 0.9875 - val_loss: 0.0456\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9842 - loss: 0.0388 - val_accuracy: 0.9881 - val_loss: 0.0360\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0342 - val_accuracy: 0.9807 - val_loss: 0.0805\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0322 - val_accuracy: 0.9863 - val_loss: 0.0519\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9876 - loss: 0.0314 - val_accuracy: 0.9841 - val_loss: 0.0533\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0288 - val_accuracy: 0.9891 - val_loss: 0.0335\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0305 - val_accuracy: 0.9832 - val_loss: 0.0575\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0315 - val_accuracy: 0.9860 - val_loss: 0.0515\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9864 - loss: 0.0333 - val_accuracy: 0.9850 - val_loss: 0.0448\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0312 - val_accuracy: 0.9803 - val_loss: 0.0775\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0310 - val_accuracy: 0.9869 - val_loss: 0.0499\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0285 - val_accuracy: 0.9856 - val_loss: 0.0524\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9878 - loss: 0.0289 - val_accuracy: 0.9866 - val_loss: 0.0479\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9892 - loss: 0.0271 - val_accuracy: 0.9872 - val_loss: 0.0455\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9881 - loss: 0.0280 - val_accuracy: 0.9832 - val_loss: 0.0669\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0262 - val_accuracy: 0.9844 - val_loss: 0.0639\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0293 - val_accuracy: 0.9866 - val_loss: 0.0543\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0245 - val_accuracy: 0.9869 - val_loss: 0.0371\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0257 - val_accuracy: 0.9803 - val_loss: 0.0801\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9872 - loss: 0.0296 - val_accuracy: 0.9863 - val_loss: 0.0504\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9904 - loss: 0.0256 - val_accuracy: 0.9832 - val_loss: 0.0512\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0265 - val_accuracy: 0.9860 - val_loss: 0.0522\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0245 - val_accuracy: 0.9872 - val_loss: 0.0428\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0276 - val_accuracy: 0.9863 - val_loss: 0.0496\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0242 - val_accuracy: 0.9838 - val_loss: 0.0552\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9914 - loss: 0.0232 - val_accuracy: 0.9853 - val_loss: 0.0508\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0244 - val_accuracy: 0.9856 - val_loss: 0.0386\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0261 - val_accuracy: 0.9863 - val_loss: 0.0445\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9887 - loss: 0.0252 - val_accuracy: 0.9844 - val_loss: 0.0536\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9909 - loss: 0.0219 - val_accuracy: 0.9807 - val_loss: 0.0610\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0217 - val_accuracy: 0.9856 - val_loss: 0.0401\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0215 - val_accuracy: 0.9807 - val_loss: 0.0613\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9896 - loss: 0.0255 - val_accuracy: 0.9841 - val_loss: 0.0542\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0206 - val_accuracy: 0.9832 - val_loss: 0.0552\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9899 - loss: 0.0245 - val_accuracy: 0.9869 - val_loss: 0.0504\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0169 - val_accuracy: 0.9850 - val_loss: 0.0529\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0235 - val_accuracy: 0.9860 - val_loss: 0.0499\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0237 - val_accuracy: 0.9850 - val_loss: 0.0587\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9904 - loss: 0.0215 - val_accuracy: 0.9828 - val_loss: 0.0630\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9909 - loss: 0.0224 - val_accuracy: 0.9725 - val_loss: 0.1001\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0181 - val_accuracy: 0.9891 - val_loss: 0.0367\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0180 - val_accuracy: 0.9875 - val_loss: 0.0446\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0182 - val_accuracy: 0.9844 - val_loss: 0.0618\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0185 - val_accuracy: 0.9800 - val_loss: 0.0638\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9916 - loss: 0.0228 - val_accuracy: 0.9844 - val_loss: 0.0541\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9914 - loss: 0.0180 - val_accuracy: 0.9838 - val_loss: 0.0631\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0204 - val_accuracy: 0.9885 - val_loss: 0.0451\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0245 - val_accuracy: 0.9847 - val_loss: 0.0589\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0164 - val_accuracy: 0.9775 - val_loss: 0.0906\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0195 - val_accuracy: 0.9825 - val_loss: 0.0648\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0162 - val_accuracy: 0.9800 - val_loss: 0.0701\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0175 - val_accuracy: 0.9822 - val_loss: 0.0747\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0156 - val_accuracy: 0.9825 - val_loss: 0.0708\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0134 - val_accuracy: 0.9847 - val_loss: 0.0460\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0184 - val_accuracy: 0.9853 - val_loss: 0.0521\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0149 - val_accuracy: 0.9838 - val_loss: 0.0623\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0147 - val_accuracy: 0.9822 - val_loss: 0.0684\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0131 - val_accuracy: 0.9800 - val_loss: 0.0745\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0140 - val_accuracy: 0.9856 - val_loss: 0.0559\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0144 - val_accuracy: 0.9828 - val_loss: 0.0657\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0153 - val_accuracy: 0.9807 - val_loss: 0.0861\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0127 - val_accuracy: 0.9847 - val_loss: 0.0560\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0128 - val_accuracy: 0.9844 - val_loss: 0.0662\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0140 - val_accuracy: 0.9800 - val_loss: 0.0698\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0193 - val_accuracy: 0.9847 - val_loss: 0.0491\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0123 - val_accuracy: 0.9775 - val_loss: 0.0878\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0151 - val_accuracy: 0.9791 - val_loss: 0.0877\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0148 - val_accuracy: 0.9807 - val_loss: 0.0618\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0111 - val_accuracy: 0.9825 - val_loss: 0.0955\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.9766 - val_loss: 0.0827\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0126 - val_accuracy: 0.9819 - val_loss: 0.0711\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0104 - val_accuracy: 0.9807 - val_loss: 0.0718\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0089 - val_accuracy: 0.9807 - val_loss: 0.0818\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0094 - val_accuracy: 0.9794 - val_loss: 0.0707\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0114 - val_accuracy: 0.9791 - val_loss: 0.0907\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0152 - val_accuracy: 0.9866 - val_loss: 0.0617\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0115 - val_accuracy: 0.9841 - val_loss: 0.0759\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9791 - val_loss: 0.0889\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9835 - val_loss: 0.0798\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.9853 - val_loss: 0.0579\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0122 - val_accuracy: 0.9813 - val_loss: 0.0773\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0080 - val_accuracy: 0.9822 - val_loss: 0.0813\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0104 - val_accuracy: 0.9838 - val_loss: 0.0677\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0090 - val_accuracy: 0.9819 - val_loss: 0.0665\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0096 - val_accuracy: 0.9844 - val_loss: 0.0665\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0120 - val_accuracy: 0.9785 - val_loss: 0.1011\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0105 - val_accuracy: 0.9766 - val_loss: 0.1111\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0076 - val_accuracy: 0.9828 - val_loss: 0.0772\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0089 - val_accuracy: 0.9828 - val_loss: 0.0798\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0081 - val_accuracy: 0.9844 - val_loss: 0.0747\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0126 - val_accuracy: 0.9741 - val_loss: 0.1325\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0139 - val_accuracy: 0.9819 - val_loss: 0.1003\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.9825 - val_loss: 0.0842\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0071 - val_accuracy: 0.9825 - val_loss: 0.0606\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0091 - val_accuracy: 0.9838 - val_loss: 0.0776\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.9803 - val_loss: 0.0946\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0089 - val_accuracy: 0.9810 - val_loss: 0.0746\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0060 - val_accuracy: 0.9810 - val_loss: 0.0852\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.9875 - val_loss: 0.0568\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.9819 - val_loss: 0.0885\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9807 - val_loss: 0.0799\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.9803 - val_loss: 0.0905\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0072 - val_accuracy: 0.9788 - val_loss: 0.1197\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.9816 - val_loss: 0.0945\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0065 - val_accuracy: 0.9810 - val_loss: 0.0883\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.9850 - val_loss: 0.0746\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.9803 - val_loss: 0.1026\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9853 - val_loss: 0.0704\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 0.9875 - val_loss: 0.0644\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0116 - val_accuracy: 0.9856 - val_loss: 0.0750\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9822 - val_loss: 0.0804\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 0.9800 - val_loss: 0.0879\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0082 - val_accuracy: 0.9797 - val_loss: 0.1130\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.9760 - val_loss: 0.0937\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0055 - val_accuracy: 0.9835 - val_loss: 0.0684\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 0.9819 - val_loss: 0.0840\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9807 - val_loss: 0.1086\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9819 - val_loss: 0.1027\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9797 - val_loss: 0.1126\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0048 - val_accuracy: 0.9841 - val_loss: 0.0751\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9828 - val_loss: 0.0845\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0037 - val_accuracy: 0.9803 - val_loss: 0.0942\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0092 - val_accuracy: 0.9822 - val_loss: 0.0683\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.9816 - val_loss: 0.1025\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9835 - val_loss: 0.0657\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0055 - val_accuracy: 0.9847 - val_loss: 0.0876\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.9832 - val_loss: 0.0828\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9822 - val_loss: 0.0881\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0176 - val_accuracy: 0.9813 - val_loss: 0.0990\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.9788 - val_loss: 0.1024\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0057 - val_accuracy: 0.9850 - val_loss: 0.0765\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 0.9760 - val_loss: 0.1367\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 0.9825 - val_loss: 0.0909\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.9832 - val_loss: 0.0886\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.9732 - val_loss: 0.1264\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.9841 - val_loss: 0.0821\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9816 - val_loss: 0.1039\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.9835 - val_loss: 0.0925\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0132 - val_accuracy: 0.9847 - val_loss: 0.0592\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0062 - val_accuracy: 0.9816 - val_loss: 0.0930\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9816 - val_loss: 0.0874\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9819 - val_loss: 0.0863\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9819 - val_loss: 0.0925\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.9835 - val_loss: 0.0748\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9835 - val_loss: 0.0934\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9872 - val_loss: 0.0646\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0097 - val_accuracy: 0.9813 - val_loss: 0.1084\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9819 - val_loss: 0.0937\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0017 - val_accuracy: 0.9863 - val_loss: 0.0656\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9722 - val_loss: 0.1282\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.9744 - val_loss: 0.1208\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.9838 - val_loss: 0.0947\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.9788 - val_loss: 0.0949\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.9816 - val_loss: 0.0889\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9813 - val_loss: 0.1017\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9810 - val_loss: 0.0994\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9810 - val_loss: 0.1132\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9832 - val_loss: 0.0937\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9800 - val_loss: 0.0901\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0079 - val_accuracy: 0.9772 - val_loss: 0.1473\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9794 - val_loss: 0.1023\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.9828 - val_loss: 0.0944\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9841 - val_loss: 0.0882\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9828 - val_loss: 0.1005\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 0.9822 - val_loss: 0.0981\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9816 - val_loss: 0.0983\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9807 - val_loss: 0.1097\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9863 - val_loss: 0.0621\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0198 - val_accuracy: 0.9835 - val_loss: 0.0801\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0034 - val_accuracy: 0.9835 - val_loss: 0.0855\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9828 - val_loss: 0.0897\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9810 - val_loss: 0.0996\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9847 - val_loss: 0.0911\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9850 - val_loss: 0.0816\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9788 - val_loss: 0.1247\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9847 - val_loss: 0.0937\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9838 - val_loss: 0.0704\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9800 - val_loss: 0.1027\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9725 - val_loss: 0.2025\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0128 - val_accuracy: 0.9828 - val_loss: 0.0861\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.9816 - val_loss: 0.0988\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9832 - val_loss: 0.0990\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0074 - val_accuracy: 0.9838 - val_loss: 0.0987\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 6.7228e-04 - val_accuracy: 0.9841 - val_loss: 0.0993\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 8.0090e-04 - val_accuracy: 0.9813 - val_loss: 0.1100\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0077 - val_accuracy: 0.9722 - val_loss: 0.1466\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0075 - val_accuracy: 0.9835 - val_loss: 0.0853\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9825 - val_loss: 0.0947\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 9.0773e-04 - val_accuracy: 0.9828 - val_loss: 0.0877\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9822 - val_loss: 0.0893\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9800 - val_loss: 0.1100\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9769 - val_loss: 0.1233\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9844 - val_loss: 0.0882\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9757 - val_loss: 0.1377\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0103 - val_accuracy: 0.9819 - val_loss: 0.0889\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.9810 - val_loss: 0.0967\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.8639e-04 - val_accuracy: 0.9828 - val_loss: 0.0946\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.1625e-04 - val_accuracy: 0.9816 - val_loss: 0.0968\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.5915e-04 - val_accuracy: 0.9803 - val_loss: 0.1104\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0057 - val_accuracy: 0.9797 - val_loss: 0.1041\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.9788 - val_loss: 0.1337\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9785 - val_loss: 0.1062\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9828 - val_loss: 0.0946\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.3139e-04 - val_accuracy: 0.9760 - val_loss: 0.1314\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0142 - val_accuracy: 0.9825 - val_loss: 0.0820\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0028 - val_accuracy: 0.9828 - val_loss: 0.0859\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9847 - val_loss: 0.0855\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.7184e-04 - val_accuracy: 0.9856 - val_loss: 0.0802\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.8429e-04 - val_accuracy: 0.9828 - val_loss: 0.0992\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.5235e-04 - val_accuracy: 0.9841 - val_loss: 0.0885\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.1251e-04 - val_accuracy: 0.9828 - val_loss: 0.0924\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9763 - val_loss: 0.1338\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0107 - val_accuracy: 0.9832 - val_loss: 0.0916\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.9838 - val_loss: 0.0898\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 8.6400e-04 - val_accuracy: 0.9853 - val_loss: 0.0856\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.4856e-04 - val_accuracy: 0.9828 - val_loss: 0.1016\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 6.4657e-04 - val_accuracy: 0.9841 - val_loss: 0.0969\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0100 - val_accuracy: 0.9807 - val_loss: 0.1265\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0119 - val_accuracy: 0.9797 - val_loss: 0.0900\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9828 - val_loss: 0.0850\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9822 - val_loss: 0.0918\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.9350e-04 - val_accuracy: 0.9825 - val_loss: 0.0954\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 5.6644e-04 - val_accuracy: 0.9813 - val_loss: 0.1024\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.8566e-04 - val_accuracy: 0.9828 - val_loss: 0.0993\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.0817e-04 - val_accuracy: 0.9819 - val_loss: 0.0989\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9803 - val_loss: 0.1022\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.9766 - val_loss: 0.1448\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9853 - val_loss: 0.0875\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 6.7769e-04 - val_accuracy: 0.9856 - val_loss: 0.0889\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 0.9766 - val_loss: 0.1319\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9838 - val_loss: 0.1014\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.9835 - val_loss: 0.1037\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 6.3730e-04 - val_accuracy: 0.9835 - val_loss: 0.0973\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 9.4592e-04 - val_accuracy: 0.9807 - val_loss: 0.1006\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9822 - val_loss: 0.0975\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9910 - val_loss: 0.0376\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0083 - val_accuracy: 0.9778 - val_loss: 0.1481\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0076 - val_accuracy: 0.9816 - val_loss: 0.0997\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.0426e-04 - val_accuracy: 0.9828 - val_loss: 0.0946\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 6.0019e-04 - val_accuracy: 0.9819 - val_loss: 0.0965\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 4.9772e-04 - val_accuracy: 0.9822 - val_loss: 0.0914\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.5413e-04 - val_accuracy: 0.9828 - val_loss: 0.1022\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.0397e-04 - val_accuracy: 0.9832 - val_loss: 0.0980\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.3021e-04 - val_accuracy: 0.9828 - val_loss: 0.1046\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.6557e-04 - val_accuracy: 0.9835 - val_loss: 0.1014\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0096 - val_accuracy: 0.9813 - val_loss: 0.1083\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.0760e-04 - val_accuracy: 0.9800 - val_loss: 0.1181\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9744 - val_loss: 0.1274\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9847 - val_loss: 0.0897\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 7.0439e-04 - val_accuracy: 0.9822 - val_loss: 0.1046\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.8502e-04 - val_accuracy: 0.9841 - val_loss: 0.0937\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.7220e-04 - val_accuracy: 0.9822 - val_loss: 0.1074\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.9788 - val_loss: 0.1098\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0166 - val_accuracy: 0.9807 - val_loss: 0.0928\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9813 - val_loss: 0.1047\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.6606e-04 - val_accuracy: 0.9822 - val_loss: 0.0990\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.1335e-04 - val_accuracy: 0.9838 - val_loss: 0.0957\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.9996e-04 - val_accuracy: 0.9822 - val_loss: 0.1000\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.6702e-04 - val_accuracy: 0.9807 - val_loss: 0.1076\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.3181e-04 - val_accuracy: 0.9832 - val_loss: 0.1036\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.6065e-04 - val_accuracy: 0.9785 - val_loss: 0.1078\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0160 - val_accuracy: 0.9856 - val_loss: 0.0741\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 0.9825 - val_loss: 0.0926\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9853 - val_loss: 0.0880\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 5.1880e-04 - val_accuracy: 0.9832 - val_loss: 0.0764\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9772 - val_loss: 0.1289\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9835 - val_loss: 0.0951\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 8.1908e-04 - val_accuracy: 0.9835 - val_loss: 0.0940\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.5436e-04 - val_accuracy: 0.9816 - val_loss: 0.1032\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.9894e-04 - val_accuracy: 0.9825 - val_loss: 0.1041\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.7549e-04 - val_accuracy: 0.9844 - val_loss: 0.1002\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.8682e-04 - val_accuracy: 0.9863 - val_loss: 0.0862\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0075 - val_accuracy: 0.9785 - val_loss: 0.1063\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0061 - val_accuracy: 0.9816 - val_loss: 0.0907\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9803 - val_loss: 0.1144\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 5.4226e-04 - val_accuracy: 0.9813 - val_loss: 0.1008\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 5.0673e-04 - val_accuracy: 0.9819 - val_loss: 0.0984\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.7871e-04 - val_accuracy: 0.9810 - val_loss: 0.1032\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.2733e-04 - val_accuracy: 0.9807 - val_loss: 0.1161\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.1142e-04 - val_accuracy: 0.9816 - val_loss: 0.1080\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.9797 - val_loss: 0.1036\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0078 - val_accuracy: 0.9810 - val_loss: 0.1072\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.9822 - val_loss: 0.1104\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.9782 - val_loss: 0.1320\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9850 - val_loss: 0.1000\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.3807e-04 - val_accuracy: 0.9822 - val_loss: 0.1105\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.9172e-04 - val_accuracy: 0.9822 - val_loss: 0.1072\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.1356e-04 - val_accuracy: 0.9828 - val_loss: 0.1084\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.8673e-04 - val_accuracy: 0.9828 - val_loss: 0.1086\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.0831e-04 - val_accuracy: 0.9844 - val_loss: 0.1033\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9794 - val_loss: 0.1379\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0116 - val_accuracy: 0.9828 - val_loss: 0.1038\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9841 - val_loss: 0.0942\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 5.8913e-04 - val_accuracy: 0.9828 - val_loss: 0.1108\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.8561e-04 - val_accuracy: 0.9828 - val_loss: 0.1101\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.0731e-04 - val_accuracy: 0.9838 - val_loss: 0.1046\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.6369e-04 - val_accuracy: 0.9835 - val_loss: 0.1003\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.5193e-04 - val_accuracy: 0.9835 - val_loss: 0.1060\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.0551e-04 - val_accuracy: 0.9838 - val_loss: 0.1068\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.1148e-04 - val_accuracy: 0.9847 - val_loss: 0.1118\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 9.3644e-05 - val_accuracy: 0.9841 - val_loss: 0.1099\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.5971e-04 - val_accuracy: 0.9660 - val_loss: 0.2511\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0341 - val_accuracy: 0.9813 - val_loss: 0.0899\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9844 - val_loss: 0.0751\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.9810 - val_loss: 0.0957\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 9.4005e-04 - val_accuracy: 0.9844 - val_loss: 0.0903\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0066 - val_accuracy: 0.9816 - val_loss: 0.0948\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 6.7654e-04 - val_accuracy: 0.9841 - val_loss: 0.0859\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 8.3220e-04 - val_accuracy: 0.9822 - val_loss: 0.1006\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.5390e-04 - val_accuracy: 0.9803 - val_loss: 0.1103\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.5504e-04 - val_accuracy: 0.9822 - val_loss: 0.1047\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.0847e-04 - val_accuracy: 0.9810 - val_loss: 0.1102\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.6074e-04 - val_accuracy: 0.9819 - val_loss: 0.1004\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9778 - val_loss: 0.1343\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0037 - val_accuracy: 0.9813 - val_loss: 0.1034\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.9841 - val_loss: 0.0874\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0012 - val_accuracy: 0.9813 - val_loss: 0.1029\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9800 - val_loss: 0.1261\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 5.2509e-04 - val_accuracy: 0.9822 - val_loss: 0.1130\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 7.0000e-04 - val_accuracy: 0.9825 - val_loss: 0.1074\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9816 - val_loss: 0.1060\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.7754e-04 - val_accuracy: 0.9803 - val_loss: 0.1287\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.5737e-04 - val_accuracy: 0.9835 - val_loss: 0.0988\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.0486e-04 - val_accuracy: 0.9828 - val_loss: 0.1087\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.3046e-04 - val_accuracy: 0.9828 - val_loss: 0.1106\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.9115e-04 - val_accuracy: 0.9838 - val_loss: 0.1084\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.1920e-04 - val_accuracy: 0.9819 - val_loss: 0.1169\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 7.0503e-05 - val_accuracy: 0.9828 - val_loss: 0.1081\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.5309e-04 - val_accuracy: 0.9850 - val_loss: 0.1018\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.3734e-04 - val_accuracy: 0.9763 - val_loss: 0.1570\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0312 - val_accuracy: 0.9810 - val_loss: 0.0904\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9797 - val_loss: 0.1107\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 3.9086e-04 - val_accuracy: 0.9807 - val_loss: 0.1033\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.0506e-04 - val_accuracy: 0.9825 - val_loss: 0.1030\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.7270e-04 - val_accuracy: 0.9828 - val_loss: 0.1031\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9828 - val_loss: 0.1083\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.1281e-04 - val_accuracy: 0.9813 - val_loss: 0.1260\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.8248e-04 - val_accuracy: 0.9828 - val_loss: 0.1100\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 3.9070e-04 - val_accuracy: 0.9832 - val_loss: 0.0967\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0195 - val_accuracy: 0.9794 - val_loss: 0.1140\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9813 - val_loss: 0.1013\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.4338e-04 - val_accuracy: 0.9832 - val_loss: 0.0993\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.3335e-04 - val_accuracy: 0.9822 - val_loss: 0.1008\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.6922e-04 - val_accuracy: 0.9800 - val_loss: 0.1240\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0015 - val_accuracy: 0.9819 - val_loss: 0.1073\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 2.2477e-04 - val_accuracy: 0.9828 - val_loss: 0.1065\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 6.3696e-04 - val_accuracy: 0.9853 - val_loss: 0.0813\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 5.3912e-04 - val_accuracy: 0.9847 - val_loss: 0.0934\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.0828e-04 - val_accuracy: 0.9825 - val_loss: 0.1092\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.7393e-04 - val_accuracy: 0.9835 - val_loss: 0.1075\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.5290e-04 - val_accuracy: 0.9810 - val_loss: 0.1358\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9835 - val_loss: 0.1185\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0179 - val_accuracy: 0.9832 - val_loss: 0.0839\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0047 - val_accuracy: 0.9825 - val_loss: 0.0997\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.2310e-04 - val_accuracy: 0.9816 - val_loss: 0.1105\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 8.3331e-04 - val_accuracy: 0.9800 - val_loss: 0.1211\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9813 - val_loss: 0.1015\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.9816 - val_loss: 0.0977\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 6.5680e-04 - val_accuracy: 0.9807 - val_loss: 0.1203\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.5886e-04 - val_accuracy: 0.9822 - val_loss: 0.1102\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 3.3788e-04 - val_accuracy: 0.9800 - val_loss: 0.1084\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9810 - val_loss: 0.0993\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0034 - val_accuracy: 0.9800 - val_loss: 0.1143\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 7.2937e-04 - val_accuracy: 0.9797 - val_loss: 0.1186\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 4.3476e-04 - val_accuracy: 0.9816 - val_loss: 0.1094\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.1754e-04 - val_accuracy: 0.9822 - val_loss: 0.1207\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0065 - val_accuracy: 0.9766 - val_loss: 0.1617\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9813 - val_loss: 0.1143\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.8660e-04 - val_accuracy: 0.9819 - val_loss: 0.1157\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.1016e-04 - val_accuracy: 0.9828 - val_loss: 0.1118\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.5675e-04 - val_accuracy: 0.9838 - val_loss: 0.1125\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.2086e-04 - val_accuracy: 0.9835 - val_loss: 0.1150\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.9669e-04 - val_accuracy: 0.9838 - val_loss: 0.0844\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9763 - val_loss: 0.1337\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0090 - val_accuracy: 0.9832 - val_loss: 0.0926\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 7.2981e-04 - val_accuracy: 0.9822 - val_loss: 0.1052\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.6553e-04 - val_accuracy: 0.9816 - val_loss: 0.1055\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.0605e-04 - val_accuracy: 0.9788 - val_loss: 0.1270\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 9.8428e-04 - val_accuracy: 0.9797 - val_loss: 0.1294\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 3.5953e-04 - val_accuracy: 0.9825 - val_loss: 0.1046\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 9.4610e-05 - val_accuracy: 0.9816 - val_loss: 0.1104\n\n\n\n\nINFO: Training model for L_ANKLE_injury_risk...\nINFO: Loaded 10 features for L_ANKLE_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 10), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.8610 - loss: 0.3470 - val_accuracy: 0.8902 - val_loss: 0.2628\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9042 - loss: 0.2121 - val_accuracy: 0.8905 - val_loss: 0.3409\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9243 - loss: 0.1704 - val_accuracy: 0.8811 - val_loss: 0.4833\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9405 - loss: 0.1421 - val_accuracy: 0.8899 - val_loss: 0.4885\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9568 - loss: 0.1132 - val_accuracy: 0.8786 - val_loss: 0.5420\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9640 - loss: 0.0930 - val_accuracy: 0.8774 - val_loss: 0.5904\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9660 - loss: 0.0822 - val_accuracy: 0.8771 - val_loss: 0.6399\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9691 - loss: 0.0762 - val_accuracy: 0.8783 - val_loss: 0.6657\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9724 - loss: 0.0704 - val_accuracy: 0.8746 - val_loss: 0.6788\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9760 - loss: 0.0612 - val_accuracy: 0.8802 - val_loss: 0.6979\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9752 - loss: 0.0604 - val_accuracy: 0.8730 - val_loss: 0.7063\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9786 - loss: 0.0512 - val_accuracy: 0.8764 - val_loss: 0.7306\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9794 - loss: 0.0483 - val_accuracy: 0.8771 - val_loss: 0.7070\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9789 - loss: 0.0513 - val_accuracy: 0.8799 - val_loss: 0.7261\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9781 - loss: 0.0484 - val_accuracy: 0.8739 - val_loss: 0.7209\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9828 - loss: 0.0435 - val_accuracy: 0.8802 - val_loss: 0.7451\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9820 - loss: 0.0427 - val_accuracy: 0.8730 - val_loss: 0.7871\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9836 - loss: 0.0428 - val_accuracy: 0.8761 - val_loss: 0.7510\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9809 - loss: 0.0457 - val_accuracy: 0.8752 - val_loss: 0.7940\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9831 - loss: 0.0418 - val_accuracy: 0.8755 - val_loss: 0.7739\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0333 - val_accuracy: 0.8693 - val_loss: 0.8037\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0349 - val_accuracy: 0.8780 - val_loss: 0.8183\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0337 - val_accuracy: 0.8786 - val_loss: 0.8182\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9853 - loss: 0.0369 - val_accuracy: 0.8771 - val_loss: 0.8145\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0311 - val_accuracy: 0.8793 - val_loss: 0.8289\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9844 - loss: 0.0344 - val_accuracy: 0.8752 - val_loss: 0.7962\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9861 - loss: 0.0323 - val_accuracy: 0.8796 - val_loss: 0.7710\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0297 - val_accuracy: 0.8780 - val_loss: 0.7817\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0305 - val_accuracy: 0.8780 - val_loss: 0.8309\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9889 - loss: 0.0300 - val_accuracy: 0.8814 - val_loss: 0.7906\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9864 - loss: 0.0356 - val_accuracy: 0.8761 - val_loss: 0.8218\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9864 - loss: 0.0338 - val_accuracy: 0.8774 - val_loss: 0.8175\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9874 - loss: 0.0296 - val_accuracy: 0.8777 - val_loss: 0.8335\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0302 - val_accuracy: 0.8814 - val_loss: 0.8464\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0268 - val_accuracy: 0.8727 - val_loss: 0.9247\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0300 - val_accuracy: 0.8755 - val_loss: 0.8832\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9881 - loss: 0.0309 - val_accuracy: 0.8739 - val_loss: 0.8782\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9872 - loss: 0.0321 - val_accuracy: 0.8718 - val_loss: 0.8855\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0278 - val_accuracy: 0.8693 - val_loss: 0.9041\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9895 - loss: 0.0276 - val_accuracy: 0.8727 - val_loss: 0.9204\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0258 - val_accuracy: 0.8830 - val_loss: 0.8398\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0257 - val_accuracy: 0.8736 - val_loss: 0.8678\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0247 - val_accuracy: 0.8839 - val_loss: 0.9065\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0243 - val_accuracy: 0.8693 - val_loss: 1.0046\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9904 - loss: 0.0230 - val_accuracy: 0.8811 - val_loss: 0.8842\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0240 - val_accuracy: 0.8830 - val_loss: 0.9181\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0199 - val_accuracy: 0.8761 - val_loss: 0.9279\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0218 - val_accuracy: 0.8808 - val_loss: 0.8784\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9900 - loss: 0.0243 - val_accuracy: 0.8877 - val_loss: 0.8425\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0213 - val_accuracy: 0.8830 - val_loss: 0.8692\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0233 - val_accuracy: 0.8849 - val_loss: 0.8277\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0206 - val_accuracy: 0.8690 - val_loss: 1.0062\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0220 - val_accuracy: 0.8655 - val_loss: 0.9714\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9889 - loss: 0.0243 - val_accuracy: 0.8746 - val_loss: 0.9216\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0212 - val_accuracy: 0.8789 - val_loss: 0.9353\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0208 - val_accuracy: 0.8752 - val_loss: 0.9528\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0185 - val_accuracy: 0.8711 - val_loss: 1.0365\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0198 - val_accuracy: 0.8777 - val_loss: 0.9648\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0254 - val_accuracy: 0.8758 - val_loss: 0.9727\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0154 - val_accuracy: 0.8786 - val_loss: 0.9300\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0227 - val_accuracy: 0.8874 - val_loss: 0.8392\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0175 - val_accuracy: 0.8774 - val_loss: 0.9617\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0179 - val_accuracy: 0.8805 - val_loss: 0.9284\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9916 - loss: 0.0196 - val_accuracy: 0.8761 - val_loss: 0.9825\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0161 - val_accuracy: 0.8789 - val_loss: 1.0070\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0182 - val_accuracy: 0.8771 - val_loss: 0.9908\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0181 - val_accuracy: 0.8793 - val_loss: 0.9836\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0187 - val_accuracy: 0.8724 - val_loss: 1.0987\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0210 - val_accuracy: 0.8786 - val_loss: 0.9250\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0153 - val_accuracy: 0.8749 - val_loss: 1.0365\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0186 - val_accuracy: 0.8749 - val_loss: 1.0308\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0175 - val_accuracy: 0.8802 - val_loss: 0.9255\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0182 - val_accuracy: 0.8764 - val_loss: 1.0006\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0178 - val_accuracy: 0.8758 - val_loss: 0.9816\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0173 - val_accuracy: 0.8752 - val_loss: 1.0082\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0202 - val_accuracy: 0.8802 - val_loss: 0.9723\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0149 - val_accuracy: 0.8786 - val_loss: 0.9682\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0168 - val_accuracy: 0.8764 - val_loss: 0.9919\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0166 - val_accuracy: 0.8761 - val_loss: 1.0414\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0154 - val_accuracy: 0.8793 - val_loss: 0.9868\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0168 - val_accuracy: 0.8755 - val_loss: 1.0472\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0174 - val_accuracy: 0.8802 - val_loss: 0.9622\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0138 - val_accuracy: 0.8793 - val_loss: 0.9950\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0149 - val_accuracy: 0.8808 - val_loss: 1.0082\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0185 - val_accuracy: 0.8811 - val_loss: 0.9735\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0160 - val_accuracy: 0.8755 - val_loss: 1.0126\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0161 - val_accuracy: 0.8746 - val_loss: 1.0127\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0172 - val_accuracy: 0.8749 - val_loss: 0.9709\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0163 - val_accuracy: 0.8746 - val_loss: 1.0324\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0144 - val_accuracy: 0.8752 - val_loss: 1.0555\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0118 - val_accuracy: 0.8774 - val_loss: 0.9795\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0145 - val_accuracy: 0.8739 - val_loss: 1.1226\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0139 - val_accuracy: 0.8752 - val_loss: 1.1458\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0161 - val_accuracy: 0.8752 - val_loss: 1.0256\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0154 - val_accuracy: 0.8752 - val_loss: 1.0270\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0139 - val_accuracy: 0.8755 - val_loss: 1.0560\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0154 - val_accuracy: 0.8793 - val_loss: 0.9999\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0145 - val_accuracy: 0.8715 - val_loss: 1.0817\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0142 - val_accuracy: 0.8833 - val_loss: 0.9943\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0148 - val_accuracy: 0.8892 - val_loss: 0.9305\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0127 - val_accuracy: 0.8749 - val_loss: 1.1054\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0143 - val_accuracy: 0.8739 - val_loss: 1.0778\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0122 - val_accuracy: 0.8796 - val_loss: 1.0798\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0143 - val_accuracy: 0.8736 - val_loss: 1.0868\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0172 - val_accuracy: 0.8764 - val_loss: 1.0413\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0130 - val_accuracy: 0.8755 - val_loss: 1.0544\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0178 - val_accuracy: 0.8799 - val_loss: 1.0271\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0139 - val_accuracy: 0.8786 - val_loss: 1.0902\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0126 - val_accuracy: 0.8814 - val_loss: 1.1006\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0115 - val_accuracy: 0.8758 - val_loss: 1.1219\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0118 - val_accuracy: 0.8771 - val_loss: 1.0873\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0125 - val_accuracy: 0.8752 - val_loss: 1.1195\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0103 - val_accuracy: 0.8764 - val_loss: 1.1466\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0119 - val_accuracy: 0.8718 - val_loss: 1.1987\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0124 - val_accuracy: 0.8793 - val_loss: 1.1089\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0174 - val_accuracy: 0.8708 - val_loss: 1.1789\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0115 - val_accuracy: 0.8783 - val_loss: 1.1106\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0130 - val_accuracy: 0.8802 - val_loss: 1.1139\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0119 - val_accuracy: 0.8683 - val_loss: 1.1556\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0128 - val_accuracy: 0.8730 - val_loss: 1.2001\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0133 - val_accuracy: 0.8680 - val_loss: 1.1101\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0116 - val_accuracy: 0.8764 - val_loss: 1.1256\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0088 - val_accuracy: 0.8658 - val_loss: 1.2413\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0135 - val_accuracy: 0.8752 - val_loss: 1.1150\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0108 - val_accuracy: 0.8761 - val_loss: 1.1412\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0096 - val_accuracy: 0.8739 - val_loss: 1.1735\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0120 - val_accuracy: 0.8780 - val_loss: 1.0847\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0161 - val_accuracy: 0.8793 - val_loss: 1.0997\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0109 - val_accuracy: 0.8821 - val_loss: 1.0357\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0115 - val_accuracy: 0.8736 - val_loss: 1.0944\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0106 - val_accuracy: 0.8786 - val_loss: 1.1002\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0109 - val_accuracy: 0.8830 - val_loss: 1.0375\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0105 - val_accuracy: 0.8727 - val_loss: 1.1192\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0116 - val_accuracy: 0.8786 - val_loss: 1.1574\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0111 - val_accuracy: 0.8730 - val_loss: 1.1807\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0101 - val_accuracy: 0.8674 - val_loss: 1.1946\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0100 - val_accuracy: 0.8799 - val_loss: 1.1557\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0131 - val_accuracy: 0.8640 - val_loss: 1.2818\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0113 - val_accuracy: 0.8730 - val_loss: 1.1853\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0112 - val_accuracy: 0.8761 - val_loss: 1.1501\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0124 - val_accuracy: 0.8786 - val_loss: 1.1363\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0083 - val_accuracy: 0.8768 - val_loss: 1.2184\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0100 - val_accuracy: 0.8789 - val_loss: 1.1698\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0099 - val_accuracy: 0.8796 - val_loss: 1.0703\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0102 - val_accuracy: 0.8746 - val_loss: 1.1606\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0105 - val_accuracy: 0.8730 - val_loss: 1.1986\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0091 - val_accuracy: 0.8733 - val_loss: 1.2560\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0113 - val_accuracy: 0.8761 - val_loss: 1.2192\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0096 - val_accuracy: 0.8743 - val_loss: 1.2270\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0082 - val_accuracy: 0.8677 - val_loss: 1.2772\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0098 - val_accuracy: 0.8699 - val_loss: 1.2065\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0104 - val_accuracy: 0.8721 - val_loss: 1.1808\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0112 - val_accuracy: 0.8715 - val_loss: 1.2960\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0157 - val_accuracy: 0.8665 - val_loss: 1.2807\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.8721 - val_loss: 1.2553\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0107 - val_accuracy: 0.8683 - val_loss: 1.1927\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0130 - val_accuracy: 0.8721 - val_loss: 1.2044\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0118 - val_accuracy: 0.8746 - val_loss: 1.2193\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0103 - val_accuracy: 0.8764 - val_loss: 1.2036\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.8749 - val_loss: 1.2529\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0119 - val_accuracy: 0.8739 - val_loss: 1.2690\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0121 - val_accuracy: 0.8755 - val_loss: 1.2697\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0102 - val_accuracy: 0.8739 - val_loss: 1.2460\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0081 - val_accuracy: 0.8774 - val_loss: 1.1764\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0087 - val_accuracy: 0.8780 - val_loss: 1.1865\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0109 - val_accuracy: 0.8783 - val_loss: 1.1438\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0105 - val_accuracy: 0.8764 - val_loss: 1.1722\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0103 - val_accuracy: 0.8774 - val_loss: 1.1617\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0075 - val_accuracy: 0.8771 - val_loss: 1.2021\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0118 - val_accuracy: 0.8749 - val_loss: 1.2367\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0088 - val_accuracy: 0.8752 - val_loss: 1.1953\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0095 - val_accuracy: 0.8755 - val_loss: 1.2508\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0106 - val_accuracy: 0.8774 - val_loss: 1.2859\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0097 - val_accuracy: 0.8736 - val_loss: 1.2305\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0100 - val_accuracy: 0.8774 - val_loss: 1.2622\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0101 - val_accuracy: 0.8783 - val_loss: 1.1911\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0083 - val_accuracy: 0.8780 - val_loss: 1.2580\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0084 - val_accuracy: 0.8743 - val_loss: 1.2900\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0067 - val_accuracy: 0.8764 - val_loss: 1.3008\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0109 - val_accuracy: 0.8758 - val_loss: 1.2514\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.8758 - val_loss: 1.3155\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0074 - val_accuracy: 0.8733 - val_loss: 1.3598\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0127 - val_accuracy: 0.8771 - val_loss: 1.3255\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0080 - val_accuracy: 0.8786 - val_loss: 1.1654\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0078 - val_accuracy: 0.8749 - val_loss: 1.2881\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0159 - val_accuracy: 0.8749 - val_loss: 1.1913\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0085 - val_accuracy: 0.8758 - val_loss: 1.2877\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0088 - val_accuracy: 0.8786 - val_loss: 1.2920\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0085 - val_accuracy: 0.8752 - val_loss: 1.2239\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 0.8755 - val_loss: 1.2202\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0096 - val_accuracy: 0.8783 - val_loss: 1.2233\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0105 - val_accuracy: 0.8764 - val_loss: 1.2567\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0102 - val_accuracy: 0.8752 - val_loss: 1.2356\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.8783 - val_loss: 1.2048\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0074 - val_accuracy: 0.8749 - val_loss: 1.2813\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0082 - val_accuracy: 0.8761 - val_loss: 1.3005\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0080 - val_accuracy: 0.8743 - val_loss: 1.2306\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0084 - val_accuracy: 0.8805 - val_loss: 1.2443\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0070 - val_accuracy: 0.8808 - val_loss: 1.2829\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0088 - val_accuracy: 0.8764 - val_loss: 1.2539\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0069 - val_accuracy: 0.8811 - val_loss: 1.2666\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0081 - val_accuracy: 0.8789 - val_loss: 1.2312\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 0.8780 - val_loss: 1.2294\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0103 - val_accuracy: 0.8758 - val_loss: 1.2587\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0083 - val_accuracy: 0.8789 - val_loss: 1.2125\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0077 - val_accuracy: 0.8761 - val_loss: 1.2911\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0134 - val_accuracy: 0.8771 - val_loss: 1.2590\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0097 - val_accuracy: 0.8774 - val_loss: 1.2108\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0084 - val_accuracy: 0.8755 - val_loss: 1.3134\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0101 - val_accuracy: 0.8705 - val_loss: 1.3698\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0070 - val_accuracy: 0.8761 - val_loss: 1.2706\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0061 - val_accuracy: 0.8783 - val_loss: 1.2501\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.8758 - val_loss: 1.2606\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0114 - val_accuracy: 0.8711 - val_loss: 1.3506\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.8755 - val_loss: 1.3517\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.8758 - val_loss: 1.3046\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0067 - val_accuracy: 0.8768 - val_loss: 1.2875\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0086 - val_accuracy: 0.8749 - val_loss: 1.2759\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0061 - val_accuracy: 0.8755 - val_loss: 1.2997\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0088 - val_accuracy: 0.8758 - val_loss: 1.3611\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.8702 - val_loss: 1.3921\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0090 - val_accuracy: 0.8739 - val_loss: 1.3273\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0070 - val_accuracy: 0.8780 - val_loss: 1.2644\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0074 - val_accuracy: 0.8783 - val_loss: 1.2685\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0080 - val_accuracy: 0.8799 - val_loss: 1.1938\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0081 - val_accuracy: 0.8736 - val_loss: 1.3005\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0083 - val_accuracy: 0.8764 - val_loss: 1.3035\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0101 - val_accuracy: 0.8758 - val_loss: 1.3221\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0073 - val_accuracy: 0.8761 - val_loss: 1.3209\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0069 - val_accuracy: 0.8793 - val_loss: 1.2511\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0094 - val_accuracy: 0.8777 - val_loss: 1.2493\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0086 - val_accuracy: 0.8771 - val_loss: 1.3013\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0085 - val_accuracy: 0.8761 - val_loss: 1.3447\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.8749 - val_loss: 1.4357\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0066 - val_accuracy: 0.8733 - val_loss: 1.3471\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0091 - val_accuracy: 0.8743 - val_loss: 1.3329\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.8693 - val_loss: 1.4472\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0098 - val_accuracy: 0.8683 - val_loss: 1.3818\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0064 - val_accuracy: 0.8658 - val_loss: 1.3898\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0087 - val_accuracy: 0.8671 - val_loss: 1.3828\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.8696 - val_loss: 1.4079\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.8708 - val_loss: 1.3736\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0078 - val_accuracy: 0.8649 - val_loss: 1.4164\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0097 - val_accuracy: 0.8690 - val_loss: 1.4481\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0049 - val_accuracy: 0.8764 - val_loss: 1.3476\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0065 - val_accuracy: 0.8696 - val_loss: 1.3953\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0104 - val_accuracy: 0.8733 - val_loss: 1.3426\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0063 - val_accuracy: 0.8708 - val_loss: 1.3883\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0080 - val_accuracy: 0.8761 - val_loss: 1.2899\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.8715 - val_loss: 1.3143\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.8761 - val_loss: 1.3435\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0057 - val_accuracy: 0.8768 - val_loss: 1.3200\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.8727 - val_loss: 1.3674\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0054 - val_accuracy: 0.8696 - val_loss: 1.3917\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0096 - val_accuracy: 0.8674 - val_loss: 1.3872\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0075 - val_accuracy: 0.8789 - val_loss: 1.3137\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.8768 - val_loss: 1.3070\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0071 - val_accuracy: 0.8761 - val_loss: 1.2756\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.8758 - val_loss: 1.3317\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0057 - val_accuracy: 0.8814 - val_loss: 1.2885\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0068 - val_accuracy: 0.8783 - val_loss: 1.2806\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0081 - val_accuracy: 0.8780 - val_loss: 1.3142\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0058 - val_accuracy: 0.8764 - val_loss: 1.3529\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0063 - val_accuracy: 0.8764 - val_loss: 1.3157\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0108 - val_accuracy: 0.8749 - val_loss: 1.3022\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0078 - val_accuracy: 0.8764 - val_loss: 1.2440\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0052 - val_accuracy: 0.8736 - val_loss: 1.3519\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0050 - val_accuracy: 0.8761 - val_loss: 1.3511\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0059 - val_accuracy: 0.8774 - val_loss: 1.4078\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.8764 - val_loss: 1.2891\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0050 - val_accuracy: 0.8733 - val_loss: 1.3046\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.8771 - val_loss: 1.2777\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0066 - val_accuracy: 0.8774 - val_loss: 1.2829\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0063 - val_accuracy: 0.8764 - val_loss: 1.3425\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0080 - val_accuracy: 0.8743 - val_loss: 1.3736\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0078 - val_accuracy: 0.8749 - val_loss: 1.3325\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0071 - val_accuracy: 0.8780 - val_loss: 1.3219\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0073 - val_accuracy: 0.8752 - val_loss: 1.3402\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.8764 - val_loss: 1.3463\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.8721 - val_loss: 1.3527\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0060 - val_accuracy: 0.8768 - val_loss: 1.2748\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0083 - val_accuracy: 0.8755 - val_loss: 1.3429\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.8739 - val_loss: 1.3478\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0080 - val_accuracy: 0.8724 - val_loss: 1.3267\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0046 - val_accuracy: 0.8711 - val_loss: 1.4076\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.8708 - val_loss: 1.4973\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0068 - val_accuracy: 0.8758 - val_loss: 1.4050\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.8736 - val_loss: 1.3610\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0067 - val_accuracy: 0.8764 - val_loss: 1.3773\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0065 - val_accuracy: 0.8736 - val_loss: 1.4255\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0081 - val_accuracy: 0.8746 - val_loss: 1.4298\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0047 - val_accuracy: 0.8749 - val_loss: 1.4740\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0054 - val_accuracy: 0.8780 - val_loss: 1.3956\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0064 - val_accuracy: 0.8768 - val_loss: 1.4082\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0095 - val_accuracy: 0.8764 - val_loss: 1.4395\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0050 - val_accuracy: 0.8755 - val_loss: 1.4060\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0079 - val_accuracy: 0.8780 - val_loss: 1.3137\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0081 - val_accuracy: 0.8758 - val_loss: 1.3243\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.8752 - val_loss: 1.3584\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.8764 - val_loss: 1.3428\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.8761 - val_loss: 1.3384\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0052 - val_accuracy: 0.8780 - val_loss: 1.3527\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0086 - val_accuracy: 0.8774 - val_loss: 1.3465\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0055 - val_accuracy: 0.8771 - val_loss: 1.3582\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.8774 - val_loss: 1.3669\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.8774 - val_loss: 1.3719\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.8739 - val_loss: 1.3548\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0081 - val_accuracy: 0.8774 - val_loss: 1.3356\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0059 - val_accuracy: 0.8755 - val_loss: 1.3497\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0057 - val_accuracy: 0.8764 - val_loss: 1.3717\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0064 - val_accuracy: 0.8793 - val_loss: 1.3181\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.8783 - val_loss: 1.3773\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0044 - val_accuracy: 0.8774 - val_loss: 1.3226\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0082 - val_accuracy: 0.8758 - val_loss: 1.3636\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0053 - val_accuracy: 0.8755 - val_loss: 1.3455\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.8789 - val_loss: 1.2754\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.8771 - val_loss: 1.3295\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0075 - val_accuracy: 0.8780 - val_loss: 1.2950\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0054 - val_accuracy: 0.8780 - val_loss: 1.3414\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0050 - val_accuracy: 0.8715 - val_loss: 1.4104\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0059 - val_accuracy: 0.8743 - val_loss: 1.3502\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.8730 - val_loss: 1.4452\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0051 - val_accuracy: 0.8743 - val_loss: 1.4156\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 0.8746 - val_loss: 1.3705\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0082 - val_accuracy: 0.8761 - val_loss: 1.2888\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0068 - val_accuracy: 0.8736 - val_loss: 1.3758\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.8733 - val_loss: 1.3432\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.8758 - val_loss: 1.3875\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0081 - val_accuracy: 0.8755 - val_loss: 1.3318\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0054 - val_accuracy: 0.8743 - val_loss: 1.4122\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0057 - val_accuracy: 0.8733 - val_loss: 1.3543\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0049 - val_accuracy: 0.8746 - val_loss: 1.3660\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0069 - val_accuracy: 0.8768 - val_loss: 1.3773\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.8758 - val_loss: 1.3823\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0065 - val_accuracy: 0.8764 - val_loss: 1.3405\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.8743 - val_loss: 1.4330\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0039 - val_accuracy: 0.8758 - val_loss: 1.4737\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.8746 - val_loss: 1.5009\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0057 - val_accuracy: 0.8739 - val_loss: 1.4127\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0042 - val_accuracy: 0.8764 - val_loss: 1.4516\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.8774 - val_loss: 1.4484\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0050 - val_accuracy: 0.8755 - val_loss: 1.4671\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0083 - val_accuracy: 0.8752 - val_loss: 1.4462\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0046 - val_accuracy: 0.8780 - val_loss: 1.3693\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0074 - val_accuracy: 0.8743 - val_loss: 1.4306\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0064 - val_accuracy: 0.8743 - val_loss: 1.4712\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0044 - val_accuracy: 0.8789 - val_loss: 1.4283\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0048 - val_accuracy: 0.8793 - val_loss: 1.3109\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0072 - val_accuracy: 0.8739 - val_loss: 1.3537\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0072 - val_accuracy: 0.8749 - val_loss: 1.4148\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0039 - val_accuracy: 0.8736 - val_loss: 1.4320\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.8749 - val_loss: 1.4275\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.8758 - val_loss: 1.3979\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.8727 - val_loss: 1.5239\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.8789 - val_loss: 1.4193\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.8817 - val_loss: 1.4158\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0055 - val_accuracy: 0.8746 - val_loss: 1.4293\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0057 - val_accuracy: 0.8743 - val_loss: 1.5044\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0067 - val_accuracy: 0.8755 - val_loss: 1.5190\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.8764 - val_loss: 1.4778\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0081 - val_accuracy: 0.8736 - val_loss: 1.4545\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0038 - val_accuracy: 0.8755 - val_loss: 1.4174\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0072 - val_accuracy: 0.8768 - val_loss: 1.4226\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0060 - val_accuracy: 0.8799 - val_loss: 1.4222\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.8739 - val_loss: 1.5176\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0067 - val_accuracy: 0.8752 - val_loss: 1.5041\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0039 - val_accuracy: 0.8780 - val_loss: 1.4524\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0110 - val_accuracy: 0.8774 - val_loss: 1.4322\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0048 - val_accuracy: 0.8780 - val_loss: 1.4418\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0055 - val_accuracy: 0.8721 - val_loss: 1.4944\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0073 - val_accuracy: 0.8755 - val_loss: 1.4138\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0044 - val_accuracy: 0.8658 - val_loss: 1.6203\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0078 - val_accuracy: 0.8696 - val_loss: 1.5584\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.8761 - val_loss: 1.4801\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0047 - val_accuracy: 0.8768 - val_loss: 1.5225\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.8774 - val_loss: 1.5168\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.8724 - val_loss: 1.5019\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0066 - val_accuracy: 0.8752 - val_loss: 1.4429\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.8746 - val_loss: 1.4340\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0057 - val_accuracy: 0.8755 - val_loss: 1.4608\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0047 - val_accuracy: 0.8743 - val_loss: 1.4816\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0063 - val_accuracy: 0.8749 - val_loss: 1.4839\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0042 - val_accuracy: 0.8761 - val_loss: 1.4906\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0054 - val_accuracy: 0.8746 - val_loss: 1.5270\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.8783 - val_loss: 1.5152\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0055 - val_accuracy: 0.8783 - val_loss: 1.4530\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.8777 - val_loss: 1.5011\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.8749 - val_loss: 1.5295\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.8755 - val_loss: 1.5393\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0045 - val_accuracy: 0.8768 - val_loss: 1.5343\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0041 - val_accuracy: 0.8752 - val_loss: 1.5450\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0050 - val_accuracy: 0.8758 - val_loss: 1.5368\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0084 - val_accuracy: 0.8746 - val_loss: 1.5414\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.8783 - val_loss: 1.5606\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.8739 - val_loss: 1.5263\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0052 - val_accuracy: 0.8758 - val_loss: 1.4763\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0031 - val_accuracy: 0.8761 - val_loss: 1.5260\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.8774 - val_loss: 1.5018\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0048 - val_accuracy: 0.8752 - val_loss: 1.5449\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.8768 - val_loss: 1.4753\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0089 - val_accuracy: 0.8774 - val_loss: 1.4493\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.8768 - val_loss: 1.4301\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0059 - val_accuracy: 0.8746 - val_loss: 1.4376\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.8736 - val_loss: 1.4816\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0049 - val_accuracy: 0.8696 - val_loss: 1.5241\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.8705 - val_loss: 1.4986\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0036 - val_accuracy: 0.8739 - val_loss: 1.4835\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0057 - val_accuracy: 0.8680 - val_loss: 1.5515\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0059 - val_accuracy: 0.8746 - val_loss: 1.5117\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.8743 - val_loss: 1.4759\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.8693 - val_loss: 1.4801\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.8736 - val_loss: 1.4732\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.8743 - val_loss: 1.4718\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0041 - val_accuracy: 0.8715 - val_loss: 1.5187\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0069 - val_accuracy: 0.8683 - val_loss: 1.5800\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0063 - val_accuracy: 0.8730 - val_loss: 1.5168\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.8739 - val_loss: 1.5741\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0042 - val_accuracy: 0.8727 - val_loss: 1.5389\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0056 - val_accuracy: 0.8758 - val_loss: 1.5159\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0069 - val_accuracy: 0.8768 - val_loss: 1.5579\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0068 - val_accuracy: 0.8777 - val_loss: 1.5532\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.8768 - val_loss: 1.4963\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.8783 - val_loss: 1.5375\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.8761 - val_loss: 1.5359\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0105 - val_accuracy: 0.8764 - val_loss: 1.4887\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.8739 - val_loss: 1.5110\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.8761 - val_loss: 1.5341\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0042 - val_accuracy: 0.8733 - val_loss: 1.5732\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0063 - val_accuracy: 0.8730 - val_loss: 1.5780\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.8693 - val_loss: 1.5706\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0086 - val_accuracy: 0.8764 - val_loss: 1.4964\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.8768 - val_loss: 1.5292\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.8768 - val_loss: 1.5516\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0046 - val_accuracy: 0.8752 - val_loss: 1.5466\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.8743 - val_loss: 1.5998\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.8736 - val_loss: 1.6066\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0045 - val_accuracy: 0.8749 - val_loss: 1.5879\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0046 - val_accuracy: 0.8755 - val_loss: 1.5962\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0046 - val_accuracy: 0.8743 - val_loss: 1.4624\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0059 - val_accuracy: 0.8739 - val_loss: 1.5110\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0045 - val_accuracy: 0.8733 - val_loss: 1.5201\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0072 - val_accuracy: 0.8768 - val_loss: 1.4925\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0045 - val_accuracy: 0.8777 - val_loss: 1.4460\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.8771 - val_loss: 1.4810\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0055 - val_accuracy: 0.8749 - val_loss: 1.5284\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0044 - val_accuracy: 0.8746 - val_loss: 1.4721\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0036 - val_accuracy: 0.8743 - val_loss: 1.4573\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.8733 - val_loss: 1.5293\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0034 - val_accuracy: 0.8739 - val_loss: 1.5520\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.8755 - val_loss: 1.4876\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0053 - val_accuracy: 0.8724 - val_loss: 1.5367\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.8755 - val_loss: 1.5419\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0047 - val_accuracy: 0.8727 - val_loss: 1.5674\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0040 - val_accuracy: 0.8721 - val_loss: 1.5469\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.8724 - val_loss: 1.4987\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0042 - val_accuracy: 0.8733 - val_loss: 1.5403\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0033 - val_accuracy: 0.8727 - val_loss: 1.5499\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.8752 - val_loss: 1.5319\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.8755 - val_loss: 1.5127\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.8721 - val_loss: 1.5740\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.8749 - val_loss: 1.4589\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0047 - val_accuracy: 0.8715 - val_loss: 1.5269\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0023 - val_accuracy: 0.8743 - val_loss: 1.5521\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.8758 - val_loss: 1.4978\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 0.8733 - val_loss: 1.4865\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.8752 - val_loss: 1.4644\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.8743 - val_loss: 1.4416\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.8739 - val_loss: 1.4540\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.8749 - val_loss: 1.5443\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0027 - val_accuracy: 0.8702 - val_loss: 1.5652\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0071 - val_accuracy: 0.8743 - val_loss: 1.4774\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0055 - val_accuracy: 0.8749 - val_loss: 1.4915\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.8749 - val_loss: 1.5388\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.8736 - val_loss: 1.5703\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0077 - val_accuracy: 0.8721 - val_loss: 1.4936\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.8718 - val_loss: 1.5989\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.8736 - val_loss: 1.5327\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0061 - val_accuracy: 0.8752 - val_loss: 1.5091\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0086 - val_accuracy: 0.8733 - val_loss: 1.4649\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0055 - val_accuracy: 0.8721 - val_loss: 1.5213\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0035 - val_accuracy: 0.8761 - val_loss: 1.4976\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.8736 - val_loss: 1.5742\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.8686 - val_loss: 1.5803\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.8739 - val_loss: 1.5355\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.8743 - val_loss: 1.5749\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0100 - val_accuracy: 0.8711 - val_loss: 1.6012\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.8730 - val_loss: 1.5615\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.8727 - val_loss: 1.5916\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.8755 - val_loss: 1.5570\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0068 - val_accuracy: 0.8708 - val_loss: 1.5830\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0030 - val_accuracy: 0.8708 - val_loss: 1.6068\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.8733 - val_loss: 1.5394\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0035 - val_accuracy: 0.8699 - val_loss: 1.6453\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.8693 - val_loss: 1.6027\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.8755 - val_loss: 1.5427\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0053 - val_accuracy: 0.8739 - val_loss: 1.5560\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.8708 - val_loss: 1.5859\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 0.8736 - val_loss: 1.5666\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.8733 - val_loss: 1.5812\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.8721 - val_loss: 1.6171\n\n\n\n\nINFO: Training model for R_ANKLE_injury_risk...\nINFO: Loaded 8 features for R_ANKLE_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 8), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 8), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.8413 - loss: 0.3731 - val_accuracy: 0.8499 - val_loss: 0.3405\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8820 - loss: 0.2589 - val_accuracy: 0.8608 - val_loss: 0.3042\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8915 - loss: 0.2347 - val_accuracy: 0.8696 - val_loss: 0.3051\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8902 - loss: 0.2282 - val_accuracy: 0.8708 - val_loss: 0.2965\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8994 - loss: 0.2154 - val_accuracy: 0.8724 - val_loss: 0.3075\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8991 - loss: 0.2114 - val_accuracy: 0.8746 - val_loss: 0.3177\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9057 - loss: 0.2011 - val_accuracy: 0.8758 - val_loss: 0.3159\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9136 - loss: 0.1891 - val_accuracy: 0.8789 - val_loss: 0.3209\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9093 - loss: 0.1877 - val_accuracy: 0.8814 - val_loss: 0.3207\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9160 - loss: 0.1770 - val_accuracy: 0.8702 - val_loss: 0.3480\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9085 - loss: 0.1795 - val_accuracy: 0.8630 - val_loss: 0.3601\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9202 - loss: 0.1685 - val_accuracy: 0.8746 - val_loss: 0.3525\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9186 - loss: 0.1681 - val_accuracy: 0.8727 - val_loss: 0.3632\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9265 - loss: 0.1559 - val_accuracy: 0.8708 - val_loss: 0.3489\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9236 - loss: 0.1571 - val_accuracy: 0.8677 - val_loss: 0.3972\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9303 - loss: 0.1475 - val_accuracy: 0.8796 - val_loss: 0.3653\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9313 - loss: 0.1477 - val_accuracy: 0.8702 - val_loss: 0.3753\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9318 - loss: 0.1417 - val_accuracy: 0.8543 - val_loss: 0.3894\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9351 - loss: 0.1386 - val_accuracy: 0.8705 - val_loss: 0.3850\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9367 - loss: 0.1358 - val_accuracy: 0.8764 - val_loss: 0.3800\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9370 - loss: 0.1309 - val_accuracy: 0.8655 - val_loss: 0.4003\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9372 - loss: 0.1299 - val_accuracy: 0.8633 - val_loss: 0.4303\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9382 - loss: 0.1281 - val_accuracy: 0.8849 - val_loss: 0.3884\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9423 - loss: 0.1215 - val_accuracy: 0.8727 - val_loss: 0.4090\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9446 - loss: 0.1193 - val_accuracy: 0.8746 - val_loss: 0.4200\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9457 - loss: 0.1178 - val_accuracy: 0.8839 - val_loss: 0.4100\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9461 - loss: 0.1152 - val_accuracy: 0.8739 - val_loss: 0.4233\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9485 - loss: 0.1079 - val_accuracy: 0.8730 - val_loss: 0.4317\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9476 - loss: 0.1077 - val_accuracy: 0.8849 - val_loss: 0.4514\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9485 - loss: 0.1089 - val_accuracy: 0.8702 - val_loss: 0.4685\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9509 - loss: 0.1029 - val_accuracy: 0.8749 - val_loss: 0.4743\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9520 - loss: 0.0983 - val_accuracy: 0.8852 - val_loss: 0.4750\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9541 - loss: 0.0990 - val_accuracy: 0.8902 - val_loss: 0.4625\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9530 - loss: 0.1014 - val_accuracy: 0.8771 - val_loss: 0.4766\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9538 - loss: 0.0960 - val_accuracy: 0.8796 - val_loss: 0.5155\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9582 - loss: 0.0895 - val_accuracy: 0.8711 - val_loss: 0.5499\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9578 - loss: 0.0897 - val_accuracy: 0.8780 - val_loss: 0.5581\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9533 - loss: 0.0949 - val_accuracy: 0.8783 - val_loss: 0.5592\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9596 - loss: 0.0871 - val_accuracy: 0.8739 - val_loss: 0.5406\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9602 - loss: 0.0851 - val_accuracy: 0.8786 - val_loss: 0.5470\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9591 - loss: 0.0840 - val_accuracy: 0.8786 - val_loss: 0.5901\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9676 - loss: 0.0744 - val_accuracy: 0.8708 - val_loss: 0.5577\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9645 - loss: 0.0778 - val_accuracy: 0.8727 - val_loss: 0.5986\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9666 - loss: 0.0714 - val_accuracy: 0.8715 - val_loss: 0.6134\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9683 - loss: 0.0743 - val_accuracy: 0.8746 - val_loss: 0.6088\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9680 - loss: 0.0685 - val_accuracy: 0.8783 - val_loss: 0.5769\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9673 - loss: 0.0706 - val_accuracy: 0.8733 - val_loss: 0.6718\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9697 - loss: 0.0653 - val_accuracy: 0.8696 - val_loss: 0.6870\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9728 - loss: 0.0594 - val_accuracy: 0.8705 - val_loss: 0.6798\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9689 - loss: 0.0639 - val_accuracy: 0.8774 - val_loss: 0.6908\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9724 - loss: 0.0609 - val_accuracy: 0.8668 - val_loss: 0.7112\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9738 - loss: 0.0623 - val_accuracy: 0.8618 - val_loss: 0.7941\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9728 - loss: 0.0574 - val_accuracy: 0.8780 - val_loss: 0.6895\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9760 - loss: 0.0549 - val_accuracy: 0.8739 - val_loss: 0.7354\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9745 - loss: 0.0593 - val_accuracy: 0.8827 - val_loss: 0.7091\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9743 - loss: 0.0564 - val_accuracy: 0.8649 - val_loss: 0.8081\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9791 - loss: 0.0484 - val_accuracy: 0.8768 - val_loss: 0.8111\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9795 - loss: 0.0498 - val_accuracy: 0.8739 - val_loss: 0.7603\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9765 - loss: 0.0513 - val_accuracy: 0.8789 - val_loss: 0.7743\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9784 - loss: 0.0487 - val_accuracy: 0.8799 - val_loss: 0.7724\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9779 - loss: 0.0476 - val_accuracy: 0.8743 - val_loss: 0.8247\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9770 - loss: 0.0520 - val_accuracy: 0.8783 - val_loss: 0.8083\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9768 - loss: 0.0518 - val_accuracy: 0.8761 - val_loss: 0.8417\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9799 - loss: 0.0436 - val_accuracy: 0.8739 - val_loss: 0.8343\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9818 - loss: 0.0421 - val_accuracy: 0.8783 - val_loss: 0.8330\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9811 - loss: 0.0443 - val_accuracy: 0.8708 - val_loss: 0.8894\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9818 - loss: 0.0436 - val_accuracy: 0.8665 - val_loss: 0.9394\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9830 - loss: 0.0409 - val_accuracy: 0.8711 - val_loss: 0.9368\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9811 - loss: 0.0445 - val_accuracy: 0.8671 - val_loss: 0.8911\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9820 - loss: 0.0424 - val_accuracy: 0.8696 - val_loss: 0.9448\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9826 - loss: 0.0427 - val_accuracy: 0.8755 - val_loss: 0.8542\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9834 - loss: 0.0395 - val_accuracy: 0.8683 - val_loss: 0.9975\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9845 - loss: 0.0368 - val_accuracy: 0.8705 - val_loss: 0.9606\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9804 - loss: 0.0474 - val_accuracy: 0.8749 - val_loss: 0.9214\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9853 - loss: 0.0364 - val_accuracy: 0.8743 - val_loss: 0.9214\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9859 - loss: 0.0340 - val_accuracy: 0.8674 - val_loss: 0.9818\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9850 - loss: 0.0375 - val_accuracy: 0.8786 - val_loss: 0.8750\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9881 - loss: 0.0321 - val_accuracy: 0.8764 - val_loss: 0.8950\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9855 - loss: 0.0341 - val_accuracy: 0.8764 - val_loss: 0.8964\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9856 - loss: 0.0366 - val_accuracy: 0.8799 - val_loss: 0.8910\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0317 - val_accuracy: 0.8715 - val_loss: 0.9756\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0294 - val_accuracy: 0.8730 - val_loss: 0.9443\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9855 - loss: 0.0333 - val_accuracy: 0.8758 - val_loss: 0.9987\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9868 - loss: 0.0321 - val_accuracy: 0.8696 - val_loss: 0.9633\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0333 - val_accuracy: 0.8724 - val_loss: 0.9348\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9846 - loss: 0.0354 - val_accuracy: 0.8752 - val_loss: 0.9137\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0289 - val_accuracy: 0.8752 - val_loss: 0.9223\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9896 - loss: 0.0272 - val_accuracy: 0.8743 - val_loss: 0.9694\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0363 - val_accuracy: 0.8730 - val_loss: 1.0341\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9863 - loss: 0.0327 - val_accuracy: 0.8752 - val_loss: 0.9540\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0297 - val_accuracy: 0.8733 - val_loss: 0.9514\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9906 - loss: 0.0251 - val_accuracy: 0.8724 - val_loss: 1.0440\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9853 - loss: 0.0368 - val_accuracy: 0.8715 - val_loss: 1.0012\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0312 - val_accuracy: 0.8733 - val_loss: 0.9808\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0253 - val_accuracy: 0.8696 - val_loss: 1.0843\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9896 - loss: 0.0266 - val_accuracy: 0.8764 - val_loss: 0.9386\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0222 - val_accuracy: 0.8749 - val_loss: 1.0070\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0246 - val_accuracy: 0.8683 - val_loss: 1.0012\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0292 - val_accuracy: 0.8718 - val_loss: 0.9646\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0255 - val_accuracy: 0.8768 - val_loss: 0.9459\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0245 - val_accuracy: 0.8777 - val_loss: 0.9420\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0248 - val_accuracy: 0.8749 - val_loss: 0.9448\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9889 - loss: 0.0262 - val_accuracy: 0.8718 - val_loss: 1.0225\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0236 - val_accuracy: 0.8761 - val_loss: 0.9723\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0223 - val_accuracy: 0.8721 - val_loss: 1.0757\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0176 - val_accuracy: 0.8777 - val_loss: 0.9659\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0292 - val_accuracy: 0.8793 - val_loss: 1.0095\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0204 - val_accuracy: 0.8699 - val_loss: 1.1097\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0202 - val_accuracy: 0.8680 - val_loss: 1.1232\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0228 - val_accuracy: 0.8736 - val_loss: 1.0854\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9920 - loss: 0.0207 - val_accuracy: 0.8711 - val_loss: 1.0770\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0230 - val_accuracy: 0.8749 - val_loss: 0.9484\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0247 - val_accuracy: 0.8783 - val_loss: 0.9913\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0188 - val_accuracy: 0.8727 - val_loss: 1.0351\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0186 - val_accuracy: 0.8786 - val_loss: 1.0321\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0170 - val_accuracy: 0.8724 - val_loss: 1.0551\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0164 - val_accuracy: 0.8708 - val_loss: 1.0636\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0297 - val_accuracy: 0.8730 - val_loss: 1.0673\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0219 - val_accuracy: 0.8696 - val_loss: 1.1238\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0244 - val_accuracy: 0.8715 - val_loss: 1.0858\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0160 - val_accuracy: 0.8693 - val_loss: 1.0983\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0170 - val_accuracy: 0.8708 - val_loss: 1.0529\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0207 - val_accuracy: 0.8718 - val_loss: 1.0809\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0182 - val_accuracy: 0.8736 - val_loss: 1.0258\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0174 - val_accuracy: 0.8752 - val_loss: 1.0543\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0222 - val_accuracy: 0.8724 - val_loss: 1.0424\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0177 - val_accuracy: 0.8708 - val_loss: 1.0957\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0179 - val_accuracy: 0.8836 - val_loss: 1.0369\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0197 - val_accuracy: 0.8721 - val_loss: 1.0726\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0148 - val_accuracy: 0.8752 - val_loss: 1.1067\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9920 - loss: 0.0211 - val_accuracy: 0.8768 - val_loss: 1.1137\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0196 - val_accuracy: 0.8693 - val_loss: 1.1551\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0198 - val_accuracy: 0.8758 - val_loss: 1.1156\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0133 - val_accuracy: 0.8786 - val_loss: 1.1142\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0309 - val_accuracy: 0.8739 - val_loss: 1.0982\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0155 - val_accuracy: 0.8702 - val_loss: 1.1151\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0173 - val_accuracy: 0.8705 - val_loss: 1.1090\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0134 - val_accuracy: 0.8752 - val_loss: 1.0953\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0104 - val_accuracy: 0.8727 - val_loss: 1.1788\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0161 - val_accuracy: 0.8733 - val_loss: 1.1451\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0171 - val_accuracy: 0.8739 - val_loss: 1.1292\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0154 - val_accuracy: 0.8711 - val_loss: 1.1334\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0191 - val_accuracy: 0.8702 - val_loss: 1.0969\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0123 - val_accuracy: 0.8696 - val_loss: 1.1538\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0109 - val_accuracy: 0.8686 - val_loss: 1.1928\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0134 - val_accuracy: 0.8702 - val_loss: 1.1445\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0173 - val_accuracy: 0.8696 - val_loss: 1.1837\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0111 - val_accuracy: 0.8755 - val_loss: 1.1223\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0156 - val_accuracy: 0.8739 - val_loss: 1.0593\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0175 - val_accuracy: 0.8661 - val_loss: 1.1201\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0139 - val_accuracy: 0.8724 - val_loss: 1.1296\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0151 - val_accuracy: 0.8683 - val_loss: 1.2001\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 0.8739 - val_loss: 1.0986\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0147 - val_accuracy: 0.8743 - val_loss: 1.1094\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0100 - val_accuracy: 0.8743 - val_loss: 1.1623\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0171 - val_accuracy: 0.8793 - val_loss: 1.0661\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0217 - val_accuracy: 0.8771 - val_loss: 1.0111\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0109 - val_accuracy: 0.8736 - val_loss: 1.0754\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0131 - val_accuracy: 0.8764 - val_loss: 1.1270\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0154 - val_accuracy: 0.8743 - val_loss: 1.1590\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0087 - val_accuracy: 0.8708 - val_loss: 1.1166\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0167 - val_accuracy: 0.8761 - val_loss: 1.1145\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0093 - val_accuracy: 0.8768 - val_loss: 1.1014\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0150 - val_accuracy: 0.8824 - val_loss: 1.0875\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0174 - val_accuracy: 0.8655 - val_loss: 1.1643\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0085 - val_accuracy: 0.8705 - val_loss: 1.2011\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0078 - val_accuracy: 0.8637 - val_loss: 1.2829\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0101 - val_accuracy: 0.8652 - val_loss: 1.2282\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0153 - val_accuracy: 0.8627 - val_loss: 1.1894\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0202 - val_accuracy: 0.8705 - val_loss: 1.1500\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0141 - val_accuracy: 0.8705 - val_loss: 1.1727\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0099 - val_accuracy: 0.8708 - val_loss: 1.1444\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0121 - val_accuracy: 0.8774 - val_loss: 1.1168\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0166 - val_accuracy: 0.8733 - val_loss: 1.0977\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0105 - val_accuracy: 0.8739 - val_loss: 1.1500\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.8721 - val_loss: 1.2363\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0070 - val_accuracy: 0.8661 - val_loss: 1.3201\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0129 - val_accuracy: 0.8749 - val_loss: 1.1815\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0156 - val_accuracy: 0.8755 - val_loss: 1.1448\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0093 - val_accuracy: 0.8752 - val_loss: 1.2319\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.8755 - val_loss: 1.2006\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.8718 - val_loss: 1.2031\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0102 - val_accuracy: 0.8752 - val_loss: 1.1832\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0159 - val_accuracy: 0.8764 - val_loss: 1.2349\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0122 - val_accuracy: 0.8771 - val_loss: 1.1568\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0083 - val_accuracy: 0.8802 - val_loss: 1.1445\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0093 - val_accuracy: 0.8727 - val_loss: 1.1794\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0186 - val_accuracy: 0.8711 - val_loss: 1.1308\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.8693 - val_loss: 1.2439\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.8774 - val_loss: 1.1485\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0081 - val_accuracy: 0.8724 - val_loss: 1.2288\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0096 - val_accuracy: 0.8768 - val_loss: 1.1520\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0117 - val_accuracy: 0.8768 - val_loss: 1.1579\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0063 - val_accuracy: 0.8727 - val_loss: 1.1837\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0196 - val_accuracy: 0.8749 - val_loss: 1.1631\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0125 - val_accuracy: 0.8683 - val_loss: 1.1469\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0121 - val_accuracy: 0.8752 - val_loss: 1.1300\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0235 - val_accuracy: 0.8736 - val_loss: 1.0726\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0092 - val_accuracy: 0.8752 - val_loss: 1.1382\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0056 - val_accuracy: 0.8711 - val_loss: 1.1994\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0093 - val_accuracy: 0.8683 - val_loss: 1.2177\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0153 - val_accuracy: 0.8702 - val_loss: 1.2452\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0083 - val_accuracy: 0.8733 - val_loss: 1.1982\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 0.8736 - val_loss: 1.1964\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0058 - val_accuracy: 0.8724 - val_loss: 1.2519\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.8705 - val_loss: 1.2011\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0162 - val_accuracy: 0.8739 - val_loss: 1.1256\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0128 - val_accuracy: 0.8739 - val_loss: 1.1455\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0096 - val_accuracy: 0.8677 - val_loss: 1.2008\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0065 - val_accuracy: 0.8708 - val_loss: 1.1898\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.8702 - val_loss: 1.1978\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0109 - val_accuracy: 0.8730 - val_loss: 1.2415\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0059 - val_accuracy: 0.8718 - val_loss: 1.2394\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0127 - val_accuracy: 0.8699 - val_loss: 1.2423\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0219 - val_accuracy: 0.8715 - val_loss: 1.1228\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.8733 - val_loss: 1.1911\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.8817 - val_loss: 1.1318\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0069 - val_accuracy: 0.8690 - val_loss: 1.2278\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0142 - val_accuracy: 0.8743 - val_loss: 1.1678\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0083 - val_accuracy: 0.8686 - val_loss: 1.2279\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0207 - val_accuracy: 0.8671 - val_loss: 1.1988\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0087 - val_accuracy: 0.8715 - val_loss: 1.1672\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0064 - val_accuracy: 0.8749 - val_loss: 1.1937\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0073 - val_accuracy: 0.8743 - val_loss: 1.2052\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.8749 - val_loss: 1.1739\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0081 - val_accuracy: 0.8774 - val_loss: 1.1383\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.8690 - val_loss: 1.2345\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.8780 - val_loss: 1.2018\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 0.8705 - val_loss: 1.1892\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0090 - val_accuracy: 0.8749 - val_loss: 1.1525\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0130 - val_accuracy: 0.8730 - val_loss: 1.1352\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.8724 - val_loss: 1.1694\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0144 - val_accuracy: 0.8655 - val_loss: 1.1029\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 0.8658 - val_loss: 1.1492\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.8711 - val_loss: 1.1807\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0048 - val_accuracy: 0.8696 - val_loss: 1.2096\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.8736 - val_loss: 1.1699\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0121 - val_accuracy: 0.8693 - val_loss: 1.1596\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0048 - val_accuracy: 0.8715 - val_loss: 1.1753\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.8733 - val_loss: 1.2254\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0068 - val_accuracy: 0.8718 - val_loss: 1.1830\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0089 - val_accuracy: 0.8749 - val_loss: 1.1085\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0122 - val_accuracy: 0.8768 - val_loss: 1.1129\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 0.8736 - val_loss: 1.1154\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0099 - val_accuracy: 0.8702 - val_loss: 1.1632\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0108 - val_accuracy: 0.8743 - val_loss: 1.1445\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.8783 - val_loss: 1.1741\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0037 - val_accuracy: 0.8727 - val_loss: 1.1852\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.8702 - val_loss: 1.2442\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.8774 - val_loss: 1.2147\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0136 - val_accuracy: 0.8777 - val_loss: 1.1898\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0096 - val_accuracy: 0.8655 - val_loss: 1.2444\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0106 - val_accuracy: 0.8711 - val_loss: 1.2304\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.8752 - val_loss: 1.2303\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.8730 - val_loss: 1.2562\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 0.8724 - val_loss: 1.2676\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.8736 - val_loss: 1.2351\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.8761 - val_loss: 1.2195\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0099 - val_accuracy: 0.8683 - val_loss: 1.2451\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0063 - val_accuracy: 0.8671 - val_loss: 1.2510\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0082 - val_accuracy: 0.8755 - val_loss: 1.1891\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0166 - val_accuracy: 0.8708 - val_loss: 1.2228\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.8752 - val_loss: 1.2269\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0152 - val_accuracy: 0.8743 - val_loss: 1.1711\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.8708 - val_loss: 1.2039\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.8761 - val_loss: 1.2084\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0077 - val_accuracy: 0.8736 - val_loss: 1.2529\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0076 - val_accuracy: 0.8711 - val_loss: 1.2415\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.8649 - val_loss: 1.3129\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0080 - val_accuracy: 0.8836 - val_loss: 1.0691\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0087 - val_accuracy: 0.8749 - val_loss: 1.1628\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.8761 - val_loss: 1.1605\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0065 - val_accuracy: 0.8633 - val_loss: 1.2376\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0063 - val_accuracy: 0.8655 - val_loss: 1.1557\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0366 - val_accuracy: 0.8677 - val_loss: 1.2072\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.8743 - val_loss: 1.1902\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.8715 - val_loss: 1.1920\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.8711 - val_loss: 1.2110\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0084 - val_accuracy: 0.8686 - val_loss: 1.2182\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0079 - val_accuracy: 0.8761 - val_loss: 1.1155\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.8739 - val_loss: 1.1742\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.8683 - val_loss: 1.2174\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.8758 - val_loss: 1.1763\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0069 - val_accuracy: 0.8711 - val_loss: 1.2301\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 0.8674 - val_loss: 1.2335\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0029 - val_accuracy: 0.8739 - val_loss: 1.1723\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.8721 - val_loss: 1.1961\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0320 - val_accuracy: 0.8771 - val_loss: 1.1214\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.8649 - val_loss: 1.2248\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.8696 - val_loss: 1.2078\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.8736 - val_loss: 1.2082\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.8718 - val_loss: 1.2556\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.8777 - val_loss: 1.2051\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0152 - val_accuracy: 0.8686 - val_loss: 1.2598\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0076 - val_accuracy: 0.8721 - val_loss: 1.1749\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.8724 - val_loss: 1.2299\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0078 - val_accuracy: 0.8649 - val_loss: 1.2251\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.8715 - val_loss: 1.2309\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.8640 - val_loss: 1.2854\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.8690 - val_loss: 1.2161\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0049 - val_accuracy: 0.8699 - val_loss: 1.2087\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 0.8749 - val_loss: 1.1781\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0081 - val_accuracy: 0.8633 - val_loss: 1.2883\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 0.8652 - val_loss: 1.2797\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.8711 - val_loss: 1.2596\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.8702 - val_loss: 1.2882\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0128 - val_accuracy: 0.8680 - val_loss: 1.2284\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.8693 - val_loss: 1.2417\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.8724 - val_loss: 1.2417\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.8668 - val_loss: 1.2867\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 0.8655 - val_loss: 1.2628\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.8668 - val_loss: 1.2290\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.8671 - val_loss: 1.2619\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.8633 - val_loss: 1.2884\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0048 - val_accuracy: 0.8718 - val_loss: 1.2526\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0047 - val_accuracy: 0.8637 - val_loss: 1.3289\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.8661 - val_loss: 1.3521\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0052 - val_accuracy: 0.8708 - val_loss: 1.2830\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0121 - val_accuracy: 0.8677 - val_loss: 1.2734\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.8702 - val_loss: 1.2541\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.8671 - val_loss: 1.2754\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.8661 - val_loss: 1.2636\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0051 - val_accuracy: 0.8680 - val_loss: 1.2767\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.8683 - val_loss: 1.3012\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0178 - val_accuracy: 0.8668 - val_loss: 1.2761\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0110 - val_accuracy: 0.8615 - val_loss: 1.3196\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0125 - val_accuracy: 0.8677 - val_loss: 1.2447\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.8708 - val_loss: 1.2617\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.8655 - val_loss: 1.2714\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0041 - val_accuracy: 0.8640 - val_loss: 1.2866\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.8683 - val_loss: 1.2767\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0027 - val_accuracy: 0.8686 - val_loss: 1.3069\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 0.8612 - val_loss: 1.3085\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0055 - val_accuracy: 0.8696 - val_loss: 1.2807\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.8690 - val_loss: 1.2926\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.8677 - val_loss: 1.3402\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0159 - val_accuracy: 0.8683 - val_loss: 1.2641\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0063 - val_accuracy: 0.8755 - val_loss: 1.1985\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.8708 - val_loss: 1.2868\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.8693 - val_loss: 1.2992\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.8730 - val_loss: 1.2739\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.8708 - val_loss: 1.2625\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0071 - val_accuracy: 0.8811 - val_loss: 1.2233\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.8724 - val_loss: 1.2778\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.8715 - val_loss: 1.2453\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0069 - val_accuracy: 0.8727 - val_loss: 1.2474\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0242 - val_accuracy: 0.8711 - val_loss: 1.2514\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.8696 - val_loss: 1.2617\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.8686 - val_loss: 1.3095\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0088 - val_accuracy: 0.8702 - val_loss: 1.2431\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.8674 - val_loss: 1.2583\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.8699 - val_loss: 1.2892\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.8715 - val_loss: 1.2802\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.8661 - val_loss: 1.3258\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0109 - val_accuracy: 0.8721 - val_loss: 1.2541\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0083 - val_accuracy: 0.8702 - val_loss: 1.2429\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.8727 - val_loss: 1.2180\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.8743 - val_loss: 1.2381\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.8755 - val_loss: 1.2739\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0048 - val_accuracy: 0.8771 - val_loss: 1.2446\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.8649 - val_loss: 1.2840\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0089 - val_accuracy: 0.8715 - val_loss: 1.2471\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.8711 - val_loss: 1.2671\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.8624 - val_loss: 1.3590\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 0.8727 - val_loss: 1.2846\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0069 - val_accuracy: 0.8686 - val_loss: 1.2360\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.8715 - val_loss: 1.2849\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.8690 - val_loss: 1.2547\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.8680 - val_loss: 1.2853\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.8702 - val_loss: 1.3106\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.8711 - val_loss: 1.2895\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 0.8668 - val_loss: 1.2920\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0075 - val_accuracy: 0.8702 - val_loss: 1.2644\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0049 - val_accuracy: 0.8746 - val_loss: 1.2308\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.8699 - val_loss: 1.3006\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.8721 - val_loss: 1.2849\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.8733 - val_loss: 1.3073\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.8699 - val_loss: 1.3157\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.8715 - val_loss: 1.3088\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0016 - val_accuracy: 0.8718 - val_loss: 1.3258\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.8705 - val_loss: 1.3350\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0169 - val_accuracy: 0.8680 - val_loss: 1.2610\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.8768 - val_loss: 1.2174\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.8758 - val_loss: 1.2082\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.8718 - val_loss: 1.2508\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.8705 - val_loss: 1.2606\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.8690 - val_loss: 1.2933\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.8699 - val_loss: 1.2995\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0014 - val_accuracy: 0.8696 - val_loss: 1.3301\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 9.2237e-04 - val_accuracy: 0.8696 - val_loss: 1.3633\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0093 - val_accuracy: 0.8668 - val_loss: 1.3222\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0204 - val_accuracy: 0.8693 - val_loss: 1.2818\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.8674 - val_loss: 1.3217\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.8655 - val_loss: 1.3522\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.8705 - val_loss: 1.3187\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 0.8696 - val_loss: 1.3371\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.8643 - val_loss: 1.4115\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0185 - val_accuracy: 0.8702 - val_loss: 1.3392\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.8674 - val_loss: 1.3834\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.6686e-04 - val_accuracy: 0.8674 - val_loss: 1.4011\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 8.0166e-04 - val_accuracy: 0.8686 - val_loss: 1.3856\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.8693 - val_loss: 1.4124\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 6.4457e-04 - val_accuracy: 0.8677 - val_loss: 1.4416\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.8674 - val_loss: 1.4275\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0182 - val_accuracy: 0.8718 - val_loss: 1.3198\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.8777 - val_loss: 1.3169\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.8724 - val_loss: 1.3137\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.8724 - val_loss: 1.3467\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.8711 - val_loss: 1.3704\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.8661 - val_loss: 1.4503\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0028 - val_accuracy: 0.8711 - val_loss: 1.4062\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.8699 - val_loss: 1.4298\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0221 - val_accuracy: 0.8665 - val_loss: 1.3545\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.8705 - val_loss: 1.3415\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.8686 - val_loss: 1.3995\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.8643 - val_loss: 1.3813\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 0.8705 - val_loss: 1.3824\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 8.3023e-04 - val_accuracy: 0.8680 - val_loss: 1.4333\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0083 - val_accuracy: 0.8646 - val_loss: 1.3533\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.8705 - val_loss: 1.3588\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.8671 - val_loss: 1.3927\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.8652 - val_loss: 1.4536\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0142 - val_accuracy: 0.8674 - val_loss: 1.3399\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.8721 - val_loss: 1.3230\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0093 - val_accuracy: 0.8696 - val_loss: 1.3573\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 9.2896e-04 - val_accuracy: 0.8702 - val_loss: 1.3739\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 6.7613e-04 - val_accuracy: 0.8637 - val_loss: 1.4105\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0213 - val_accuracy: 0.8693 - val_loss: 1.2834\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.8680 - val_loss: 1.2855\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.8711 - val_loss: 1.3041\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.8755 - val_loss: 1.2991\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0073 - val_accuracy: 0.8674 - val_loss: 1.3154\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0086 - val_accuracy: 0.8718 - val_loss: 1.3078\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0076 - val_accuracy: 0.8799 - val_loss: 1.1998\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 0.8702 - val_loss: 1.2896\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0047 - val_accuracy: 0.8711 - val_loss: 1.2858\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.8702 - val_loss: 1.2957\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 9.7773e-04 - val_accuracy: 0.8708 - val_loss: 1.3199\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.8764 - val_loss: 1.2984\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.8736 - val_loss: 1.3037\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.8690 - val_loss: 1.4193\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.8668 - val_loss: 1.3888\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.8643 - val_loss: 1.4232\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.8686 - val_loss: 1.3862\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.8693 - val_loss: 1.4192\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.8693 - val_loss: 1.3494\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0150 - val_accuracy: 0.8693 - val_loss: 1.3266\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.8690 - val_loss: 1.3389\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0061 - val_accuracy: 0.8649 - val_loss: 1.3693\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.8630 - val_loss: 1.3587\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.8627 - val_loss: 1.3006\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.8718 - val_loss: 1.2499\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.8699 - val_loss: 1.2709\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.8715 - val_loss: 1.2844\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.8764 - val_loss: 1.2680\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.8749 - val_loss: 1.2924\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.8711 - val_loss: 1.3257\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 6.2250e-04 - val_accuracy: 0.8721 - val_loss: 1.3478\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.8665 - val_loss: 1.3135\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.8674 - val_loss: 1.3553\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.8730 - val_loss: 1.3113\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 9.8084e-04 - val_accuracy: 0.8649 - val_loss: 1.3753\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.8705 - val_loss: 1.3503\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0016 - val_accuracy: 0.8708 - val_loss: 1.3739\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.8658 - val_loss: 1.4379\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0064 - val_accuracy: 0.8646 - val_loss: 1.2689\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0188 - val_accuracy: 0.8708 - val_loss: 1.3356\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.8777 - val_loss: 1.3036\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.8743 - val_loss: 1.3253\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.5876e-04 - val_accuracy: 0.8733 - val_loss: 1.3208\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.5933e-04 - val_accuracy: 0.8758 - val_loss: 1.3277\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.3829e-04 - val_accuracy: 0.8758 - val_loss: 1.3550\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.7991e-04 - val_accuracy: 0.8755 - val_loss: 1.3761\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 1.8832e-04 - val_accuracy: 0.8739 - val_loss: 1.3733\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.4258e-04 - val_accuracy: 0.8702 - val_loss: 1.4094\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0076 - val_accuracy: 0.8814 - val_loss: 1.2857\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0140 - val_accuracy: 0.8746 - val_loss: 1.3358\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0036 - val_accuracy: 0.8724 - val_loss: 1.3033\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 9.7930e-04 - val_accuracy: 0.8755 - val_loss: 1.3127\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.8736 - val_loss: 1.3363\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.5877e-04 - val_accuracy: 0.8705 - val_loss: 1.3610\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 8.2625e-04 - val_accuracy: 0.8708 - val_loss: 1.3678\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.8661 - val_loss: 1.4396\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.9929e-04 - val_accuracy: 0.8674 - val_loss: 1.3551\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.8655 - val_loss: 1.4052\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0208 - val_accuracy: 0.8652 - val_loss: 1.3537\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 0.8708 - val_loss: 1.3181\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.8649 - val_loss: 1.3526\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.8643 - val_loss: 1.3897\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 5.8477e-04 - val_accuracy: 0.8658 - val_loss: 1.3926\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.8677 - val_loss: 1.3757\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 9.1804e-04 - val_accuracy: 0.8649 - val_loss: 1.4236\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.8655 - val_loss: 1.3881\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.8633 - val_loss: 1.3729\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.8718 - val_loss: 1.3790\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.8671 - val_loss: 1.4562\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 0.8627 - val_loss: 1.4838\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0071 - val_accuracy: 0.8711 - val_loss: 1.3691\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.8715 - val_loss: 1.3683\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 9.0892e-04 - val_accuracy: 0.8708 - val_loss: 1.3995\n\n\n\n\nINFO: Training model for L_WRIST_injury_risk...\nINFO: Loaded 9 features for L_WRIST_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 9), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.9110 - loss: 0.2443 - val_accuracy: 0.9725 - val_loss: 0.0631\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9667 - loss: 0.0920 - val_accuracy: 0.9775 - val_loss: 0.0508\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9703 - loss: 0.0820 - val_accuracy: 0.9710 - val_loss: 0.0657\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9689 - loss: 0.0829 - val_accuracy: 0.9738 - val_loss: 0.0579\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9676 - loss: 0.0808 - val_accuracy: 0.9772 - val_loss: 0.0537\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9730 - loss: 0.0705 - val_accuracy: 0.9775 - val_loss: 0.0524\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9725 - loss: 0.0713 - val_accuracy: 0.9747 - val_loss: 0.0584\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9702 - loss: 0.0749 - val_accuracy: 0.9785 - val_loss: 0.0512\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9702 - loss: 0.0672 - val_accuracy: 0.9775 - val_loss: 0.0517\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9686 - loss: 0.0709 - val_accuracy: 0.9775 - val_loss: 0.0547\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9719 - loss: 0.0649 - val_accuracy: 0.9788 - val_loss: 0.0507\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9701 - loss: 0.0675 - val_accuracy: 0.9760 - val_loss: 0.0548\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9723 - loss: 0.0624 - val_accuracy: 0.9763 - val_loss: 0.0553\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9734 - loss: 0.0604 - val_accuracy: 0.9763 - val_loss: 0.0526\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9752 - loss: 0.0541 - val_accuracy: 0.9785 - val_loss: 0.0535\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9753 - loss: 0.0567 - val_accuracy: 0.9772 - val_loss: 0.0546\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9783 - loss: 0.0525 - val_accuracy: 0.9747 - val_loss: 0.0565\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9784 - loss: 0.0501 - val_accuracy: 0.9763 - val_loss: 0.0539\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9764 - loss: 0.0543 - val_accuracy: 0.9769 - val_loss: 0.0557\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9798 - loss: 0.0485 - val_accuracy: 0.9757 - val_loss: 0.0542\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9817 - loss: 0.0471 - val_accuracy: 0.9729 - val_loss: 0.0626\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9793 - loss: 0.0479 - val_accuracy: 0.9769 - val_loss: 0.0530\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9793 - loss: 0.0482 - val_accuracy: 0.9772 - val_loss: 0.0542\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9783 - loss: 0.0463 - val_accuracy: 0.9772 - val_loss: 0.0514\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9782 - loss: 0.0529 - val_accuracy: 0.9782 - val_loss: 0.0514\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9824 - loss: 0.0453 - val_accuracy: 0.9788 - val_loss: 0.0510\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9797 - loss: 0.0470 - val_accuracy: 0.9797 - val_loss: 0.0518\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9805 - loss: 0.0471 - val_accuracy: 0.9782 - val_loss: 0.0512\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9813 - loss: 0.0461 - val_accuracy: 0.9791 - val_loss: 0.0499\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9782 - loss: 0.0548 - val_accuracy: 0.9791 - val_loss: 0.0512\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9819 - loss: 0.0439 - val_accuracy: 0.9788 - val_loss: 0.0510\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9827 - loss: 0.0427 - val_accuracy: 0.9769 - val_loss: 0.0549\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9816 - loss: 0.0413 - val_accuracy: 0.9788 - val_loss: 0.0518\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9833 - loss: 0.0398 - val_accuracy: 0.9778 - val_loss: 0.0526\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9824 - loss: 0.0419 - val_accuracy: 0.9782 - val_loss: 0.0508\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9834 - loss: 0.0389 - val_accuracy: 0.9782 - val_loss: 0.0505\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9836 - loss: 0.0425 - val_accuracy: 0.9788 - val_loss: 0.0508\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9822 - loss: 0.0432 - val_accuracy: 0.9797 - val_loss: 0.0499\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9850 - loss: 0.0391 - val_accuracy: 0.9754 - val_loss: 0.0569\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9827 - loss: 0.0438 - val_accuracy: 0.9788 - val_loss: 0.0496\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9846 - loss: 0.0389 - val_accuracy: 0.9778 - val_loss: 0.0497\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9831 - loss: 0.0429 - val_accuracy: 0.9785 - val_loss: 0.0503\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9817 - loss: 0.0478 - val_accuracy: 0.9775 - val_loss: 0.0526\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9837 - loss: 0.0389 - val_accuracy: 0.9763 - val_loss: 0.0527\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9845 - loss: 0.0358 - val_accuracy: 0.9800 - val_loss: 0.0495\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9829 - loss: 0.0422 - val_accuracy: 0.9788 - val_loss: 0.0546\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9836 - loss: 0.0385 - val_accuracy: 0.9754 - val_loss: 0.0615\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9821 - loss: 0.0447 - val_accuracy: 0.9760 - val_loss: 0.0539\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9867 - loss: 0.0363 - val_accuracy: 0.9775 - val_loss: 0.0541\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0347 - val_accuracy: 0.9782 - val_loss: 0.0523\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9837 - loss: 0.0408 - val_accuracy: 0.9791 - val_loss: 0.0532\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9851 - loss: 0.0341 - val_accuracy: 0.9772 - val_loss: 0.0518\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9834 - loss: 0.0370 - val_accuracy: 0.9754 - val_loss: 0.0559\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9840 - loss: 0.0419 - val_accuracy: 0.9769 - val_loss: 0.0531\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9850 - loss: 0.0367 - val_accuracy: 0.9772 - val_loss: 0.0534\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9851 - loss: 0.0363 - val_accuracy: 0.9785 - val_loss: 0.0512\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9879 - loss: 0.0341 - val_accuracy: 0.9785 - val_loss: 0.0489\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9813 - loss: 0.0481 - val_accuracy: 0.9778 - val_loss: 0.0512\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9853 - loss: 0.0351 - val_accuracy: 0.9788 - val_loss: 0.0532\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9859 - loss: 0.0384 - val_accuracy: 0.9775 - val_loss: 0.0516\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9847 - loss: 0.0329 - val_accuracy: 0.9763 - val_loss: 0.0560\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0314 - val_accuracy: 0.9744 - val_loss: 0.0639\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9824 - loss: 0.0418 - val_accuracy: 0.9738 - val_loss: 0.0590\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9847 - loss: 0.0350 - val_accuracy: 0.9775 - val_loss: 0.0532\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0310 - val_accuracy: 0.9760 - val_loss: 0.0552\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9861 - loss: 0.0311 - val_accuracy: 0.9735 - val_loss: 0.0596\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9863 - loss: 0.0305 - val_accuracy: 0.9794 - val_loss: 0.0564\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0301 - val_accuracy: 0.9725 - val_loss: 0.0637\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9854 - loss: 0.0371 - val_accuracy: 0.9769 - val_loss: 0.0537\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0307 - val_accuracy: 0.9775 - val_loss: 0.0597\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0274 - val_accuracy: 0.9785 - val_loss: 0.0582\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9864 - loss: 0.0299 - val_accuracy: 0.9750 - val_loss: 0.0607\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9879 - loss: 0.0294 - val_accuracy: 0.9760 - val_loss: 0.0632\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9855 - loss: 0.0331 - val_accuracy: 0.9775 - val_loss: 0.0588\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9842 - loss: 0.0344 - val_accuracy: 0.9775 - val_loss: 0.0595\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0287 - val_accuracy: 0.9803 - val_loss: 0.0579\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0297 - val_accuracy: 0.9772 - val_loss: 0.0600\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0339 - val_accuracy: 0.9766 - val_loss: 0.0588\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0322 - val_accuracy: 0.9775 - val_loss: 0.0641\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9859 - loss: 0.0316 - val_accuracy: 0.9757 - val_loss: 0.0686\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9879 - loss: 0.0283 - val_accuracy: 0.9778 - val_loss: 0.0610\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0284 - val_accuracy: 0.9760 - val_loss: 0.0680\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0283 - val_accuracy: 0.9747 - val_loss: 0.0685\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0325 - val_accuracy: 0.9775 - val_loss: 0.0615\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9860 - loss: 0.0303 - val_accuracy: 0.9757 - val_loss: 0.0755\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9874 - loss: 0.0289 - val_accuracy: 0.9807 - val_loss: 0.0614\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9867 - loss: 0.0294 - val_accuracy: 0.9772 - val_loss: 0.0679\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0271 - val_accuracy: 0.9744 - val_loss: 0.0734\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9879 - loss: 0.0269 - val_accuracy: 0.9747 - val_loss: 0.0689\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0287 - val_accuracy: 0.9772 - val_loss: 0.0663\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0350 - val_accuracy: 0.9797 - val_loss: 0.0628\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0254 - val_accuracy: 0.9766 - val_loss: 0.0710\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9878 - loss: 0.0255 - val_accuracy: 0.9772 - val_loss: 0.0758\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0258 - val_accuracy: 0.9769 - val_loss: 0.0681\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0248 - val_accuracy: 0.9760 - val_loss: 0.0709\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0285 - val_accuracy: 0.9778 - val_loss: 0.0670\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0251 - val_accuracy: 0.9763 - val_loss: 0.0707\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0229 - val_accuracy: 0.9822 - val_loss: 0.0609\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0272 - val_accuracy: 0.9785 - val_loss: 0.0639\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9893 - loss: 0.0245 - val_accuracy: 0.9800 - val_loss: 0.0666\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9889 - loss: 0.0244 - val_accuracy: 0.9747 - val_loss: 0.0771\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9889 - loss: 0.0280 - val_accuracy: 0.9797 - val_loss: 0.0718\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0234 - val_accuracy: 0.9744 - val_loss: 0.0714\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9892 - loss: 0.0244 - val_accuracy: 0.9769 - val_loss: 0.0674\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0278 - val_accuracy: 0.9757 - val_loss: 0.0787\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0242 - val_accuracy: 0.9766 - val_loss: 0.0723\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0256 - val_accuracy: 0.9757 - val_loss: 0.0745\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0226 - val_accuracy: 0.9750 - val_loss: 0.0816\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9899 - loss: 0.0216 - val_accuracy: 0.9766 - val_loss: 0.0772\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0223 - val_accuracy: 0.9769 - val_loss: 0.0711\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0202 - val_accuracy: 0.9744 - val_loss: 0.0853\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0300 - val_accuracy: 0.9778 - val_loss: 0.0731\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9906 - loss: 0.0221 - val_accuracy: 0.9769 - val_loss: 0.0756\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0204 - val_accuracy: 0.9772 - val_loss: 0.0782\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9904 - loss: 0.0217 - val_accuracy: 0.9769 - val_loss: 0.0755\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0220 - val_accuracy: 0.9763 - val_loss: 0.0764\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0210 - val_accuracy: 0.9750 - val_loss: 0.0887\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0295 - val_accuracy: 0.9744 - val_loss: 0.0851\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0187 - val_accuracy: 0.9747 - val_loss: 0.0864\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0228 - val_accuracy: 0.9735 - val_loss: 0.0890\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0198 - val_accuracy: 0.9785 - val_loss: 0.0809\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0223 - val_accuracy: 0.9750 - val_loss: 0.0882\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9916 - loss: 0.0233 - val_accuracy: 0.9741 - val_loss: 0.0826\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0166 - val_accuracy: 0.9757 - val_loss: 0.0849\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9915 - loss: 0.0200 - val_accuracy: 0.9735 - val_loss: 0.0812\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0212 - val_accuracy: 0.9760 - val_loss: 0.0807\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0300 - val_accuracy: 0.9785 - val_loss: 0.0774\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0178 - val_accuracy: 0.9769 - val_loss: 0.0824\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0205 - val_accuracy: 0.9729 - val_loss: 0.0923\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0201 - val_accuracy: 0.9750 - val_loss: 0.0917\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0167 - val_accuracy: 0.9750 - val_loss: 0.0873\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0245 - val_accuracy: 0.9738 - val_loss: 0.0893\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0154 - val_accuracy: 0.9769 - val_loss: 0.0889\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9920 - loss: 0.0204 - val_accuracy: 0.9760 - val_loss: 0.0859\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0154 - val_accuracy: 0.9744 - val_loss: 0.0988\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0253 - val_accuracy: 0.9766 - val_loss: 0.0901\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0158 - val_accuracy: 0.9744 - val_loss: 0.0980\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0171 - val_accuracy: 0.9744 - val_loss: 0.1068\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0165 - val_accuracy: 0.9741 - val_loss: 0.0978\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9909 - loss: 0.0234 - val_accuracy: 0.9747 - val_loss: 0.0920\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0153 - val_accuracy: 0.9754 - val_loss: 0.0966\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0160 - val_accuracy: 0.9688 - val_loss: 0.1059\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0163 - val_accuracy: 0.9725 - val_loss: 0.1008\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0158 - val_accuracy: 0.9744 - val_loss: 0.0971\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0149 - val_accuracy: 0.9778 - val_loss: 0.0915\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0137 - val_accuracy: 0.9763 - val_loss: 0.0961\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0140 - val_accuracy: 0.9772 - val_loss: 0.0938\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0172 - val_accuracy: 0.9704 - val_loss: 0.1152\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0144 - val_accuracy: 0.9716 - val_loss: 0.1045\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0111 - val_accuracy: 0.9747 - val_loss: 0.1001\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0118 - val_accuracy: 0.9772 - val_loss: 0.0903\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0139 - val_accuracy: 0.9700 - val_loss: 0.1200\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0172 - val_accuracy: 0.9716 - val_loss: 0.0979\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0127 - val_accuracy: 0.9741 - val_loss: 0.1019\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0126 - val_accuracy: 0.9744 - val_loss: 0.1067\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9849 - loss: 0.0651 - val_accuracy: 0.9725 - val_loss: 0.1093\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9857 - loss: 0.0393 - val_accuracy: 0.9741 - val_loss: 0.1026\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9878 - loss: 0.0313 - val_accuracy: 0.9735 - val_loss: 0.1072\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9876 - loss: 0.0326 - val_accuracy: 0.9766 - val_loss: 0.0997\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9895 - loss: 0.0239 - val_accuracy: 0.9744 - val_loss: 0.1109\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9889 - loss: 0.0237 - val_accuracy: 0.9772 - val_loss: 0.0948\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0210 - val_accuracy: 0.9722 - val_loss: 0.1216\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0238 - val_accuracy: 0.9760 - val_loss: 0.1043\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0238 - val_accuracy: 0.9754 - val_loss: 0.0957\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0186 - val_accuracy: 0.9750 - val_loss: 0.1092\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0158 - val_accuracy: 0.9732 - val_loss: 0.1118\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0139 - val_accuracy: 0.9738 - val_loss: 0.1010\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0122 - val_accuracy: 0.9700 - val_loss: 0.1230\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0148 - val_accuracy: 0.9725 - val_loss: 0.1092\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0124 - val_accuracy: 0.9713 - val_loss: 0.1159\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0099 - val_accuracy: 0.9747 - val_loss: 0.1122\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0118 - val_accuracy: 0.9666 - val_loss: 0.1408\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0135 - val_accuracy: 0.9760 - val_loss: 0.1119\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0221 - val_accuracy: 0.9754 - val_loss: 0.1169\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0087 - val_accuracy: 0.9750 - val_loss: 0.1123\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0114 - val_accuracy: 0.9738 - val_loss: 0.1167\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0168 - val_accuracy: 0.9732 - val_loss: 0.1183\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0160 - val_accuracy: 0.9719 - val_loss: 0.1131\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0134 - val_accuracy: 0.9719 - val_loss: 0.1174\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0160 - val_accuracy: 0.9738 - val_loss: 0.1117\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0101 - val_accuracy: 0.9704 - val_loss: 0.1279\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0080 - val_accuracy: 0.9713 - val_loss: 0.1232\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0090 - val_accuracy: 0.9713 - val_loss: 0.1235\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0118 - val_accuracy: 0.9719 - val_loss: 0.1125\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0117 - val_accuracy: 0.9688 - val_loss: 0.1240\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0161 - val_accuracy: 0.9732 - val_loss: 0.1155\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0245 - val_accuracy: 0.9710 - val_loss: 0.1206\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0148 - val_accuracy: 0.9732 - val_loss: 0.1047\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0158 - val_accuracy: 0.9738 - val_loss: 0.1103\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0100 - val_accuracy: 0.9682 - val_loss: 0.1362\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0082 - val_accuracy: 0.9757 - val_loss: 0.1103\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0073 - val_accuracy: 0.9741 - val_loss: 0.1097\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0123 - val_accuracy: 0.9747 - val_loss: 0.1078\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0125 - val_accuracy: 0.9741 - val_loss: 0.1149\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0112 - val_accuracy: 0.9704 - val_loss: 0.1229\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0099 - val_accuracy: 0.9750 - val_loss: 0.1130\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0106 - val_accuracy: 0.9750 - val_loss: 0.1101\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0101 - val_accuracy: 0.9747 - val_loss: 0.1230\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0268 - val_accuracy: 0.9725 - val_loss: 0.1045\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0144 - val_accuracy: 0.9738 - val_loss: 0.1116\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0082 - val_accuracy: 0.9700 - val_loss: 0.1276\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.9744 - val_loss: 0.1188\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0103 - val_accuracy: 0.9766 - val_loss: 0.1155\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0085 - val_accuracy: 0.9757 - val_loss: 0.1201\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0206 - val_accuracy: 0.9713 - val_loss: 0.1208\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.9707 - val_loss: 0.1374\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0108 - val_accuracy: 0.9741 - val_loss: 0.1308\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.9747 - val_loss: 0.1227\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0090 - val_accuracy: 0.9725 - val_loss: 0.1222\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0132 - val_accuracy: 0.9738 - val_loss: 0.1259\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0089 - val_accuracy: 0.9710 - val_loss: 0.1401\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0087 - val_accuracy: 0.9729 - val_loss: 0.1228\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0116 - val_accuracy: 0.9679 - val_loss: 0.1410\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0100 - val_accuracy: 0.9719 - val_loss: 0.1327\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0065 - val_accuracy: 0.9725 - val_loss: 0.1421\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.9741 - val_loss: 0.1270\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0117 - val_accuracy: 0.9735 - val_loss: 0.1292\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0160 - val_accuracy: 0.9738 - val_loss: 0.1286\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0153 - val_accuracy: 0.9747 - val_loss: 0.1238\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0077 - val_accuracy: 0.9747 - val_loss: 0.1297\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0064 - val_accuracy: 0.9741 - val_loss: 0.1318\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0070 - val_accuracy: 0.9760 - val_loss: 0.1270\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0076 - val_accuracy: 0.9676 - val_loss: 0.1350\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0092 - val_accuracy: 0.9750 - val_loss: 0.1309\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0061 - val_accuracy: 0.9732 - val_loss: 0.1401\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0104 - val_accuracy: 0.9750 - val_loss: 0.1246\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0074 - val_accuracy: 0.9722 - val_loss: 0.1322\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0080 - val_accuracy: 0.9747 - val_loss: 0.1289\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0158 - val_accuracy: 0.9744 - val_loss: 0.1365\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 0.9707 - val_loss: 0.1379\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0062 - val_accuracy: 0.9744 - val_loss: 0.1234\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9732 - val_loss: 0.1349\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9738 - val_loss: 0.1408\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0091 - val_accuracy: 0.9719 - val_loss: 0.1354\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0108 - val_accuracy: 0.9729 - val_loss: 0.1388\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0159 - val_accuracy: 0.9738 - val_loss: 0.1327\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.9750 - val_loss: 0.1266\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0059 - val_accuracy: 0.9738 - val_loss: 0.1334\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0077 - val_accuracy: 0.9735 - val_loss: 0.1295\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0087 - val_accuracy: 0.9735 - val_loss: 0.1337\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 0.9735 - val_loss: 0.1221\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0066 - val_accuracy: 0.9754 - val_loss: 0.1393\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0060 - val_accuracy: 0.9719 - val_loss: 0.1403\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0053 - val_accuracy: 0.9725 - val_loss: 0.1349\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0052 - val_accuracy: 0.9772 - val_loss: 0.1195\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9710 - val_loss: 0.1363\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9719 - val_loss: 0.1461\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0084 - val_accuracy: 0.9732 - val_loss: 0.1500\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0070 - val_accuracy: 0.9775 - val_loss: 0.1298\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.9710 - val_loss: 0.1564\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0095 - val_accuracy: 0.9750 - val_loss: 0.1285\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0082 - val_accuracy: 0.9791 - val_loss: 0.1237\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0053 - val_accuracy: 0.9744 - val_loss: 0.1430\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.9754 - val_loss: 0.1376\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 0.9754 - val_loss: 0.1430\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0072 - val_accuracy: 0.9760 - val_loss: 0.1445\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0047 - val_accuracy: 0.9754 - val_loss: 0.1405\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9760 - val_loss: 0.1459\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0080 - val_accuracy: 0.9760 - val_loss: 0.1451\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.9754 - val_loss: 0.1434\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9760 - val_loss: 0.1475\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0138 - val_accuracy: 0.9747 - val_loss: 0.1438\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0071 - val_accuracy: 0.9738 - val_loss: 0.1578\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0054 - val_accuracy: 0.9732 - val_loss: 0.1637\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0091 - val_accuracy: 0.9754 - val_loss: 0.1546\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9757 - val_loss: 0.1422\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.9744 - val_loss: 0.1544\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9766 - val_loss: 0.1461\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0078 - val_accuracy: 0.9747 - val_loss: 0.1438\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9729 - val_loss: 0.1599\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0059 - val_accuracy: 0.9738 - val_loss: 0.1631\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9763 - val_loss: 0.1584\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9738 - val_loss: 0.1703\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0055 - val_accuracy: 0.9713 - val_loss: 0.1801\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.9750 - val_loss: 0.1629\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0044 - val_accuracy: 0.9757 - val_loss: 0.1548\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.9763 - val_loss: 0.1666\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9741 - val_loss: 0.1672\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0067 - val_accuracy: 0.9725 - val_loss: 0.1792\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0090 - val_accuracy: 0.9747 - val_loss: 0.1451\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0244 - val_accuracy: 0.9735 - val_loss: 0.1512\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9775 - val_loss: 0.1546\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9735 - val_loss: 0.1651\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9760 - val_loss: 0.1553\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9754 - val_loss: 0.1648\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0098 - val_accuracy: 0.9754 - val_loss: 0.1627\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9754 - val_loss: 0.1559\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.9725 - val_loss: 0.1761\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.9769 - val_loss: 0.1542\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 0.9754 - val_loss: 0.1617\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0118 - val_accuracy: 0.9741 - val_loss: 0.1598\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9713 - val_loss: 0.1670\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.9763 - val_loss: 0.1468\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0026 - val_accuracy: 0.9750 - val_loss: 0.1764\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0076 - val_accuracy: 0.9763 - val_loss: 0.1528\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0051 - val_accuracy: 0.9754 - val_loss: 0.1533\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9725 - val_loss: 0.1692\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0060 - val_accuracy: 0.9744 - val_loss: 0.1544\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9747 - val_loss: 0.1631\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.9750 - val_loss: 0.1521\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9754 - val_loss: 0.1552\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 0.9763 - val_loss: 0.1557\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.9754 - val_loss: 0.1392\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9738 - val_loss: 0.1671\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0032 - val_accuracy: 0.9732 - val_loss: 0.1524\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0160 - val_accuracy: 0.9738 - val_loss: 0.1540\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0041 - val_accuracy: 0.9738 - val_loss: 0.1568\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9744 - val_loss: 0.1547\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9741 - val_loss: 0.1602\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9722 - val_loss: 0.1581\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9700 - val_loss: 0.1816\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9716 - val_loss: 0.1731\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9704 - val_loss: 0.1739\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9729 - val_loss: 0.1619\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0171 - val_accuracy: 0.9725 - val_loss: 0.1772\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0112 - val_accuracy: 0.9719 - val_loss: 0.1691\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.9741 - val_loss: 0.1648\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9735 - val_loss: 0.1585\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9738 - val_loss: 0.1759\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.9735 - val_loss: 0.1607\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.9741 - val_loss: 0.1491\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0242 - val_accuracy: 0.9716 - val_loss: 0.1716\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0054 - val_accuracy: 0.9716 - val_loss: 0.1635\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.9732 - val_loss: 0.1660\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9707 - val_loss: 0.1880\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9725 - val_loss: 0.1585\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9713 - val_loss: 0.1716\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0095 - val_accuracy: 0.9750 - val_loss: 0.1498\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9747 - val_loss: 0.1603\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.9735 - val_loss: 0.1693\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9741 - val_loss: 0.1567\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0059 - val_accuracy: 0.9732 - val_loss: 0.1654\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9741 - val_loss: 0.1570\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9722 - val_loss: 0.1689\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0057 - val_accuracy: 0.9744 - val_loss: 0.1386\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.9735 - val_loss: 0.1627\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.9738 - val_loss: 0.1689\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9738 - val_loss: 0.1706\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9744 - val_loss: 0.1640\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0332 - val_accuracy: 0.9716 - val_loss: 0.1669\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9735 - val_loss: 0.1626\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9741 - val_loss: 0.1525\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0020 - val_accuracy: 0.9744 - val_loss: 0.1636\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9729 - val_loss: 0.1701\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9750 - val_loss: 0.1649\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0073 - val_accuracy: 0.9691 - val_loss: 0.1610\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9719 - val_loss: 0.1770\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9713 - val_loss: 0.1742\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9719 - val_loss: 0.1719\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.9747 - val_loss: 0.1555\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0025 - val_accuracy: 0.9707 - val_loss: 0.1759\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9735 - val_loss: 0.1522\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0042 - val_accuracy: 0.9750 - val_loss: 0.1501\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.9738 - val_loss: 0.1620\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9741 - val_loss: 0.1661\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.5755e-04 - val_accuracy: 0.9679 - val_loss: 0.1871\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.9710 - val_loss: 0.1484\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0041 - val_accuracy: 0.9750 - val_loss: 0.1410\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9744 - val_loss: 0.1540\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9735 - val_loss: 0.1620\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0017 - val_accuracy: 0.9735 - val_loss: 0.1557\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9763 - val_loss: 0.1655\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0095 - val_accuracy: 0.9725 - val_loss: 0.1458\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9757 - val_loss: 0.1439\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9747 - val_loss: 0.1532\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 9.0332e-04 - val_accuracy: 0.9754 - val_loss: 0.1533\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 6.9623e-04 - val_accuracy: 0.9750 - val_loss: 0.1525\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9719 - val_loss: 0.1573\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9735 - val_loss: 0.1560\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9735 - val_loss: 0.1595\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.9732 - val_loss: 0.1608\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9707 - val_loss: 0.1795\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.9722 - val_loss: 0.1715\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9716 - val_loss: 0.1749\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.3167e-04 - val_accuracy: 0.9722 - val_loss: 0.1740\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 8.6808e-04 - val_accuracy: 0.9747 - val_loss: 0.1727\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9757 - val_loss: 0.1530\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0093 - val_accuracy: 0.9738 - val_loss: 0.1604\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0059 - val_accuracy: 0.9710 - val_loss: 0.1687\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0135 - val_accuracy: 0.9722 - val_loss: 0.1659\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0027 - val_accuracy: 0.9738 - val_loss: 0.1660\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9732 - val_loss: 0.1667\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9738 - val_loss: 0.1717\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.6906e-04 - val_accuracy: 0.9738 - val_loss: 0.1753\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.1937e-04 - val_accuracy: 0.9732 - val_loss: 0.1786\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.9750 - val_loss: 0.1558\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 9.0114e-04 - val_accuracy: 0.9757 - val_loss: 0.1604\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 9.3907e-04 - val_accuracy: 0.9722 - val_loss: 0.1650\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0074 - val_accuracy: 0.9719 - val_loss: 0.1726\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9710 - val_loss: 0.1790\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9722 - val_loss: 0.1702\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.9704 - val_loss: 0.1836\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9760 - val_loss: 0.1593\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9725 - val_loss: 0.1749\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 9.5996e-04 - val_accuracy: 0.9735 - val_loss: 0.1743\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9729 - val_loss: 0.1781\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9738 - val_loss: 0.1666\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.9713 - val_loss: 0.1590\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0077 - val_accuracy: 0.9738 - val_loss: 0.1603\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9757 - val_loss: 0.1463\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0017 - val_accuracy: 0.9760 - val_loss: 0.1541\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9738 - val_loss: 0.1712\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.5941e-04 - val_accuracy: 0.9747 - val_loss: 0.1683\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 8.8293e-04 - val_accuracy: 0.9725 - val_loss: 0.1718\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0093 - val_accuracy: 0.9694 - val_loss: 0.1805\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 0.9732 - val_loss: 0.1637\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9741 - val_loss: 0.1605\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9722 - val_loss: 0.1680\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0060 - val_accuracy: 0.9729 - val_loss: 0.1791\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 0.9754 - val_loss: 0.1428\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0033 - val_accuracy: 0.9716 - val_loss: 0.1702\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.9738 - val_loss: 0.1662\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.1687e-04 - val_accuracy: 0.9716 - val_loss: 0.1732\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9713 - val_loss: 0.1831\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 8.0152e-04 - val_accuracy: 0.9738 - val_loss: 0.1890\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0059 - val_accuracy: 0.9732 - val_loss: 0.1744\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9722 - val_loss: 0.1686\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.1704e-04 - val_accuracy: 0.9725 - val_loss: 0.1720\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.2851e-04 - val_accuracy: 0.9741 - val_loss: 0.1708\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.4473e-04 - val_accuracy: 0.9732 - val_loss: 0.1775\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.9725 - val_loss: 0.1616\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0121 - val_accuracy: 0.9704 - val_loss: 0.1713\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9741 - val_loss: 0.1532\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9738 - val_loss: 0.1640\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9750 - val_loss: 0.1630\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.5070e-04 - val_accuracy: 0.9741 - val_loss: 0.1662\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9700 - val_loss: 0.1805\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0064 - val_accuracy: 0.9707 - val_loss: 0.1701\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0085 - val_accuracy: 0.9719 - val_loss: 0.1690\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9738 - val_loss: 0.1639\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9747 - val_loss: 0.1598\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.9735 - val_loss: 0.1726\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.3781e-04 - val_accuracy: 0.9741 - val_loss: 0.1708\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.2517e-04 - val_accuracy: 0.9738 - val_loss: 0.1707\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.3753e-04 - val_accuracy: 0.9738 - val_loss: 0.1767\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0120 - val_accuracy: 0.9732 - val_loss: 0.1352\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0064 - val_accuracy: 0.9719 - val_loss: 0.1603\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9716 - val_loss: 0.1618\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9719 - val_loss: 0.1593\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.8966e-04 - val_accuracy: 0.9725 - val_loss: 0.1602\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9716 - val_loss: 0.1668\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0023 - val_accuracy: 0.9707 - val_loss: 0.1641\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.9747 - val_loss: 0.1516\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 8.2662e-04 - val_accuracy: 0.9729 - val_loss: 0.1579\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.1181e-04 - val_accuracy: 0.9710 - val_loss: 0.1631\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9700 - val_loss: 0.1735\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0051 - val_accuracy: 0.9716 - val_loss: 0.1629\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9732 - val_loss: 0.1686\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.9738 - val_loss: 0.1650\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.4637e-04 - val_accuracy: 0.9744 - val_loss: 0.1619\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.2528e-04 - val_accuracy: 0.9741 - val_loss: 0.1674\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.5134e-04 - val_accuracy: 0.9747 - val_loss: 0.1691\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.3811e-04 - val_accuracy: 0.9744 - val_loss: 0.1751\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 9.6364e-04 - val_accuracy: 0.9725 - val_loss: 0.1899\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0136 - val_accuracy: 0.9685 - val_loss: 0.1681\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0029 - val_accuracy: 0.9729 - val_loss: 0.1584\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0016 - val_accuracy: 0.9754 - val_loss: 0.1525\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.9747 - val_loss: 0.1599\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9729 - val_loss: 0.1661\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9719 - val_loss: 0.1533\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0112 - val_accuracy: 0.9729 - val_loss: 0.1538\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9722 - val_loss: 0.1636\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.6526e-04 - val_accuracy: 0.9719 - val_loss: 0.1639\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 8.2584e-04 - val_accuracy: 0.9732 - val_loss: 0.1656\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9735 - val_loss: 0.1563\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9710 - val_loss: 0.1672\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.2509e-04 - val_accuracy: 0.9725 - val_loss: 0.1670\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.1186e-04 - val_accuracy: 0.9725 - val_loss: 0.1690\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.8208e-04 - val_accuracy: 0.9732 - val_loss: 0.1676\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.0719e-04 - val_accuracy: 0.9710 - val_loss: 0.1887\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.9704 - val_loss: 0.1834\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 0.9713 - val_loss: 0.1695\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9694 - val_loss: 0.1847\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9719 - val_loss: 0.1590\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.6111e-04 - val_accuracy: 0.9722 - val_loss: 0.1682\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.2011e-04 - val_accuracy: 0.9722 - val_loss: 0.1845\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.6468e-04 - val_accuracy: 0.9722 - val_loss: 0.1943\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0115 - val_accuracy: 0.9772 - val_loss: 0.1214\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9750 - val_loss: 0.1436\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9744 - val_loss: 0.1495\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 7.5831e-04 - val_accuracy: 0.9735 - val_loss: 0.1587\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 0.9744 - val_loss: 0.1550\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 6.3449e-04 - val_accuracy: 0.9744 - val_loss: 0.1551\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9744 - val_loss: 0.1639\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 2.7872e-04 - val_accuracy: 0.9732 - val_loss: 0.1653\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.8020e-04 - val_accuracy: 0.9772 - val_loss: 0.1546\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9700 - val_loss: 0.1741\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0066 - val_accuracy: 0.9729 - val_loss: 0.1655\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.9738 - val_loss: 0.1606\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.7280e-04 - val_accuracy: 0.9750 - val_loss: 0.1632\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9750 - val_loss: 0.1557\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9741 - val_loss: 0.1464\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.9312e-04 - val_accuracy: 0.9760 - val_loss: 0.1529\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 3.0619e-04 - val_accuracy: 0.9760 - val_loss: 0.1613\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0036 - val_accuracy: 0.9754 - val_loss: 0.1621\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9722 - val_loss: 0.1799\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0095 - val_accuracy: 0.9716 - val_loss: 0.1742\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0058 - val_accuracy: 0.9747 - val_loss: 0.1547\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.9539e-04 - val_accuracy: 0.9741 - val_loss: 0.1551\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9741 - val_loss: 0.1627\n\n\n\n\nINFO: Training model for R_WRIST_injury_risk...\nINFO: Loaded 10 features for R_WRIST_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 10), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.9161 - loss: 0.2519 - val_accuracy: 0.9660 - val_loss: 0.0900\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9659 - loss: 0.0991 - val_accuracy: 0.9697 - val_loss: 0.0904\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9673 - loss: 0.0924 - val_accuracy: 0.9676 - val_loss: 0.0877\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9671 - loss: 0.0912 - val_accuracy: 0.9725 - val_loss: 0.0783\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9669 - loss: 0.0898 - val_accuracy: 0.9747 - val_loss: 0.0666\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9724 - loss: 0.0804 - val_accuracy: 0.9691 - val_loss: 0.0797\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9714 - loss: 0.0770 - val_accuracy: 0.9766 - val_loss: 0.0576\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9720 - loss: 0.0729 - val_accuracy: 0.9722 - val_loss: 0.0633\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9712 - loss: 0.0665 - val_accuracy: 0.9725 - val_loss: 0.0659\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9727 - loss: 0.0645 - val_accuracy: 0.9750 - val_loss: 0.0624\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9747 - loss: 0.0631 - val_accuracy: 0.9713 - val_loss: 0.0681\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9777 - loss: 0.0550 - val_accuracy: 0.9750 - val_loss: 0.0573\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9769 - loss: 0.0534 - val_accuracy: 0.9766 - val_loss: 0.0634\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9756 - loss: 0.0593 - val_accuracy: 0.9744 - val_loss: 0.0544\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9783 - loss: 0.0500 - val_accuracy: 0.9757 - val_loss: 0.0610\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9793 - loss: 0.0485 - val_accuracy: 0.9772 - val_loss: 0.0582\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9819 - loss: 0.0444 - val_accuracy: 0.9700 - val_loss: 0.0719\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9825 - loss: 0.0413 - val_accuracy: 0.9588 - val_loss: 0.0821\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9830 - loss: 0.0398 - val_accuracy: 0.9735 - val_loss: 0.0951\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9860 - loss: 0.0368 - val_accuracy: 0.9666 - val_loss: 0.0765\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9827 - loss: 0.0452 - val_accuracy: 0.9732 - val_loss: 0.0601\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9835 - loss: 0.0390 - val_accuracy: 0.9713 - val_loss: 0.0664\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9780 - loss: 0.0506 - val_accuracy: 0.9719 - val_loss: 0.0706\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9854 - loss: 0.0376 - val_accuracy: 0.9598 - val_loss: 0.0802\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9843 - loss: 0.0378 - val_accuracy: 0.9666 - val_loss: 0.0695\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0341 - val_accuracy: 0.9785 - val_loss: 0.0612\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0361 - val_accuracy: 0.9735 - val_loss: 0.0739\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9812 - loss: 0.0495 - val_accuracy: 0.9685 - val_loss: 0.0826\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9829 - loss: 0.0385 - val_accuracy: 0.9797 - val_loss: 0.0469\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9843 - loss: 0.0368 - val_accuracy: 0.9778 - val_loss: 0.0555\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9892 - loss: 0.0291 - val_accuracy: 0.9638 - val_loss: 0.0811\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9852 - loss: 0.0345 - val_accuracy: 0.9782 - val_loss: 0.0528\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0378 - val_accuracy: 0.9747 - val_loss: 0.0661\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9802 - loss: 0.0512 - val_accuracy: 0.9766 - val_loss: 0.0556\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0299 - val_accuracy: 0.9766 - val_loss: 0.0590\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9860 - loss: 0.0325 - val_accuracy: 0.9788 - val_loss: 0.0481\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0330 - val_accuracy: 0.9775 - val_loss: 0.0599\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9850 - loss: 0.0385 - val_accuracy: 0.9785 - val_loss: 0.0536\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9811 - loss: 0.0468 - val_accuracy: 0.9719 - val_loss: 0.0684\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9864 - loss: 0.0336 - val_accuracy: 0.9738 - val_loss: 0.0736\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0311 - val_accuracy: 0.9729 - val_loss: 0.0628\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9835 - loss: 0.0351 - val_accuracy: 0.9747 - val_loss: 0.0630\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9852 - loss: 0.0381 - val_accuracy: 0.9757 - val_loss: 0.0594\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0320 - val_accuracy: 0.9729 - val_loss: 0.0562\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9854 - loss: 0.0307 - val_accuracy: 0.9778 - val_loss: 0.0571\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9874 - loss: 0.0290 - val_accuracy: 0.9782 - val_loss: 0.0571\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0284 - val_accuracy: 0.9735 - val_loss: 0.0692\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0307 - val_accuracy: 0.9750 - val_loss: 0.0621\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9842 - loss: 0.0386 - val_accuracy: 0.9710 - val_loss: 0.0799\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9879 - loss: 0.0298 - val_accuracy: 0.9725 - val_loss: 0.0741\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0309 - val_accuracy: 0.9769 - val_loss: 0.0644\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9889 - loss: 0.0254 - val_accuracy: 0.9700 - val_loss: 0.0700\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0259 - val_accuracy: 0.9700 - val_loss: 0.0788\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9881 - loss: 0.0276 - val_accuracy: 0.9782 - val_loss: 0.0653\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0285 - val_accuracy: 0.9778 - val_loss: 0.0610\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0271 - val_accuracy: 0.9738 - val_loss: 0.0764\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9896 - loss: 0.0249 - val_accuracy: 0.9732 - val_loss: 0.0701\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9893 - loss: 0.0236 - val_accuracy: 0.9741 - val_loss: 0.0638\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0291 - val_accuracy: 0.9710 - val_loss: 0.0669\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0248 - val_accuracy: 0.9710 - val_loss: 0.0790\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0266 - val_accuracy: 0.9704 - val_loss: 0.0799\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9904 - loss: 0.0214 - val_accuracy: 0.9713 - val_loss: 0.0902\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0228 - val_accuracy: 0.9685 - val_loss: 0.0815\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0201 - val_accuracy: 0.9741 - val_loss: 0.0708\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0266 - val_accuracy: 0.9782 - val_loss: 0.0671\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0242 - val_accuracy: 0.9741 - val_loss: 0.0935\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0211 - val_accuracy: 0.9732 - val_loss: 0.1014\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9909 - loss: 0.0215 - val_accuracy: 0.9769 - val_loss: 0.0747\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0450 - val_accuracy: 0.9800 - val_loss: 0.0593\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9852 - loss: 0.0446 - val_accuracy: 0.9794 - val_loss: 0.0614\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0379 - val_accuracy: 0.9735 - val_loss: 0.0791\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9868 - loss: 0.0327 - val_accuracy: 0.9747 - val_loss: 0.0760\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9909 - loss: 0.0248 - val_accuracy: 0.9769 - val_loss: 0.0611\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0229 - val_accuracy: 0.9760 - val_loss: 0.0803\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0186 - val_accuracy: 0.9788 - val_loss: 0.0552\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0246 - val_accuracy: 0.9719 - val_loss: 0.0713\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9820 - loss: 0.0433 - val_accuracy: 0.9754 - val_loss: 0.0706\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9838 - loss: 0.0370 - val_accuracy: 0.9757 - val_loss: 0.0646\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0284 - val_accuracy: 0.9738 - val_loss: 0.0754\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0216 - val_accuracy: 0.9785 - val_loss: 0.0609\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0180 - val_accuracy: 0.9754 - val_loss: 0.0709\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0192 - val_accuracy: 0.9803 - val_loss: 0.0663\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0180 - val_accuracy: 0.9760 - val_loss: 0.0853\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0169 - val_accuracy: 0.9769 - val_loss: 0.0673\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0195 - val_accuracy: 0.9797 - val_loss: 0.0620\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0264 - val_accuracy: 0.9763 - val_loss: 0.0603\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0159 - val_accuracy: 0.9716 - val_loss: 0.0821\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0188 - val_accuracy: 0.9747 - val_loss: 0.0763\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9899 - loss: 0.0253 - val_accuracy: 0.9747 - val_loss: 0.0842\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0156 - val_accuracy: 0.9778 - val_loss: 0.0660\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0156 - val_accuracy: 0.9757 - val_loss: 0.0850\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0182 - val_accuracy: 0.9778 - val_loss: 0.0824\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0176 - val_accuracy: 0.9747 - val_loss: 0.0767\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0143 - val_accuracy: 0.9760 - val_loss: 0.0887\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0187 - val_accuracy: 0.9722 - val_loss: 0.0816\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0191 - val_accuracy: 0.9750 - val_loss: 0.0774\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0256 - val_accuracy: 0.9760 - val_loss: 0.0790\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0170 - val_accuracy: 0.9707 - val_loss: 0.0967\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0158 - val_accuracy: 0.9757 - val_loss: 0.0750\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0176 - val_accuracy: 0.9719 - val_loss: 0.0793\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0128 - val_accuracy: 0.9747 - val_loss: 0.0918\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0176 - val_accuracy: 0.9750 - val_loss: 0.0938\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0133 - val_accuracy: 0.9766 - val_loss: 0.0856\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0176 - val_accuracy: 0.9760 - val_loss: 0.0793\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0134 - val_accuracy: 0.9757 - val_loss: 0.0766\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0148 - val_accuracy: 0.9732 - val_loss: 0.0854\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0146 - val_accuracy: 0.9710 - val_loss: 0.0985\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0129 - val_accuracy: 0.9766 - val_loss: 0.0753\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9920 - loss: 0.0222 - val_accuracy: 0.9750 - val_loss: 0.0735\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0138 - val_accuracy: 0.9791 - val_loss: 0.0765\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0101 - val_accuracy: 0.9744 - val_loss: 0.0935\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0129 - val_accuracy: 0.9766 - val_loss: 0.0835\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0182 - val_accuracy: 0.9741 - val_loss: 0.0968\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0138 - val_accuracy: 0.9669 - val_loss: 0.1115\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0126 - val_accuracy: 0.9766 - val_loss: 0.0840\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0103 - val_accuracy: 0.9769 - val_loss: 0.0917\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0121 - val_accuracy: 0.9754 - val_loss: 0.0859\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0155 - val_accuracy: 0.9778 - val_loss: 0.0766\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0106 - val_accuracy: 0.9747 - val_loss: 0.0988\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0100 - val_accuracy: 0.9778 - val_loss: 0.0957\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0104 - val_accuracy: 0.9757 - val_loss: 0.0818\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0111 - val_accuracy: 0.9744 - val_loss: 0.1018\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0118 - val_accuracy: 0.9785 - val_loss: 0.0840\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0121 - val_accuracy: 0.9769 - val_loss: 0.0780\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0136 - val_accuracy: 0.9772 - val_loss: 0.0705\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0204 - val_accuracy: 0.9750 - val_loss: 0.0986\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0114 - val_accuracy: 0.9775 - val_loss: 0.0828\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0089 - val_accuracy: 0.9735 - val_loss: 0.0774\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 0.9747 - val_loss: 0.0842\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.9688 - val_loss: 0.1143\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0081 - val_accuracy: 0.9738 - val_loss: 0.0847\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0249 - val_accuracy: 0.9788 - val_loss: 0.0818\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0149 - val_accuracy: 0.9741 - val_loss: 0.0929\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0113 - val_accuracy: 0.9791 - val_loss: 0.0854\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0098 - val_accuracy: 0.9750 - val_loss: 0.0967\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0089 - val_accuracy: 0.9754 - val_loss: 0.0826\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 0.9760 - val_loss: 0.0772\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0075 - val_accuracy: 0.9757 - val_loss: 0.0995\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.9682 - val_loss: 0.1424\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0135 - val_accuracy: 0.9732 - val_loss: 0.1054\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0100 - val_accuracy: 0.9744 - val_loss: 0.0959\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0143 - val_accuracy: 0.9791 - val_loss: 0.0793\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0083 - val_accuracy: 0.9769 - val_loss: 0.0938\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0081 - val_accuracy: 0.9729 - val_loss: 0.1191\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0111 - val_accuracy: 0.9707 - val_loss: 0.1016\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0104 - val_accuracy: 0.9772 - val_loss: 0.0889\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0105 - val_accuracy: 0.9775 - val_loss: 0.0915\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0087 - val_accuracy: 0.9794 - val_loss: 0.0833\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.9791 - val_loss: 0.0818\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0082 - val_accuracy: 0.9763 - val_loss: 0.0866\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0079 - val_accuracy: 0.9782 - val_loss: 0.0761\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0082 - val_accuracy: 0.9526 - val_loss: 0.1526\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0183 - val_accuracy: 0.9791 - val_loss: 0.0882\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.9757 - val_loss: 0.0992\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0091 - val_accuracy: 0.9760 - val_loss: 0.0972\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0087 - val_accuracy: 0.9816 - val_loss: 0.0825\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0093 - val_accuracy: 0.9716 - val_loss: 0.1162\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0097 - val_accuracy: 0.9763 - val_loss: 0.0874\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0090 - val_accuracy: 0.9754 - val_loss: 0.0910\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0085 - val_accuracy: 0.9747 - val_loss: 0.0955\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0060 - val_accuracy: 0.9775 - val_loss: 0.0962\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0109 - val_accuracy: 0.9757 - val_loss: 0.0968\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 0.9772 - val_loss: 0.0926\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0068 - val_accuracy: 0.9747 - val_loss: 0.1117\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0127 - val_accuracy: 0.9682 - val_loss: 0.1128\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0085 - val_accuracy: 0.9766 - val_loss: 0.0936\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.9760 - val_loss: 0.0903\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 0.9747 - val_loss: 0.0935\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0066 - val_accuracy: 0.9772 - val_loss: 0.0965\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.9778 - val_loss: 0.0895\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 0.9725 - val_loss: 0.1182\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0063 - val_accuracy: 0.9694 - val_loss: 0.1211\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0155 - val_accuracy: 0.9716 - val_loss: 0.1050\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0097 - val_accuracy: 0.9766 - val_loss: 0.1030\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9725 - val_loss: 0.1247\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9769 - val_loss: 0.0985\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0089 - val_accuracy: 0.9769 - val_loss: 0.0918\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0078 - val_accuracy: 0.9757 - val_loss: 0.1122\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0083 - val_accuracy: 0.9744 - val_loss: 0.0994\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0067 - val_accuracy: 0.9769 - val_loss: 0.0963\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0138 - val_accuracy: 0.9769 - val_loss: 0.1019\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0072 - val_accuracy: 0.9744 - val_loss: 0.1195\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0076 - val_accuracy: 0.9775 - val_loss: 0.0974\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0056 - val_accuracy: 0.9778 - val_loss: 0.1067\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0195 - val_accuracy: 0.9754 - val_loss: 0.1124\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0105 - val_accuracy: 0.9769 - val_loss: 0.0979\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0092 - val_accuracy: 0.9754 - val_loss: 0.0906\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0050 - val_accuracy: 0.9688 - val_loss: 0.1476\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0071 - val_accuracy: 0.9704 - val_loss: 0.1162\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.9775 - val_loss: 0.0981\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0061 - val_accuracy: 0.9772 - val_loss: 0.1086\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9760 - val_loss: 0.1086\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0077 - val_accuracy: 0.9719 - val_loss: 0.1258\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0201 - val_accuracy: 0.9754 - val_loss: 0.0946\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0066 - val_accuracy: 0.9757 - val_loss: 0.1019\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0054 - val_accuracy: 0.9738 - val_loss: 0.1124\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0054 - val_accuracy: 0.9772 - val_loss: 0.1043\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0048 - val_accuracy: 0.9754 - val_loss: 0.1052\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.9763 - val_loss: 0.0967\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9747 - val_loss: 0.1092\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0075 - val_accuracy: 0.9775 - val_loss: 0.1001\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.9750 - val_loss: 0.1164\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0076 - val_accuracy: 0.9747 - val_loss: 0.1048\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.9769 - val_loss: 0.1014\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.9707 - val_loss: 0.1312\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0054 - val_accuracy: 0.9719 - val_loss: 0.1202\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0074 - val_accuracy: 0.9735 - val_loss: 0.1146\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0051 - val_accuracy: 0.9760 - val_loss: 0.1105\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0043 - val_accuracy: 0.9716 - val_loss: 0.1270\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0082 - val_accuracy: 0.9735 - val_loss: 0.1214\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0074 - val_accuracy: 0.9772 - val_loss: 0.1099\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0075 - val_accuracy: 0.9778 - val_loss: 0.0954\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9778 - val_loss: 0.1058\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0047 - val_accuracy: 0.9719 - val_loss: 0.1231\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0077 - val_accuracy: 0.9757 - val_loss: 0.1184\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.9707 - val_loss: 0.1386\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.9747 - val_loss: 0.1294\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9732 - val_loss: 0.1158\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0063 - val_accuracy: 0.9750 - val_loss: 0.1103\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9601 - val_loss: 0.1613\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0128 - val_accuracy: 0.9744 - val_loss: 0.1158\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0037 - val_accuracy: 0.9750 - val_loss: 0.1200\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.9738 - val_loss: 0.1246\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0055 - val_accuracy: 0.9760 - val_loss: 0.1186\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9754 - val_loss: 0.1288\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0057 - val_accuracy: 0.9754 - val_loss: 0.1140\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0292 - val_accuracy: 0.9757 - val_loss: 0.1054\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9713 - val_loss: 0.1404\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9713 - val_loss: 0.1336\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0077 - val_accuracy: 0.9791 - val_loss: 0.0976\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.9757 - val_loss: 0.1217\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.9719 - val_loss: 0.1283\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9766 - val_loss: 0.1029\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.9744 - val_loss: 0.1193\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9760 - val_loss: 0.1254\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.9741 - val_loss: 0.1123\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0068 - val_accuracy: 0.9769 - val_loss: 0.1130\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9785 - val_loss: 0.1132\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9725 - val_loss: 0.1223\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0043 - val_accuracy: 0.9719 - val_loss: 0.1379\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0257 - val_accuracy: 0.9782 - val_loss: 0.0987\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.9769 - val_loss: 0.1090\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9769 - val_loss: 0.1129\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9754 - val_loss: 0.1228\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0060 - val_accuracy: 0.9785 - val_loss: 0.1046\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9754 - val_loss: 0.1207\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0090 - val_accuracy: 0.9713 - val_loss: 0.1364\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9782 - val_loss: 0.1037\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0133 - val_accuracy: 0.9747 - val_loss: 0.1200\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0093 - val_accuracy: 0.9750 - val_loss: 0.1021\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0055 - val_accuracy: 0.9729 - val_loss: 0.1137\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9747 - val_loss: 0.1169\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.9750 - val_loss: 0.1170\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.9738 - val_loss: 0.1319\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9760 - val_loss: 0.1037\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9741 - val_loss: 0.1242\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9732 - val_loss: 0.1162\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9747 - val_loss: 0.1157\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0033 - val_accuracy: 0.9778 - val_loss: 0.1150\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0201 - val_accuracy: 0.9735 - val_loss: 0.1283\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0183 - val_accuracy: 0.9710 - val_loss: 0.1364\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 0.9754 - val_loss: 0.1111\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 0.9760 - val_loss: 0.1111\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9707 - val_loss: 0.1444\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9775 - val_loss: 0.1033\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0074 - val_accuracy: 0.9769 - val_loss: 0.1119\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0033 - val_accuracy: 0.9747 - val_loss: 0.1251\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.9772 - val_loss: 0.1094\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0074 - val_accuracy: 0.9716 - val_loss: 0.1263\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.9760 - val_loss: 0.1100\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9757 - val_loss: 0.1110\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.9760 - val_loss: 0.1162\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0039 - val_accuracy: 0.9741 - val_loss: 0.1193\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9757 - val_loss: 0.1137\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9757 - val_loss: 0.1074\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0047 - val_accuracy: 0.9782 - val_loss: 0.1097\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9750 - val_loss: 0.1275\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 0.9744 - val_loss: 0.1210\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0036 - val_accuracy: 0.9750 - val_loss: 0.1288\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9707 - val_loss: 0.1564\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9744 - val_loss: 0.1280\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0100 - val_accuracy: 0.9766 - val_loss: 0.1276\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.9763 - val_loss: 0.1164\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9747 - val_loss: 0.1283\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9750 - val_loss: 0.1308\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9735 - val_loss: 0.1342\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9766 - val_loss: 0.1181\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0122 - val_accuracy: 0.9750 - val_loss: 0.1161\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.9735 - val_loss: 0.1263\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0045 - val_accuracy: 0.9760 - val_loss: 0.1131\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 0.9778 - val_loss: 0.1230\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9775 - val_loss: 0.1200\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.9738 - val_loss: 0.1338\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9772 - val_loss: 0.1306\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0025 - val_accuracy: 0.9757 - val_loss: 0.1325\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9754 - val_loss: 0.1208\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 0.9744 - val_loss: 0.1248\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.9635 - val_loss: 0.1523\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0205 - val_accuracy: 0.9772 - val_loss: 0.1265\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9763 - val_loss: 0.1266\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9754 - val_loss: 0.1394\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9725 - val_loss: 0.1358\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.9757 - val_loss: 0.1228\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9754 - val_loss: 0.1222\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9775 - val_loss: 0.1157\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0068 - val_accuracy: 0.9747 - val_loss: 0.1276\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9729 - val_loss: 0.1278\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0084 - val_accuracy: 0.9754 - val_loss: 0.1254\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9729 - val_loss: 0.1425\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9769 - val_loss: 0.1299\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0028 - val_accuracy: 0.9763 - val_loss: 0.1322\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9754 - val_loss: 0.1248\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.9738 - val_loss: 0.1304\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0027 - val_accuracy: 0.9729 - val_loss: 0.1370\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9744 - val_loss: 0.1378\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0033 - val_accuracy: 0.9722 - val_loss: 0.1379\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0072 - val_accuracy: 0.9725 - val_loss: 0.1430\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 0.9719 - val_loss: 0.1286\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0081 - val_accuracy: 0.9713 - val_loss: 0.1358\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9754 - val_loss: 0.1248\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0026 - val_accuracy: 0.9750 - val_loss: 0.1314\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.9704 - val_loss: 0.1463\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9760 - val_loss: 0.1257\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9738 - val_loss: 0.1320\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9657 - val_loss: 0.1533\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9700 - val_loss: 0.1619\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9754 - val_loss: 0.1173\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9757 - val_loss: 0.1322\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9763 - val_loss: 0.1250\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9713 - val_loss: 0.1555\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.9732 - val_loss: 0.1372\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 0.9766 - val_loss: 0.1337\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0158 - val_accuracy: 0.9741 - val_loss: 0.1283\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9744 - val_loss: 0.1426\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9725 - val_loss: 0.1581\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0040 - val_accuracy: 0.9754 - val_loss: 0.1386\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9710 - val_loss: 0.1522\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9719 - val_loss: 0.1401\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9704 - val_loss: 0.1487\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.9744 - val_loss: 0.1349\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9754 - val_loss: 0.1285\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9719 - val_loss: 0.1416\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9750 - val_loss: 0.1410\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0080 - val_accuracy: 0.9694 - val_loss: 0.1454\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9682 - val_loss: 0.1620\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9757 - val_loss: 0.1151\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9732 - val_loss: 0.1360\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9757 - val_loss: 0.1337\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9738 - val_loss: 0.1432\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9757 - val_loss: 0.1460\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9744 - val_loss: 0.1427\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0101 - val_accuracy: 0.9744 - val_loss: 0.1297\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0280 - val_accuracy: 0.9744 - val_loss: 0.1377\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0115 - val_accuracy: 0.9722 - val_loss: 0.1401\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9725 - val_loss: 0.1342\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9757 - val_loss: 0.1197\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9722 - val_loss: 0.1409\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0020 - val_accuracy: 0.9729 - val_loss: 0.1501\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9744 - val_loss: 0.1346\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9725 - val_loss: 0.1430\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0015 - val_accuracy: 0.9732 - val_loss: 0.1548\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0088 - val_accuracy: 0.9738 - val_loss: 0.1359\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9716 - val_loss: 0.1536\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0039 - val_accuracy: 0.9725 - val_loss: 0.1423\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9744 - val_loss: 0.1447\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0035 - val_accuracy: 0.9741 - val_loss: 0.1526\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9722 - val_loss: 0.1418\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9732 - val_loss: 0.1445\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0035 - val_accuracy: 0.9725 - val_loss: 0.1451\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9732 - val_loss: 0.1371\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0023 - val_accuracy: 0.9763 - val_loss: 0.1334\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9754 - val_loss: 0.1342\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 0.9713 - val_loss: 0.1749\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0076 - val_accuracy: 0.9691 - val_loss: 0.1560\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0119 - val_accuracy: 0.9719 - val_loss: 0.1347\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9747 - val_loss: 0.1357\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 8.9606e-04 - val_accuracy: 0.9700 - val_loss: 0.1498\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9778 - val_loss: 0.1370\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0107 - val_accuracy: 0.9772 - val_loss: 0.1218\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9769 - val_loss: 0.1399\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9716 - val_loss: 0.1521\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9769 - val_loss: 0.1167\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.9750 - val_loss: 0.1382\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0045 - val_accuracy: 0.9747 - val_loss: 0.1411\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9754 - val_loss: 0.1440\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0018 - val_accuracy: 0.9694 - val_loss: 0.1758\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.9685 - val_loss: 0.1695\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9778 - val_loss: 0.1276\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0129 - val_accuracy: 0.9738 - val_loss: 0.1437\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9772 - val_loss: 0.1257\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.9744 - val_loss: 0.1446\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9757 - val_loss: 0.1389\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9735 - val_loss: 0.1397\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0224 - val_accuracy: 0.9741 - val_loss: 0.1368\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0040 - val_accuracy: 0.9750 - val_loss: 0.1370\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0023 - val_accuracy: 0.9741 - val_loss: 0.1329\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0049 - val_accuracy: 0.9710 - val_loss: 0.1581\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9710 - val_loss: 0.1646\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9729 - val_loss: 0.1509\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0084 - val_accuracy: 0.9775 - val_loss: 0.1284\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9760 - val_loss: 0.1357\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 9.2266e-04 - val_accuracy: 0.9754 - val_loss: 0.1380\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0047 - val_accuracy: 0.9732 - val_loss: 0.1564\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9760 - val_loss: 0.1327\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9766 - val_loss: 0.1319\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9763 - val_loss: 0.1450\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.9732 - val_loss: 0.1566\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.9763 - val_loss: 0.1382\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0033 - val_accuracy: 0.9757 - val_loss: 0.1460\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9750 - val_loss: 0.1465\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0022 - val_accuracy: 0.9754 - val_loss: 0.1478\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9735 - val_loss: 0.1449\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0047 - val_accuracy: 0.9507 - val_loss: 0.2877\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0091 - val_accuracy: 0.9707 - val_loss: 0.1622\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0075 - val_accuracy: 0.9769 - val_loss: 0.1368\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9757 - val_loss: 0.1376\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.9778 - val_loss: 0.1265\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9769 - val_loss: 0.1279\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9772 - val_loss: 0.1340\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9766 - val_loss: 0.1407\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9757 - val_loss: 0.1286\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0021 - val_accuracy: 0.9760 - val_loss: 0.1520\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9778 - val_loss: 0.1326\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9766 - val_loss: 0.1332\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 7.2675e-04 - val_accuracy: 0.9785 - val_loss: 0.1323\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9766 - val_loss: 0.1489\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9747 - val_loss: 0.1515\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0222 - val_accuracy: 0.9735 - val_loss: 0.1258\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.9732 - val_loss: 0.1383\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0088 - val_accuracy: 0.9757 - val_loss: 0.1268\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9744 - val_loss: 0.1343\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9763 - val_loss: 0.1373\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 5.7581e-04 - val_accuracy: 0.9750 - val_loss: 0.1361\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9747 - val_loss: 0.1434\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0033 - val_accuracy: 0.9732 - val_loss: 0.1556\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9772 - val_loss: 0.1312\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.9747 - val_loss: 0.1396\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.9754 - val_loss: 0.1399\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9763 - val_loss: 0.1408\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9766 - val_loss: 0.1250\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9766 - val_loss: 0.1338\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 8.8888e-04 - val_accuracy: 0.9775 - val_loss: 0.1376\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9782 - val_loss: 0.1400\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 0.9775 - val_loss: 0.1295\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0023 - val_accuracy: 0.9754 - val_loss: 0.1466\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0045 - val_accuracy: 0.9729 - val_loss: 0.1570\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9763 - val_loss: 0.1545\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9754 - val_loss: 0.1589\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9794 - val_loss: 0.1272\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9744 - val_loss: 0.1432\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9750 - val_loss: 0.1497\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9750 - val_loss: 0.1410\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.9782 - val_loss: 0.1188\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.9763 - val_loss: 0.1322\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 8.6863e-04 - val_accuracy: 0.9741 - val_loss: 0.1565\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.2604e-04 - val_accuracy: 0.9760 - val_loss: 0.1432\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0048 - val_accuracy: 0.9722 - val_loss: 0.1601\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9738 - val_loss: 0.1544\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0118 - val_accuracy: 0.9694 - val_loss: 0.1540\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9651 - val_loss: 0.1658\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 6.9219e-04 - val_accuracy: 0.9716 - val_loss: 0.1564\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9725 - val_loss: 0.1445\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9741 - val_loss: 0.1403\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0024 - val_accuracy: 0.9766 - val_loss: 0.1377\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9741 - val_loss: 0.1403\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0038 - val_accuracy: 0.9747 - val_loss: 0.1437\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 6.5554e-04 - val_accuracy: 0.9757 - val_loss: 0.1439\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 7.3705e-04 - val_accuracy: 0.9754 - val_loss: 0.1429\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.9732 - val_loss: 0.1587\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9750 - val_loss: 0.1421\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9722 - val_loss: 0.1419\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9738 - val_loss: 0.1536\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9729 - val_loss: 0.1615\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9700 - val_loss: 0.1695\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9741 - val_loss: 0.1471\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9738 - val_loss: 0.1434\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0022 - val_accuracy: 0.9713 - val_loss: 0.1717\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9747 - val_loss: 0.1515\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 8.9446e-04 - val_accuracy: 0.9710 - val_loss: 0.1837\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0043 - val_accuracy: 0.9729 - val_loss: 0.1488\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9738 - val_loss: 0.1478\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 5.7008e-04 - val_accuracy: 0.9735 - val_loss: 0.1532\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 7.6161e-04 - val_accuracy: 0.9747 - val_loss: 0.1567\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 4.6483e-04 - val_accuracy: 0.9741 - val_loss: 0.1566\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9741 - val_loss: 0.1647\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0092 - val_accuracy: 0.9722 - val_loss: 0.1517\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9725 - val_loss: 0.1640\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9704 - val_loss: 0.1609\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0021 - val_accuracy: 0.9741 - val_loss: 0.1559\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9685 - val_loss: 0.1779\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9676 - val_loss: 0.2020\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0078 - val_accuracy: 0.9732 - val_loss: 0.1398\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9722 - val_loss: 0.1354\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9716 - val_loss: 0.1497\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.9744 - val_loss: 0.1348\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 7.7648e-04 - val_accuracy: 0.9725 - val_loss: 0.1440\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9732 - val_loss: 0.1470\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9732 - val_loss: 0.1420\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9763 - val_loss: 0.1417\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0053 - val_accuracy: 0.9754 - val_loss: 0.1468\n\n\n\n\nINFO: Training model for L_ELBOW_injury_risk...\nINFO: Loaded 10 features for L_ELBOW_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 10), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.8837 - loss: 0.2746 - val_accuracy: 0.9647 - val_loss: 0.0868\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9616 - loss: 0.1036 - val_accuracy: 0.9722 - val_loss: 0.0633\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9624 - loss: 0.0933 - val_accuracy: 0.9707 - val_loss: 0.0677\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9610 - loss: 0.0972 - val_accuracy: 0.9685 - val_loss: 0.0733\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9657 - loss: 0.0864 - val_accuracy: 0.9679 - val_loss: 0.0714\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9648 - loss: 0.0899 - val_accuracy: 0.9729 - val_loss: 0.0610\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9631 - loss: 0.0892 - val_accuracy: 0.9738 - val_loss: 0.0585\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9686 - loss: 0.0836 - val_accuracy: 0.9719 - val_loss: 0.0621\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9671 - loss: 0.0794 - val_accuracy: 0.9775 - val_loss: 0.0569\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9699 - loss: 0.0760 - val_accuracy: 0.9704 - val_loss: 0.0697\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9672 - loss: 0.0801 - val_accuracy: 0.9629 - val_loss: 0.0856\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9676 - loss: 0.0808 - val_accuracy: 0.9738 - val_loss: 0.0589\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9689 - loss: 0.0793 - val_accuracy: 0.9763 - val_loss: 0.0554\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9667 - loss: 0.0786 - val_accuracy: 0.9754 - val_loss: 0.0563\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9719 - loss: 0.0718 - val_accuracy: 0.9685 - val_loss: 0.0669\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9684 - loss: 0.0810 - val_accuracy: 0.9803 - val_loss: 0.0541\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9701 - loss: 0.0715 - val_accuracy: 0.9716 - val_loss: 0.0634\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9702 - loss: 0.0720 - val_accuracy: 0.9741 - val_loss: 0.0569\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9671 - loss: 0.0721 - val_accuracy: 0.9716 - val_loss: 0.0605\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9698 - loss: 0.0714 - val_accuracy: 0.9760 - val_loss: 0.0555\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9727 - loss: 0.0656 - val_accuracy: 0.9613 - val_loss: 0.0997\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9678 - loss: 0.0726 - val_accuracy: 0.9660 - val_loss: 0.0778\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9687 - loss: 0.0698 - val_accuracy: 0.9769 - val_loss: 0.0529\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9712 - loss: 0.0674 - val_accuracy: 0.9772 - val_loss: 0.0558\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9708 - loss: 0.0675 - val_accuracy: 0.9613 - val_loss: 0.0983\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9674 - loss: 0.0719 - val_accuracy: 0.9807 - val_loss: 0.0535\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9712 - loss: 0.0648 - val_accuracy: 0.9722 - val_loss: 0.0615\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9717 - loss: 0.0641 - val_accuracy: 0.9766 - val_loss: 0.0589\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9705 - loss: 0.0638 - val_accuracy: 0.9707 - val_loss: 0.0632\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9687 - loss: 0.0670 - val_accuracy: 0.9713 - val_loss: 0.0655\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9725 - loss: 0.0628 - val_accuracy: 0.9778 - val_loss: 0.0554\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9703 - loss: 0.0629 - val_accuracy: 0.9785 - val_loss: 0.0548\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9740 - loss: 0.0597 - val_accuracy: 0.9778 - val_loss: 0.0572\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9722 - loss: 0.0637 - val_accuracy: 0.9716 - val_loss: 0.0717\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9698 - loss: 0.0648 - val_accuracy: 0.9741 - val_loss: 0.0663\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9734 - loss: 0.0600 - val_accuracy: 0.9775 - val_loss: 0.0575\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9748 - loss: 0.0575 - val_accuracy: 0.9803 - val_loss: 0.0613\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9696 - loss: 0.0633 - val_accuracy: 0.9782 - val_loss: 0.0574\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9701 - loss: 0.0583 - val_accuracy: 0.9729 - val_loss: 0.0760\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9711 - loss: 0.0632 - val_accuracy: 0.9775 - val_loss: 0.0639\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9736 - loss: 0.0579 - val_accuracy: 0.9732 - val_loss: 0.0732\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9727 - loss: 0.0622 - val_accuracy: 0.9775 - val_loss: 0.0650\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9724 - loss: 0.0572 - val_accuracy: 0.9807 - val_loss: 0.0631\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9734 - loss: 0.0570 - val_accuracy: 0.9725 - val_loss: 0.0802\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9727 - loss: 0.0599 - val_accuracy: 0.9757 - val_loss: 0.0752\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9719 - loss: 0.0595 - val_accuracy: 0.9747 - val_loss: 0.0751\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9729 - loss: 0.0570 - val_accuracy: 0.9760 - val_loss: 0.0679\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9743 - loss: 0.0577 - val_accuracy: 0.9791 - val_loss: 0.0616\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9719 - loss: 0.0559 - val_accuracy: 0.9713 - val_loss: 0.0860\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9752 - loss: 0.0574 - val_accuracy: 0.9735 - val_loss: 0.0727\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9763 - loss: 0.0527 - val_accuracy: 0.9691 - val_loss: 0.0941\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9749 - loss: 0.0578 - val_accuracy: 0.9788 - val_loss: 0.0707\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9740 - loss: 0.0536 - val_accuracy: 0.9763 - val_loss: 0.0746\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9764 - loss: 0.0516 - val_accuracy: 0.9782 - val_loss: 0.0763\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9759 - loss: 0.0546 - val_accuracy: 0.9794 - val_loss: 0.0759\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9761 - loss: 0.0528 - val_accuracy: 0.9722 - val_loss: 0.0829\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9741 - loss: 0.0538 - val_accuracy: 0.9672 - val_loss: 0.0989\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9743 - loss: 0.0557 - val_accuracy: 0.9785 - val_loss: 0.0763\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9742 - loss: 0.0522 - val_accuracy: 0.9785 - val_loss: 0.0721\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9779 - loss: 0.0489 - val_accuracy: 0.9769 - val_loss: 0.0813\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9776 - loss: 0.0512 - val_accuracy: 0.9722 - val_loss: 0.1124\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9792 - loss: 0.0453 - val_accuracy: 0.9763 - val_loss: 0.0865\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9790 - loss: 0.0473 - val_accuracy: 0.9810 - val_loss: 0.0885\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9777 - loss: 0.0472 - val_accuracy: 0.9803 - val_loss: 0.0866\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9777 - loss: 0.0460 - val_accuracy: 0.9769 - val_loss: 0.0922\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9814 - loss: 0.0426 - val_accuracy: 0.9735 - val_loss: 0.0977\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9748 - loss: 0.0533 - val_accuracy: 0.9741 - val_loss: 0.1094\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9766 - loss: 0.0486 - val_accuracy: 0.9741 - val_loss: 0.0973\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9801 - loss: 0.0415 - val_accuracy: 0.9763 - val_loss: 0.0954\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9782 - loss: 0.0455 - val_accuracy: 0.9800 - val_loss: 0.0766\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9811 - loss: 0.0425 - val_accuracy: 0.9807 - val_loss: 0.0878\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9773 - loss: 0.0462 - val_accuracy: 0.9704 - val_loss: 0.1137\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9794 - loss: 0.0439 - val_accuracy: 0.9691 - val_loss: 0.1415\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9822 - loss: 0.0433 - val_accuracy: 0.9757 - val_loss: 0.1029\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9786 - loss: 0.0441 - val_accuracy: 0.9735 - val_loss: 0.1307\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9807 - loss: 0.0410 - val_accuracy: 0.9800 - val_loss: 0.0930\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9797 - loss: 0.0409 - val_accuracy: 0.9738 - val_loss: 0.1223\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9827 - loss: 0.0378 - val_accuracy: 0.9800 - val_loss: 0.1049\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9816 - loss: 0.0411 - val_accuracy: 0.9766 - val_loss: 0.0981\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9835 - loss: 0.0385 - val_accuracy: 0.9682 - val_loss: 0.1337\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9828 - loss: 0.0368 - val_accuracy: 0.9732 - val_loss: 0.1119\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9829 - loss: 0.0376 - val_accuracy: 0.9741 - val_loss: 0.1103\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9817 - loss: 0.0381 - val_accuracy: 0.9747 - val_loss: 0.1275\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9836 - loss: 0.0376 - val_accuracy: 0.9725 - val_loss: 0.1098\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9844 - loss: 0.0341 - val_accuracy: 0.9685 - val_loss: 0.1324\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9830 - loss: 0.0362 - val_accuracy: 0.9710 - val_loss: 0.1201\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9857 - loss: 0.0324 - val_accuracy: 0.9760 - val_loss: 0.1284\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9850 - loss: 0.0326 - val_accuracy: 0.9694 - val_loss: 0.1411\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9857 - loss: 0.0340 - val_accuracy: 0.9707 - val_loss: 0.1400\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9841 - loss: 0.0364 - val_accuracy: 0.9747 - val_loss: 0.1180\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9860 - loss: 0.0315 - val_accuracy: 0.9694 - val_loss: 0.1409\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0307 - val_accuracy: 0.9741 - val_loss: 0.1257\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9859 - loss: 0.0335 - val_accuracy: 0.9775 - val_loss: 0.1267\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9845 - loss: 0.0324 - val_accuracy: 0.9750 - val_loss: 0.1213\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9856 - loss: 0.0339 - val_accuracy: 0.9722 - val_loss: 0.1268\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0318 - val_accuracy: 0.9738 - val_loss: 0.1127\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9852 - loss: 0.0326 - val_accuracy: 0.9722 - val_loss: 0.1391\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0273 - val_accuracy: 0.9663 - val_loss: 0.1718\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9893 - loss: 0.0269 - val_accuracy: 0.9704 - val_loss: 0.1529\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0285 - val_accuracy: 0.9657 - val_loss: 0.1770\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9863 - loss: 0.0310 - val_accuracy: 0.9651 - val_loss: 0.1485\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0280 - val_accuracy: 0.9663 - val_loss: 0.1669\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9887 - loss: 0.0269 - val_accuracy: 0.9722 - val_loss: 0.1294\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0245 - val_accuracy: 0.9735 - val_loss: 0.1362\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9899 - loss: 0.0242 - val_accuracy: 0.9707 - val_loss: 0.1647\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0272 - val_accuracy: 0.9704 - val_loss: 0.1680\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0274 - val_accuracy: 0.9763 - val_loss: 0.1245\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0253 - val_accuracy: 0.9769 - val_loss: 0.1263\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0256 - val_accuracy: 0.9741 - val_loss: 0.1309\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9879 - loss: 0.0286 - val_accuracy: 0.9676 - val_loss: 0.1739\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9892 - loss: 0.0235 - val_accuracy: 0.9682 - val_loss: 0.1502\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0201 - val_accuracy: 0.9688 - val_loss: 0.1834\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0246 - val_accuracy: 0.9729 - val_loss: 0.1447\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0269 - val_accuracy: 0.9766 - val_loss: 0.1402\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9899 - loss: 0.0246 - val_accuracy: 0.9769 - val_loss: 0.1418\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0269 - val_accuracy: 0.9766 - val_loss: 0.1381\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0234 - val_accuracy: 0.9691 - val_loss: 0.1676\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0251 - val_accuracy: 0.9725 - val_loss: 0.1443\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9895 - loss: 0.0245 - val_accuracy: 0.9719 - val_loss: 0.1414\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0249 - val_accuracy: 0.9738 - val_loss: 0.1257\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0210 - val_accuracy: 0.9697 - val_loss: 0.1825\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0247 - val_accuracy: 0.9722 - val_loss: 0.1614\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0215 - val_accuracy: 0.9685 - val_loss: 0.1488\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0231 - val_accuracy: 0.9722 - val_loss: 0.1670\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0208 - val_accuracy: 0.9710 - val_loss: 0.1597\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0196 - val_accuracy: 0.9676 - val_loss: 0.1642\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9906 - loss: 0.0227 - val_accuracy: 0.9669 - val_loss: 0.1527\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9902 - loss: 0.0224 - val_accuracy: 0.9738 - val_loss: 0.1479\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0189 - val_accuracy: 0.9754 - val_loss: 0.1288\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0220 - val_accuracy: 0.9660 - val_loss: 0.1792\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0166 - val_accuracy: 0.9700 - val_loss: 0.1789\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0218 - val_accuracy: 0.9632 - val_loss: 0.1888\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0211 - val_accuracy: 0.9722 - val_loss: 0.1530\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9920 - loss: 0.0194 - val_accuracy: 0.9688 - val_loss: 0.1723\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0175 - val_accuracy: 0.9710 - val_loss: 0.1553\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9914 - loss: 0.0209 - val_accuracy: 0.9691 - val_loss: 0.1998\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9906 - loss: 0.0213 - val_accuracy: 0.9719 - val_loss: 0.1793\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0168 - val_accuracy: 0.9669 - val_loss: 0.1836\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0170 - val_accuracy: 0.9663 - val_loss: 0.1821\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9916 - loss: 0.0187 - val_accuracy: 0.9672 - val_loss: 0.1808\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0224 - val_accuracy: 0.9685 - val_loss: 0.1731\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0150 - val_accuracy: 0.9691 - val_loss: 0.1816\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0173 - val_accuracy: 0.9694 - val_loss: 0.1660\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0226 - val_accuracy: 0.9722 - val_loss: 0.1672\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0195 - val_accuracy: 0.9682 - val_loss: 0.1799\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0188 - val_accuracy: 0.9685 - val_loss: 0.2056\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0144 - val_accuracy: 0.9729 - val_loss: 0.1779\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0196 - val_accuracy: 0.9744 - val_loss: 0.1635\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0196 - val_accuracy: 0.9722 - val_loss: 0.1787\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0158 - val_accuracy: 0.9704 - val_loss: 0.1864\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0163 - val_accuracy: 0.9710 - val_loss: 0.1866\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0138 - val_accuracy: 0.9763 - val_loss: 0.1694\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9915 - loss: 0.0228 - val_accuracy: 0.9716 - val_loss: 0.1954\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0162 - val_accuracy: 0.9713 - val_loss: 0.2044\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9916 - loss: 0.0183 - val_accuracy: 0.9719 - val_loss: 0.1769\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0138 - val_accuracy: 0.9735 - val_loss: 0.1757\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0125 - val_accuracy: 0.9654 - val_loss: 0.2183\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0189 - val_accuracy: 0.9672 - val_loss: 0.1956\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0142 - val_accuracy: 0.9754 - val_loss: 0.1720\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0149 - val_accuracy: 0.9725 - val_loss: 0.1847\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0173 - val_accuracy: 0.9694 - val_loss: 0.2115\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0121 - val_accuracy: 0.9700 - val_loss: 0.1683\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0140 - val_accuracy: 0.9741 - val_loss: 0.1858\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0147 - val_accuracy: 0.9704 - val_loss: 0.1930\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0161 - val_accuracy: 0.9676 - val_loss: 0.1948\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0136 - val_accuracy: 0.9707 - val_loss: 0.1935\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0121 - val_accuracy: 0.9719 - val_loss: 0.1909\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0132 - val_accuracy: 0.9660 - val_loss: 0.2128\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0130 - val_accuracy: 0.9663 - val_loss: 0.2239\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0160 - val_accuracy: 0.9744 - val_loss: 0.1776\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0141 - val_accuracy: 0.9713 - val_loss: 0.1718\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0128 - val_accuracy: 0.9672 - val_loss: 0.1948\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0152 - val_accuracy: 0.9647 - val_loss: 0.1997\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0155 - val_accuracy: 0.9691 - val_loss: 0.1962\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0125 - val_accuracy: 0.9691 - val_loss: 0.2081\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0120 - val_accuracy: 0.9710 - val_loss: 0.2047\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0138 - val_accuracy: 0.9732 - val_loss: 0.1841\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0132 - val_accuracy: 0.9729 - val_loss: 0.1959\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0097 - val_accuracy: 0.9707 - val_loss: 0.2090\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0134 - val_accuracy: 0.9744 - val_loss: 0.1968\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0128 - val_accuracy: 0.9710 - val_loss: 0.2223\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0142 - val_accuracy: 0.9716 - val_loss: 0.2108\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0142 - val_accuracy: 0.9691 - val_loss: 0.2301\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0106 - val_accuracy: 0.9679 - val_loss: 0.2634\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0143 - val_accuracy: 0.9707 - val_loss: 0.1937\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0099 - val_accuracy: 0.9660 - val_loss: 0.2168\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0118 - val_accuracy: 0.9704 - val_loss: 0.1971\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0136 - val_accuracy: 0.9719 - val_loss: 0.2155\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0096 - val_accuracy: 0.9707 - val_loss: 0.1896\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0114 - val_accuracy: 0.9700 - val_loss: 0.1955\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0085 - val_accuracy: 0.9635 - val_loss: 0.2325\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0189 - val_accuracy: 0.9704 - val_loss: 0.1808\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0180 - val_accuracy: 0.9691 - val_loss: 0.1952\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0106 - val_accuracy: 0.9729 - val_loss: 0.1989\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0095 - val_accuracy: 0.9676 - val_loss: 0.2403\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0080 - val_accuracy: 0.9679 - val_loss: 0.2327\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0188 - val_accuracy: 0.9685 - val_loss: 0.2033\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 0.9691 - val_loss: 0.2179\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0127 - val_accuracy: 0.9710 - val_loss: 0.2135\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0094 - val_accuracy: 0.9688 - val_loss: 0.1940\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0135 - val_accuracy: 0.9654 - val_loss: 0.2402\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0091 - val_accuracy: 0.9694 - val_loss: 0.2450\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0103 - val_accuracy: 0.9738 - val_loss: 0.1845\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0167 - val_accuracy: 0.9744 - val_loss: 0.1968\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0116 - val_accuracy: 0.9725 - val_loss: 0.2120\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0085 - val_accuracy: 0.9716 - val_loss: 0.2018\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0107 - val_accuracy: 0.9716 - val_loss: 0.1947\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0096 - val_accuracy: 0.9685 - val_loss: 0.2079\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0087 - val_accuracy: 0.9654 - val_loss: 0.2414\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0196 - val_accuracy: 0.9707 - val_loss: 0.2161\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0090 - val_accuracy: 0.9676 - val_loss: 0.2102\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0100 - val_accuracy: 0.9697 - val_loss: 0.2307\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0110 - val_accuracy: 0.9710 - val_loss: 0.2289\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0079 - val_accuracy: 0.9644 - val_loss: 0.2921\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0113 - val_accuracy: 0.9669 - val_loss: 0.2353\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0083 - val_accuracy: 0.9725 - val_loss: 0.2071\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0117 - val_accuracy: 0.9685 - val_loss: 0.2161\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0079 - val_accuracy: 0.9735 - val_loss: 0.2258\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0186 - val_accuracy: 0.9663 - val_loss: 0.2428\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.9663 - val_loss: 0.2315\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0088 - val_accuracy: 0.9719 - val_loss: 0.2255\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0055 - val_accuracy: 0.9713 - val_loss: 0.2392\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0066 - val_accuracy: 0.9697 - val_loss: 0.2155\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0073 - val_accuracy: 0.9688 - val_loss: 0.2404\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0084 - val_accuracy: 0.9697 - val_loss: 0.2415\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0081 - val_accuracy: 0.9704 - val_loss: 0.2597\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0134 - val_accuracy: 0.9688 - val_loss: 0.2346\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0082 - val_accuracy: 0.9744 - val_loss: 0.2246\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0086 - val_accuracy: 0.9760 - val_loss: 0.1912\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0120 - val_accuracy: 0.9704 - val_loss: 0.2208\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0076 - val_accuracy: 0.9704 - val_loss: 0.2292\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0090 - val_accuracy: 0.9725 - val_loss: 0.2207\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0055 - val_accuracy: 0.9704 - val_loss: 0.2121\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0085 - val_accuracy: 0.9691 - val_loss: 0.2438\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0099 - val_accuracy: 0.9750 - val_loss: 0.2261\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0090 - val_accuracy: 0.9713 - val_loss: 0.2329\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0081 - val_accuracy: 0.9710 - val_loss: 0.2127\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0210 - val_accuracy: 0.9685 - val_loss: 0.2329\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0074 - val_accuracy: 0.9747 - val_loss: 0.2087\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9725 - val_loss: 0.2138\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9747 - val_loss: 0.2135\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0071 - val_accuracy: 0.9704 - val_loss: 0.2269\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0114 - val_accuracy: 0.9707 - val_loss: 0.2379\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0056 - val_accuracy: 0.9697 - val_loss: 0.2578\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0076 - val_accuracy: 0.9700 - val_loss: 0.2258\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0092 - val_accuracy: 0.9616 - val_loss: 0.3236\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0080 - val_accuracy: 0.9663 - val_loss: 0.2512\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0089 - val_accuracy: 0.9700 - val_loss: 0.2438\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0078 - val_accuracy: 0.9663 - val_loss: 0.2407\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0071 - val_accuracy: 0.9694 - val_loss: 0.2296\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0078 - val_accuracy: 0.9694 - val_loss: 0.2213\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0078 - val_accuracy: 0.9700 - val_loss: 0.2217\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9713 - val_loss: 0.2202\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0079 - val_accuracy: 0.9707 - val_loss: 0.2360\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9704 - val_loss: 0.2352\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0072 - val_accuracy: 0.9729 - val_loss: 0.2502\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0124 - val_accuracy: 0.9719 - val_loss: 0.2068\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0046 - val_accuracy: 0.9663 - val_loss: 0.2525\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.9697 - val_loss: 0.2203\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9663 - val_loss: 0.2433\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0067 - val_accuracy: 0.9713 - val_loss: 0.2373\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0079 - val_accuracy: 0.9700 - val_loss: 0.2278\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.9688 - val_loss: 0.2324\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0054 - val_accuracy: 0.9691 - val_loss: 0.2477\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9697 - val_loss: 0.2438\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0112 - val_accuracy: 0.9722 - val_loss: 0.2358\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0088 - val_accuracy: 0.9697 - val_loss: 0.2338\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0074 - val_accuracy: 0.9704 - val_loss: 0.2261\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9719 - val_loss: 0.2292\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 0.9694 - val_loss: 0.2447\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.9697 - val_loss: 0.2138\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.9694 - val_loss: 0.2241\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0081 - val_accuracy: 0.9710 - val_loss: 0.2371\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0061 - val_accuracy: 0.9697 - val_loss: 0.2441\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.9713 - val_loss: 0.2358\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0053 - val_accuracy: 0.9713 - val_loss: 0.2336\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0079 - val_accuracy: 0.9707 - val_loss: 0.2305\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0088 - val_accuracy: 0.9641 - val_loss: 0.2548\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0057 - val_accuracy: 0.9741 - val_loss: 0.2336\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0091 - val_accuracy: 0.9716 - val_loss: 0.2234\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9713 - val_loss: 0.2428\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9729 - val_loss: 0.2217\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9747 - val_loss: 0.2117\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0119 - val_accuracy: 0.9704 - val_loss: 0.2487\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9719 - val_loss: 0.2233\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0052 - val_accuracy: 0.9713 - val_loss: 0.2378\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0089 - val_accuracy: 0.9725 - val_loss: 0.2249\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0051 - val_accuracy: 0.9710 - val_loss: 0.2244\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.9722 - val_loss: 0.2258\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0116 - val_accuracy: 0.9704 - val_loss: 0.2424\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.9741 - val_loss: 0.2237\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0044 - val_accuracy: 0.9735 - val_loss: 0.2168\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0100 - val_accuracy: 0.9738 - val_loss: 0.2257\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0080 - val_accuracy: 0.9735 - val_loss: 0.2304\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9741 - val_loss: 0.2372\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0066 - val_accuracy: 0.9732 - val_loss: 0.2255\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0050 - val_accuracy: 0.9741 - val_loss: 0.2283\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0109 - val_accuracy: 0.9791 - val_loss: 0.2194\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0084 - val_accuracy: 0.9722 - val_loss: 0.2427\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0073 - val_accuracy: 0.9700 - val_loss: 0.2581\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9735 - val_loss: 0.2133\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0078 - val_accuracy: 0.9716 - val_loss: 0.2235\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9688 - val_loss: 0.2422\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0041 - val_accuracy: 0.9725 - val_loss: 0.2261\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0106 - val_accuracy: 0.9710 - val_loss: 0.2476\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0064 - val_accuracy: 0.9676 - val_loss: 0.2603\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0104 - val_accuracy: 0.9713 - val_loss: 0.2305\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9704 - val_loss: 0.2515\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.9716 - val_loss: 0.2280\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0083 - val_accuracy: 0.9691 - val_loss: 0.2296\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.9700 - val_loss: 0.2578\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9694 - val_loss: 0.2540\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0054 - val_accuracy: 0.9704 - val_loss: 0.2568\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0079 - val_accuracy: 0.9694 - val_loss: 0.2674\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0043 - val_accuracy: 0.9697 - val_loss: 0.2652\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9697 - val_loss: 0.2704\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9725 - val_loss: 0.2583\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.9691 - val_loss: 0.2895\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0060 - val_accuracy: 0.9732 - val_loss: 0.2357\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0142 - val_accuracy: 0.9676 - val_loss: 0.2701\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0040 - val_accuracy: 0.9663 - val_loss: 0.2758\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9676 - val_loss: 0.2662\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9700 - val_loss: 0.2536\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0052 - val_accuracy: 0.9697 - val_loss: 0.2643\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0086 - val_accuracy: 0.9713 - val_loss: 0.2415\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9685 - val_loss: 0.2508\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9660 - val_loss: 0.2634\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0097 - val_accuracy: 0.9694 - val_loss: 0.2549\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9679 - val_loss: 0.2705\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0087 - val_accuracy: 0.9672 - val_loss: 0.2510\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0103 - val_accuracy: 0.9688 - val_loss: 0.2489\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.9713 - val_loss: 0.2585\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9691 - val_loss: 0.2547\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.9679 - val_loss: 0.2598\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0067 - val_accuracy: 0.9688 - val_loss: 0.2461\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9685 - val_loss: 0.2591\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9663 - val_loss: 0.2690\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0076 - val_accuracy: 0.9694 - val_loss: 0.2645\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0080 - val_accuracy: 0.9669 - val_loss: 0.2888\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.9732 - val_loss: 0.2455\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9719 - val_loss: 0.2566\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0032 - val_accuracy: 0.9685 - val_loss: 0.2509\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9676 - val_loss: 0.2698\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9710 - val_loss: 0.2676\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0094 - val_accuracy: 0.9663 - val_loss: 0.2577\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9672 - val_loss: 0.2400\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0096 - val_accuracy: 0.9669 - val_loss: 0.2600\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0037 - val_accuracy: 0.9685 - val_loss: 0.2400\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 0.9676 - val_loss: 0.2542\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0022 - val_accuracy: 0.9682 - val_loss: 0.2573\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0035 - val_accuracy: 0.9679 - val_loss: 0.2763\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.9679 - val_loss: 0.2491\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0101 - val_accuracy: 0.9682 - val_loss: 0.2447\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9672 - val_loss: 0.2644\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0085 - val_accuracy: 0.9688 - val_loss: 0.2640\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9647 - val_loss: 0.3127\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0067 - val_accuracy: 0.9688 - val_loss: 0.2541\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0030 - val_accuracy: 0.9688 - val_loss: 0.2484\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0028 - val_accuracy: 0.9710 - val_loss: 0.2421\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9672 - val_loss: 0.2723\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0071 - val_accuracy: 0.9704 - val_loss: 0.2411\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0039 - val_accuracy: 0.9707 - val_loss: 0.2507\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9697 - val_loss: 0.2638\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0046 - val_accuracy: 0.9700 - val_loss: 0.2461\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0068 - val_accuracy: 0.9679 - val_loss: 0.2570\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0067 - val_accuracy: 0.9691 - val_loss: 0.2571\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0084 - val_accuracy: 0.9697 - val_loss: 0.2285\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.9685 - val_loss: 0.2439\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0024 - val_accuracy: 0.9688 - val_loss: 0.2521\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9666 - val_loss: 0.2515\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9676 - val_loss: 0.2455\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0044 - val_accuracy: 0.9669 - val_loss: 0.2569\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0096 - val_accuracy: 0.9663 - val_loss: 0.2762\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0066 - val_accuracy: 0.9657 - val_loss: 0.2689\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9685 - val_loss: 0.2518\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9688 - val_loss: 0.2777\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9688 - val_loss: 0.2563\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0066 - val_accuracy: 0.9660 - val_loss: 0.2646\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.9691 - val_loss: 0.2571\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.9682 - val_loss: 0.2286\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.9716 - val_loss: 0.2334\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9688 - val_loss: 0.2501\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9694 - val_loss: 0.2451\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0024 - val_accuracy: 0.9704 - val_loss: 0.2495\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9722 - val_loss: 0.2398\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.9704 - val_loss: 0.2502\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.9722 - val_loss: 0.2276\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9700 - val_loss: 0.2326\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9713 - val_loss: 0.2256\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9704 - val_loss: 0.2380\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9694 - val_loss: 0.2508\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.9707 - val_loss: 0.2314\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.9672 - val_loss: 0.2452\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 0.9697 - val_loss: 0.2323\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0044 - val_accuracy: 0.9672 - val_loss: 0.2488\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0057 - val_accuracy: 0.9679 - val_loss: 0.2378\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0020 - val_accuracy: 0.9688 - val_loss: 0.2375\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.9679 - val_loss: 0.2392\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0031 - val_accuracy: 0.9672 - val_loss: 0.2572\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9676 - val_loss: 0.2430\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9691 - val_loss: 0.2293\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9694 - val_loss: 0.2475\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9700 - val_loss: 0.2569\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0031 - val_accuracy: 0.9676 - val_loss: 0.2537\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9697 - val_loss: 0.2686\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.9669 - val_loss: 0.2535\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0279 - val_accuracy: 0.9676 - val_loss: 0.2476\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9672 - val_loss: 0.2421\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9713 - val_loss: 0.2132\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9682 - val_loss: 0.2535\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9694 - val_loss: 0.2477\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9669 - val_loss: 0.2779\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.9676 - val_loss: 0.2800\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9676 - val_loss: 0.2311\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9697 - val_loss: 0.2368\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9713 - val_loss: 0.2251\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9697 - val_loss: 0.2372\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9682 - val_loss: 0.2395\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0065 - val_accuracy: 0.9722 - val_loss: 0.2415\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0118 - val_accuracy: 0.9707 - val_loss: 0.2328\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9713 - val_loss: 0.2330\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 9.0346e-04 - val_accuracy: 0.9716 - val_loss: 0.2327\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.9682 - val_loss: 0.2471\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9682 - val_loss: 0.2437\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.9676 - val_loss: 0.2616\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9716 - val_loss: 0.2294\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9716 - val_loss: 0.2335\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0021 - val_accuracy: 0.9679 - val_loss: 0.2615\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0081 - val_accuracy: 0.9757 - val_loss: 0.2355\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0081 - val_accuracy: 0.9707 - val_loss: 0.2409\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0035 - val_accuracy: 0.9700 - val_loss: 0.2366\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9691 - val_loss: 0.2411\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9707 - val_loss: 0.2395\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9679 - val_loss: 0.2630\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9700 - val_loss: 0.2351\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9697 - val_loss: 0.2606\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 0.9669 - val_loss: 0.2763\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9660 - val_loss: 0.2591\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9647 - val_loss: 0.2725\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9679 - val_loss: 0.2598\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0057 - val_accuracy: 0.9666 - val_loss: 0.2700\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9685 - val_loss: 0.2616\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0014 - val_accuracy: 0.9676 - val_loss: 0.2646\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9672 - val_loss: 0.2756\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0033 - val_accuracy: 0.9663 - val_loss: 0.2812\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0086 - val_accuracy: 0.9644 - val_loss: 0.2534\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0046 - val_accuracy: 0.9663 - val_loss: 0.2540\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.9697 - val_loss: 0.2451\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.9710 - val_loss: 0.2332\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9697 - val_loss: 0.2454\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9691 - val_loss: 0.2663\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0027 - val_accuracy: 0.9700 - val_loss: 0.2559\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9672 - val_loss: 0.2683\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0079 - val_accuracy: 0.9672 - val_loss: 0.2512\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9713 - val_loss: 0.2437\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9707 - val_loss: 0.2663\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0079 - val_accuracy: 0.9719 - val_loss: 0.2505\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9710 - val_loss: 0.2404\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9700 - val_loss: 0.2516\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9719 - val_loss: 0.2390\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0070 - val_accuracy: 0.9682 - val_loss: 0.2649\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.9700 - val_loss: 0.2591\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.5026e-04 - val_accuracy: 0.9688 - val_loss: 0.2618\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 6.8722e-04 - val_accuracy: 0.9682 - val_loss: 0.2650\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9685 - val_loss: 0.2715\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9679 - val_loss: 0.2571\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0157 - val_accuracy: 0.9704 - val_loss: 0.2445\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 0.9688 - val_loss: 0.2727\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.9682 - val_loss: 0.2663\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 5.7725e-04 - val_accuracy: 0.9679 - val_loss: 0.2739\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9697 - val_loss: 0.2496\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0057 - val_accuracy: 0.9682 - val_loss: 0.2794\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0081 - val_accuracy: 0.9704 - val_loss: 0.2452\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0063 - val_accuracy: 0.9704 - val_loss: 0.2407\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9710 - val_loss: 0.2357\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9707 - val_loss: 0.2461\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9725 - val_loss: 0.2187\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 0.9697 - val_loss: 0.2573\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 0.9713 - val_loss: 0.2603\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.9707 - val_loss: 0.2533\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9704 - val_loss: 0.2559\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9704 - val_loss: 0.2511\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9697 - val_loss: 0.2641\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9688 - val_loss: 0.2652\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9691 - val_loss: 0.2719\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.9682 - val_loss: 0.2546\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0085 - val_accuracy: 0.9676 - val_loss: 0.2583\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 0.9697 - val_loss: 0.2561\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 7.6758e-04 - val_accuracy: 0.9685 - val_loss: 0.2554\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 4.3707e-04 - val_accuracy: 0.9676 - val_loss: 0.2640\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 6.5134e-04 - val_accuracy: 0.9694 - val_loss: 0.2605\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9700 - val_loss: 0.2626\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9669 - val_loss: 0.2774\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.9666 - val_loss: 0.2563\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9663 - val_loss: 0.2773\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9669 - val_loss: 0.2679\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 5.2884e-04 - val_accuracy: 0.9682 - val_loss: 0.2785\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 0.9676 - val_loss: 0.2632\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0116 - val_accuracy: 0.9676 - val_loss: 0.2593\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9672 - val_loss: 0.2679\n\n\n\n\nINFO: Training model for R_ELBOW_injury_risk...\nINFO: Loaded 10 features for R_ELBOW_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 10), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.9144 - loss: 0.2536 - val_accuracy: 0.9772 - val_loss: 0.0716\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9647 - loss: 0.1034 - val_accuracy: 0.9760 - val_loss: 0.0725\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9639 - loss: 0.1029 - val_accuracy: 0.9716 - val_loss: 0.0922\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9642 - loss: 0.0979 - val_accuracy: 0.9741 - val_loss: 0.0736\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9665 - loss: 0.0956 - val_accuracy: 0.9750 - val_loss: 0.0676\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9662 - loss: 0.0918 - val_accuracy: 0.9794 - val_loss: 0.0621\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9685 - loss: 0.0848 - val_accuracy: 0.9782 - val_loss: 0.0672\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9676 - loss: 0.0844 - val_accuracy: 0.9707 - val_loss: 0.0748\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9687 - loss: 0.0798 - val_accuracy: 0.9769 - val_loss: 0.0553\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9684 - loss: 0.0800 - val_accuracy: 0.9803 - val_loss: 0.0605\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9683 - loss: 0.0761 - val_accuracy: 0.9797 - val_loss: 0.0543\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9698 - loss: 0.0733 - val_accuracy: 0.9713 - val_loss: 0.0611\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9743 - loss: 0.0673 - val_accuracy: 0.9725 - val_loss: 0.0649\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9719 - loss: 0.0642 - val_accuracy: 0.9754 - val_loss: 0.0605\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9736 - loss: 0.0598 - val_accuracy: 0.9676 - val_loss: 0.0769\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9762 - loss: 0.0578 - val_accuracy: 0.9738 - val_loss: 0.0632\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9776 - loss: 0.0542 - val_accuracy: 0.9685 - val_loss: 0.0702\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9746 - loss: 0.0563 - val_accuracy: 0.9710 - val_loss: 0.0695\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9794 - loss: 0.0483 - val_accuracy: 0.9794 - val_loss: 0.0567\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9798 - loss: 0.0498 - val_accuracy: 0.9741 - val_loss: 0.0644\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9819 - loss: 0.0444 - val_accuracy: 0.9638 - val_loss: 0.0744\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9803 - loss: 0.0498 - val_accuracy: 0.9576 - val_loss: 0.0899\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9804 - loss: 0.0469 - val_accuracy: 0.9750 - val_loss: 0.0672\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9804 - loss: 0.0446 - val_accuracy: 0.9694 - val_loss: 0.0717\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9822 - loss: 0.0436 - val_accuracy: 0.9725 - val_loss: 0.0678\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9823 - loss: 0.0401 - val_accuracy: 0.9738 - val_loss: 0.0649\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9831 - loss: 0.0396 - val_accuracy: 0.9638 - val_loss: 0.0906\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9750 - loss: 0.0576 - val_accuracy: 0.9669 - val_loss: 0.0816\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9836 - loss: 0.0367 - val_accuracy: 0.9719 - val_loss: 0.0735\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9817 - loss: 0.0429 - val_accuracy: 0.9663 - val_loss: 0.0867\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9825 - loss: 0.0396 - val_accuracy: 0.9520 - val_loss: 0.1116\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9823 - loss: 0.0444 - val_accuracy: 0.9713 - val_loss: 0.0743\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9837 - loss: 0.0395 - val_accuracy: 0.9641 - val_loss: 0.0860\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9829 - loss: 0.0371 - val_accuracy: 0.9676 - val_loss: 0.0880\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9845 - loss: 0.0354 - val_accuracy: 0.9682 - val_loss: 0.0929\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9815 - loss: 0.0413 - val_accuracy: 0.9685 - val_loss: 0.0883\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9840 - loss: 0.0333 - val_accuracy: 0.9672 - val_loss: 0.0924\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9867 - loss: 0.0328 - val_accuracy: 0.9672 - val_loss: 0.1002\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9826 - loss: 0.0337 - val_accuracy: 0.9691 - val_loss: 0.0913\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9776 - loss: 0.0659 - val_accuracy: 0.9707 - val_loss: 0.0904\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9827 - loss: 0.0414 - val_accuracy: 0.9632 - val_loss: 0.1051\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9852 - loss: 0.0324 - val_accuracy: 0.9694 - val_loss: 0.0899\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0312 - val_accuracy: 0.9641 - val_loss: 0.1073\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9897 - loss: 0.0271 - val_accuracy: 0.9657 - val_loss: 0.1070\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9899 - loss: 0.0271 - val_accuracy: 0.9672 - val_loss: 0.1137\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9868 - loss: 0.0327 - val_accuracy: 0.9651 - val_loss: 0.1238\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0359 - val_accuracy: 0.9669 - val_loss: 0.1081\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0267 - val_accuracy: 0.9700 - val_loss: 0.0950\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0243 - val_accuracy: 0.9635 - val_loss: 0.1282\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0290 - val_accuracy: 0.9694 - val_loss: 0.1009\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9895 - loss: 0.0257 - val_accuracy: 0.9713 - val_loss: 0.1029\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9895 - loss: 0.0282 - val_accuracy: 0.9626 - val_loss: 0.1364\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0222 - val_accuracy: 0.9697 - val_loss: 0.1027\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0256 - val_accuracy: 0.9641 - val_loss: 0.1208\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9849 - loss: 0.0365 - val_accuracy: 0.9682 - val_loss: 0.1077\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0253 - val_accuracy: 0.9697 - val_loss: 0.1039\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9915 - loss: 0.0225 - val_accuracy: 0.9619 - val_loss: 0.1358\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9889 - loss: 0.0256 - val_accuracy: 0.9676 - val_loss: 0.1176\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9915 - loss: 0.0210 - val_accuracy: 0.9641 - val_loss: 0.1483\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9900 - loss: 0.0234 - val_accuracy: 0.9682 - val_loss: 0.1083\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0174 - val_accuracy: 0.9660 - val_loss: 0.1302\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0211 - val_accuracy: 0.9616 - val_loss: 0.1385\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9914 - loss: 0.0194 - val_accuracy: 0.9682 - val_loss: 0.1150\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0264 - val_accuracy: 0.9676 - val_loss: 0.1230\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0239 - val_accuracy: 0.9657 - val_loss: 0.1532\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9909 - loss: 0.0222 - val_accuracy: 0.9660 - val_loss: 0.1374\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0207 - val_accuracy: 0.9647 - val_loss: 0.1361\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0229 - val_accuracy: 0.9679 - val_loss: 0.1102\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0340 - val_accuracy: 0.9591 - val_loss: 0.1525\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0194 - val_accuracy: 0.9657 - val_loss: 0.1333\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9920 - loss: 0.0176 - val_accuracy: 0.9676 - val_loss: 0.1263\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0186 - val_accuracy: 0.9657 - val_loss: 0.1313\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0194 - val_accuracy: 0.9660 - val_loss: 0.1240\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0186 - val_accuracy: 0.9697 - val_loss: 0.1116\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0260 - val_accuracy: 0.9644 - val_loss: 0.1435\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0178 - val_accuracy: 0.9647 - val_loss: 0.1464\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0197 - val_accuracy: 0.9647 - val_loss: 0.1328\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0189 - val_accuracy: 0.9651 - val_loss: 0.1434\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0166 - val_accuracy: 0.9638 - val_loss: 0.1422\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9897 - loss: 0.0238 - val_accuracy: 0.9632 - val_loss: 0.1504\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0187 - val_accuracy: 0.9644 - val_loss: 0.1447\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0151 - val_accuracy: 0.9641 - val_loss: 0.1490\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0162 - val_accuracy: 0.9644 - val_loss: 0.1620\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9916 - loss: 0.0214 - val_accuracy: 0.9622 - val_loss: 0.1609\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0150 - val_accuracy: 0.9641 - val_loss: 0.1580\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0184 - val_accuracy: 0.9626 - val_loss: 0.1800\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0184 - val_accuracy: 0.9679 - val_loss: 0.1438\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0197 - val_accuracy: 0.9657 - val_loss: 0.1388\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0226 - val_accuracy: 0.9654 - val_loss: 0.1526\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0135 - val_accuracy: 0.9660 - val_loss: 0.1435\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0169 - val_accuracy: 0.9704 - val_loss: 0.1351\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0202 - val_accuracy: 0.9672 - val_loss: 0.1351\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0166 - val_accuracy: 0.9663 - val_loss: 0.1511\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0130 - val_accuracy: 0.9676 - val_loss: 0.1496\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9916 - loss: 0.0195 - val_accuracy: 0.9651 - val_loss: 0.1550\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0138 - val_accuracy: 0.9666 - val_loss: 0.1517\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0159 - val_accuracy: 0.9585 - val_loss: 0.1922\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0149 - val_accuracy: 0.9685 - val_loss: 0.1463\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0171 - val_accuracy: 0.9666 - val_loss: 0.1483\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0163 - val_accuracy: 0.9647 - val_loss: 0.1665\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9897 - loss: 0.0266 - val_accuracy: 0.9651 - val_loss: 0.1654\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0148 - val_accuracy: 0.9672 - val_loss: 0.1504\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0137 - val_accuracy: 0.9672 - val_loss: 0.1452\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0141 - val_accuracy: 0.9704 - val_loss: 0.1390\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0146 - val_accuracy: 0.9594 - val_loss: 0.1862\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0152 - val_accuracy: 0.9644 - val_loss: 0.1751\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0154 - val_accuracy: 0.9654 - val_loss: 0.1627\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0154 - val_accuracy: 0.9647 - val_loss: 0.1621\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0189 - val_accuracy: 0.9682 - val_loss: 0.1402\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0113 - val_accuracy: 0.9663 - val_loss: 0.1572\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0124 - val_accuracy: 0.9663 - val_loss: 0.1562\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0101 - val_accuracy: 0.9607 - val_loss: 0.2036\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0162 - val_accuracy: 0.9632 - val_loss: 0.1729\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0205 - val_accuracy: 0.9682 - val_loss: 0.1472\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0089 - val_accuracy: 0.9688 - val_loss: 0.1385\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0117 - val_accuracy: 0.9657 - val_loss: 0.1683\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0167 - val_accuracy: 0.9663 - val_loss: 0.1632\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0134 - val_accuracy: 0.9644 - val_loss: 0.1914\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0145 - val_accuracy: 0.9676 - val_loss: 0.1494\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0113 - val_accuracy: 0.9657 - val_loss: 0.1737\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0140 - val_accuracy: 0.9638 - val_loss: 0.1716\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0108 - val_accuracy: 0.9685 - val_loss: 0.1433\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0128 - val_accuracy: 0.9654 - val_loss: 0.1826\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0153 - val_accuracy: 0.9641 - val_loss: 0.1535\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0121 - val_accuracy: 0.9676 - val_loss: 0.1575\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0129 - val_accuracy: 0.9657 - val_loss: 0.1771\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0093 - val_accuracy: 0.9676 - val_loss: 0.1604\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9672 - val_loss: 0.1612\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0134 - val_accuracy: 0.9644 - val_loss: 0.1860\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0147 - val_accuracy: 0.9688 - val_loss: 0.1496\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0260 - val_accuracy: 0.9697 - val_loss: 0.1450\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.9654 - val_loss: 0.1895\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0104 - val_accuracy: 0.9635 - val_loss: 0.1931\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0116 - val_accuracy: 0.9688 - val_loss: 0.1560\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0210 - val_accuracy: 0.9632 - val_loss: 0.1786\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0076 - val_accuracy: 0.9660 - val_loss: 0.1719\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0106 - val_accuracy: 0.9663 - val_loss: 0.1603\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.9651 - val_loss: 0.1564\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0257 - val_accuracy: 0.9660 - val_loss: 0.1653\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0101 - val_accuracy: 0.9697 - val_loss: 0.1522\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0082 - val_accuracy: 0.9685 - val_loss: 0.1637\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0106 - val_accuracy: 0.9663 - val_loss: 0.1757\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0145 - val_accuracy: 0.9641 - val_loss: 0.1678\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0097 - val_accuracy: 0.9654 - val_loss: 0.1802\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0078 - val_accuracy: 0.9644 - val_loss: 0.1817\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9641 - val_loss: 0.1985\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0088 - val_accuracy: 0.9647 - val_loss: 0.1946\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9682 - val_loss: 0.1504\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0128 - val_accuracy: 0.9613 - val_loss: 0.2040\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0090 - val_accuracy: 0.9679 - val_loss: 0.1566\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0081 - val_accuracy: 0.9700 - val_loss: 0.1518\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0120 - val_accuracy: 0.9635 - val_loss: 0.1993\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0199 - val_accuracy: 0.9666 - val_loss: 0.1720\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0087 - val_accuracy: 0.9697 - val_loss: 0.1646\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0130 - val_accuracy: 0.9679 - val_loss: 0.1521\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0157 - val_accuracy: 0.9654 - val_loss: 0.1658\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9660 - val_loss: 0.1715\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9666 - val_loss: 0.1828\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0069 - val_accuracy: 0.9647 - val_loss: 0.2063\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0065 - val_accuracy: 0.9641 - val_loss: 0.2058\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0102 - val_accuracy: 0.9616 - val_loss: 0.2006\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0197 - val_accuracy: 0.9660 - val_loss: 0.1648\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0073 - val_accuracy: 0.9691 - val_loss: 0.1597\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0088 - val_accuracy: 0.9657 - val_loss: 0.1975\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0086 - val_accuracy: 0.9679 - val_loss: 0.1645\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.9663 - val_loss: 0.1845\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0112 - val_accuracy: 0.9676 - val_loss: 0.1690\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0066 - val_accuracy: 0.9654 - val_loss: 0.1950\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0071 - val_accuracy: 0.9679 - val_loss: 0.1735\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.9591 - val_loss: 0.1930\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0070 - val_accuracy: 0.9626 - val_loss: 0.2068\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9635 - val_loss: 0.2044\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0083 - val_accuracy: 0.9694 - val_loss: 0.1682\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0072 - val_accuracy: 0.9663 - val_loss: 0.1755\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.9666 - val_loss: 0.1855\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0074 - val_accuracy: 0.9669 - val_loss: 0.1829\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0136 - val_accuracy: 0.9647 - val_loss: 0.2066\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0064 - val_accuracy: 0.9688 - val_loss: 0.1680\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.9660 - val_loss: 0.1867\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0074 - val_accuracy: 0.9610 - val_loss: 0.2213\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0096 - val_accuracy: 0.9666 - val_loss: 0.1801\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0065 - val_accuracy: 0.9651 - val_loss: 0.1951\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0071 - val_accuracy: 0.9644 - val_loss: 0.1900\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0090 - val_accuracy: 0.9669 - val_loss: 0.1837\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0072 - val_accuracy: 0.9669 - val_loss: 0.1857\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0070 - val_accuracy: 0.9647 - val_loss: 0.1978\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0071 - val_accuracy: 0.9663 - val_loss: 0.1927\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0079 - val_accuracy: 0.9663 - val_loss: 0.1981\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0089 - val_accuracy: 0.9498 - val_loss: 0.2281\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9853 - loss: 0.0598 - val_accuracy: 0.9688 - val_loss: 0.1768\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0089 - val_accuracy: 0.9679 - val_loss: 0.1690\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.9632 - val_loss: 0.2042\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0080 - val_accuracy: 0.9651 - val_loss: 0.1848\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.9672 - val_loss: 0.1746\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0097 - val_accuracy: 0.9632 - val_loss: 0.1944\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9632 - val_loss: 0.2030\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0092 - val_accuracy: 0.9666 - val_loss: 0.1789\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0320 - val_accuracy: 0.9598 - val_loss: 0.2050\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0083 - val_accuracy: 0.9669 - val_loss: 0.1905\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0062 - val_accuracy: 0.9651 - val_loss: 0.1847\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0061 - val_accuracy: 0.9635 - val_loss: 0.1932\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0078 - val_accuracy: 0.9644 - val_loss: 0.1879\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9679 - val_loss: 0.1836\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9651 - val_loss: 0.2012\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0112 - val_accuracy: 0.9685 - val_loss: 0.1667\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0101 - val_accuracy: 0.9579 - val_loss: 0.1963\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.9635 - val_loss: 0.2112\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0049 - val_accuracy: 0.9647 - val_loss: 0.2109\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.9619 - val_loss: 0.2237\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0084 - val_accuracy: 0.9644 - val_loss: 0.1966\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9685 - val_loss: 0.1809\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.9635 - val_loss: 0.2043\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0094 - val_accuracy: 0.9672 - val_loss: 0.1700\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0095 - val_accuracy: 0.9657 - val_loss: 0.1793\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0125 - val_accuracy: 0.9632 - val_loss: 0.1913\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0043 - val_accuracy: 0.9647 - val_loss: 0.2019\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.9616 - val_loss: 0.2118\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0077 - val_accuracy: 0.9598 - val_loss: 0.2366\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0086 - val_accuracy: 0.9657 - val_loss: 0.1908\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0072 - val_accuracy: 0.9604 - val_loss: 0.2253\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 0.9660 - val_loss: 0.1869\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9654 - val_loss: 0.1975\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9663 - val_loss: 0.1982\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0101 - val_accuracy: 0.9654 - val_loss: 0.2032\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.9626 - val_loss: 0.2049\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0047 - val_accuracy: 0.9676 - val_loss: 0.1923\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0093 - val_accuracy: 0.9663 - val_loss: 0.1945\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.9651 - val_loss: 0.2094\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0066 - val_accuracy: 0.9660 - val_loss: 0.2036\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0073 - val_accuracy: 0.9651 - val_loss: 0.2029\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0122 - val_accuracy: 0.9638 - val_loss: 0.2168\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9629 - val_loss: 0.2134\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0078 - val_accuracy: 0.9598 - val_loss: 0.2233\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0088 - val_accuracy: 0.9594 - val_loss: 0.2025\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0055 - val_accuracy: 0.9644 - val_loss: 0.2027\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0081 - val_accuracy: 0.9632 - val_loss: 0.2107\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9638 - val_loss: 0.2165\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0087 - val_accuracy: 0.9660 - val_loss: 0.2025\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0060 - val_accuracy: 0.9641 - val_loss: 0.2057\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0067 - val_accuracy: 0.9651 - val_loss: 0.2040\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9651 - val_loss: 0.2038\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.9679 - val_loss: 0.1862\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0097 - val_accuracy: 0.9679 - val_loss: 0.1744\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 0.9629 - val_loss: 0.2169\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0050 - val_accuracy: 0.9629 - val_loss: 0.2258\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9657 - val_loss: 0.1972\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0035 - val_accuracy: 0.9666 - val_loss: 0.2037\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 0.9644 - val_loss: 0.2141\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0091 - val_accuracy: 0.9654 - val_loss: 0.1950\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.9632 - val_loss: 0.2182\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0055 - val_accuracy: 0.9647 - val_loss: 0.2020\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9657 - val_loss: 0.2045\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9622 - val_loss: 0.2377\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9613 - val_loss: 0.2334\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0121 - val_accuracy: 0.9622 - val_loss: 0.2018\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0085 - val_accuracy: 0.9647 - val_loss: 0.1733\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0081 - val_accuracy: 0.9657 - val_loss: 0.1842\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0050 - val_accuracy: 0.9632 - val_loss: 0.2051\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0046 - val_accuracy: 0.9660 - val_loss: 0.1918\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0066 - val_accuracy: 0.9651 - val_loss: 0.2022\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0337 - val_accuracy: 0.9647 - val_loss: 0.1872\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0113 - val_accuracy: 0.9635 - val_loss: 0.2022\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0110 - val_accuracy: 0.9613 - val_loss: 0.2175\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9629 - val_loss: 0.2049\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9635 - val_loss: 0.2111\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 0.9663 - val_loss: 0.1867\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9654 - val_loss: 0.2188\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0064 - val_accuracy: 0.9676 - val_loss: 0.2093\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0111 - val_accuracy: 0.9651 - val_loss: 0.2079\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0074 - val_accuracy: 0.9679 - val_loss: 0.1993\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0044 - val_accuracy: 0.9654 - val_loss: 0.2091\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.9676 - val_loss: 0.1844\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9669 - val_loss: 0.1937\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9651 - val_loss: 0.2109\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.9626 - val_loss: 0.2431\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9632 - val_loss: 0.2329\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.9635 - val_loss: 0.2318\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0133 - val_accuracy: 0.9638 - val_loss: 0.2088\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0037 - val_accuracy: 0.9660 - val_loss: 0.2007\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0063 - val_accuracy: 0.9676 - val_loss: 0.2017\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0049 - val_accuracy: 0.9679 - val_loss: 0.1970\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0071 - val_accuracy: 0.9676 - val_loss: 0.1973\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9682 - val_loss: 0.2017\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9679 - val_loss: 0.1824\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0087 - val_accuracy: 0.9651 - val_loss: 0.2188\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9691 - val_loss: 0.1908\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.9660 - val_loss: 0.2196\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.9635 - val_loss: 0.2502\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.9638 - val_loss: 0.2309\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.9654 - val_loss: 0.2401\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.9679 - val_loss: 0.2037\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0035 - val_accuracy: 0.9657 - val_loss: 0.2382\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9651 - val_loss: 0.2026\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0156 - val_accuracy: 0.9654 - val_loss: 0.1939\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9688 - val_loss: 0.1857\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9647 - val_loss: 0.2101\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0033 - val_accuracy: 0.9638 - val_loss: 0.2105\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9610 - val_loss: 0.2565\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0039 - val_accuracy: 0.9704 - val_loss: 0.2013\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0030 - val_accuracy: 0.9638 - val_loss: 0.2209\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0169 - val_accuracy: 0.9651 - val_loss: 0.2030\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.9635 - val_loss: 0.2331\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9651 - val_loss: 0.2444\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.9669 - val_loss: 0.2244\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0043 - val_accuracy: 0.9644 - val_loss: 0.2445\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0038 - val_accuracy: 0.9663 - val_loss: 0.2304\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 0.9660 - val_loss: 0.2350\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0034 - val_accuracy: 0.9635 - val_loss: 0.2371\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9632 - val_loss: 0.2505\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.9632 - val_loss: 0.2110\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9663 - val_loss: 0.2031\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9672 - val_loss: 0.2104\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0087 - val_accuracy: 0.9657 - val_loss: 0.2180\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9676 - val_loss: 0.1827\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.9638 - val_loss: 0.2329\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9666 - val_loss: 0.2143\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0081 - val_accuracy: 0.9644 - val_loss: 0.2216\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9672 - val_loss: 0.2021\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0029 - val_accuracy: 0.9669 - val_loss: 0.2111\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0047 - val_accuracy: 0.9657 - val_loss: 0.2274\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0049 - val_accuracy: 0.9669 - val_loss: 0.2177\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0039 - val_accuracy: 0.9638 - val_loss: 0.2549\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 0.9638 - val_loss: 0.2459\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 0.9641 - val_loss: 0.2408\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9666 - val_loss: 0.2092\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9666 - val_loss: 0.2323\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0067 - val_accuracy: 0.9669 - val_loss: 0.2082\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0030 - val_accuracy: 0.9688 - val_loss: 0.2028\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9676 - val_loss: 0.2211\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9666 - val_loss: 0.2348\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9666 - val_loss: 0.2409\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0054 - val_accuracy: 0.9632 - val_loss: 0.2344\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9660 - val_loss: 0.2494\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0104 - val_accuracy: 0.9666 - val_loss: 0.2261\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9669 - val_loss: 0.2089\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.9691 - val_loss: 0.1894\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0036 - val_accuracy: 0.9660 - val_loss: 0.2032\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9638 - val_loss: 0.2385\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.9666 - val_loss: 0.2250\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.9676 - val_loss: 0.1983\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.9616 - val_loss: 0.2432\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0116 - val_accuracy: 0.9651 - val_loss: 0.2186\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0031 - val_accuracy: 0.9676 - val_loss: 0.2074\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.9676 - val_loss: 0.2189\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0022 - val_accuracy: 0.9688 - val_loss: 0.2040\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9669 - val_loss: 0.2261\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9672 - val_loss: 0.2145\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0145 - val_accuracy: 0.9676 - val_loss: 0.1964\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0055 - val_accuracy: 0.9641 - val_loss: 0.2220\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9635 - val_loss: 0.2298\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0027 - val_accuracy: 0.9657 - val_loss: 0.2237\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9644 - val_loss: 0.2125\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0061 - val_accuracy: 0.9654 - val_loss: 0.2077\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9651 - val_loss: 0.2338\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9651 - val_loss: 0.2305\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9632 - val_loss: 0.2517\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0041 - val_accuracy: 0.9672 - val_loss: 0.2284\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.9657 - val_loss: 0.2451\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9663 - val_loss: 0.2325\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0091 - val_accuracy: 0.9666 - val_loss: 0.2252\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0057 - val_accuracy: 0.9660 - val_loss: 0.2162\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0057 - val_accuracy: 0.9682 - val_loss: 0.2139\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0023 - val_accuracy: 0.9666 - val_loss: 0.2354\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9666 - val_loss: 0.2334\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9629 - val_loss: 0.2352\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0178 - val_accuracy: 0.9666 - val_loss: 0.2042\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9660 - val_loss: 0.2143\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9635 - val_loss: 0.2370\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9654 - val_loss: 0.2288\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9666 - val_loss: 0.2221\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9672 - val_loss: 0.2290\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0093 - val_accuracy: 0.9657 - val_loss: 0.1888\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9657 - val_loss: 0.2095\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9641 - val_loss: 0.2277\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9654 - val_loss: 0.2262\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9685 - val_loss: 0.1986\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9660 - val_loss: 0.2285\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.9700 - val_loss: 0.2067\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9644 - val_loss: 0.2435\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9666 - val_loss: 0.2109\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0085 - val_accuracy: 0.9657 - val_loss: 0.2089\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9663 - val_loss: 0.2159\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9651 - val_loss: 0.2251\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0030 - val_accuracy: 0.9666 - val_loss: 0.2308\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0090 - val_accuracy: 0.9676 - val_loss: 0.2127\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.9669 - val_loss: 0.2210\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9654 - val_loss: 0.2474\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9598 - val_loss: 0.2594\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.9651 - val_loss: 0.2492\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0134 - val_accuracy: 0.9629 - val_loss: 0.2449\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9654 - val_loss: 0.2270\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9626 - val_loss: 0.2388\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0060 - val_accuracy: 0.9601 - val_loss: 0.2547\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.9644 - val_loss: 0.2378\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9641 - val_loss: 0.2373\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9682 - val_loss: 0.2249\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.9651 - val_loss: 0.2526\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9657 - val_loss: 0.2501\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0080 - val_accuracy: 0.9638 - val_loss: 0.2248\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9629 - val_loss: 0.2301\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0024 - val_accuracy: 0.9641 - val_loss: 0.2446\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9647 - val_loss: 0.2397\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9654 - val_loss: 0.2248\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9669 - val_loss: 0.2312\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0087 - val_accuracy: 0.9604 - val_loss: 0.2508\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0092 - val_accuracy: 0.9647 - val_loss: 0.2261\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9669 - val_loss: 0.2228\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9647 - val_loss: 0.2453\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9654 - val_loss: 0.2149\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9657 - val_loss: 0.2305\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9660 - val_loss: 0.2365\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0036 - val_accuracy: 0.9635 - val_loss: 0.2313\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0114 - val_accuracy: 0.9635 - val_loss: 0.2236\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9635 - val_loss: 0.2361\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.9638 - val_loss: 0.2291\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.9682 - val_loss: 0.2082\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0061 - val_accuracy: 0.9672 - val_loss: 0.2290\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0051 - val_accuracy: 0.9654 - val_loss: 0.2291\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9657 - val_loss: 0.2319\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9672 - val_loss: 0.2359\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0019 - val_accuracy: 0.9644 - val_loss: 0.2588\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9657 - val_loss: 0.2396\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9672 - val_loss: 0.2354\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9676 - val_loss: 0.2380\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9641 - val_loss: 0.2370\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9669 - val_loss: 0.2271\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.9669 - val_loss: 0.2418\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.9651 - val_loss: 0.2363\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.9685 - val_loss: 0.2052\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9641 - val_loss: 0.2491\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9660 - val_loss: 0.2293\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.9654 - val_loss: 0.2264\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9676 - val_loss: 0.2056\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0032 - val_accuracy: 0.9666 - val_loss: 0.2342\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9669 - val_loss: 0.2207\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9663 - val_loss: 0.2288\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9651 - val_loss: 0.2390\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0018 - val_accuracy: 0.9669 - val_loss: 0.2503\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9644 - val_loss: 0.2698\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 0.9697 - val_loss: 0.1975\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.9666 - val_loss: 0.2294\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9654 - val_loss: 0.2467\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9622 - val_loss: 0.2692\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.9641 - val_loss: 0.2392\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0030 - val_accuracy: 0.9616 - val_loss: 0.2579\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0085 - val_accuracy: 0.9657 - val_loss: 0.2229\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9672 - val_loss: 0.2154\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 0.9679 - val_loss: 0.2159\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.9669 - val_loss: 0.2156\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0035 - val_accuracy: 0.9682 - val_loss: 0.2258\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0039 - val_accuracy: 0.9669 - val_loss: 0.2253\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 0.9666 - val_loss: 0.2361\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0030 - val_accuracy: 0.9679 - val_loss: 0.2226\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9685 - val_loss: 0.2229\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0020 - val_accuracy: 0.9676 - val_loss: 0.2308\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.9688 - val_loss: 0.2322\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9638 - val_loss: 0.2583\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.9629 - val_loss: 0.2495\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9663 - val_loss: 0.2311\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0096 - val_accuracy: 0.9669 - val_loss: 0.2193\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9632 - val_loss: 0.2457\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9657 - val_loss: 0.2287\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9676 - val_loss: 0.2282\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9672 - val_loss: 0.2344\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9666 - val_loss: 0.2239\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0256 - val_accuracy: 0.9651 - val_loss: 0.2162\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0077 - val_accuracy: 0.9635 - val_loss: 0.2384\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0031 - val_accuracy: 0.9666 - val_loss: 0.2202\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9669 - val_loss: 0.2266\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9676 - val_loss: 0.2173\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9676 - val_loss: 0.2345\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 8.5905e-04 - val_accuracy: 0.9691 - val_loss: 0.2304\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9657 - val_loss: 0.2297\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9666 - val_loss: 0.2191\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9669 - val_loss: 0.2302\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9657 - val_loss: 0.2330\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9676 - val_loss: 0.2307\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 9.7049e-04 - val_accuracy: 0.9657 - val_loss: 0.2501\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9669 - val_loss: 0.2081\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9657 - val_loss: 0.2287\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9663 - val_loss: 0.2316\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9669 - val_loss: 0.2412\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9682 - val_loss: 0.2338\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0054 - val_accuracy: 0.9676 - val_loss: 0.2297\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 0.9638 - val_loss: 0.2418\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0153 - val_accuracy: 0.9679 - val_loss: 0.2184\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9654 - val_loss: 0.2265\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9666 - val_loss: 0.2279\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9647 - val_loss: 0.2195\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.9651 - val_loss: 0.2224\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.9638 - val_loss: 0.2258\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.9626 - val_loss: 0.2378\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9641 - val_loss: 0.2406\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9635 - val_loss: 0.2493\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.9629 - val_loss: 0.2490\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 0.9622 - val_loss: 0.2693\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.9635 - val_loss: 0.2384\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0102 - val_accuracy: 0.9669 - val_loss: 0.2052\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9663 - val_loss: 0.2279\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9619 - val_loss: 0.2509\n\n\n\n\nINFO: Training model for L_KNEE_injury_risk...\nINFO: Loaded 9 features for L_KNEE_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 9), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.9083 - loss: 0.2648 - val_accuracy: 0.9626 - val_loss: 0.0888\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9559 - loss: 0.1276 - val_accuracy: 0.9616 - val_loss: 0.1023\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9508 - loss: 0.1271 - val_accuracy: 0.9594 - val_loss: 0.1032\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9533 - loss: 0.1249 - val_accuracy: 0.9626 - val_loss: 0.0909\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9556 - loss: 0.1149 - val_accuracy: 0.9641 - val_loss: 0.0881\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9512 - loss: 0.1156 - val_accuracy: 0.9632 - val_loss: 0.0880\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9547 - loss: 0.1133 - val_accuracy: 0.9635 - val_loss: 0.0877\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9500 - loss: 0.1187 - val_accuracy: 0.9635 - val_loss: 0.0919\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9531 - loss: 0.1118 - val_accuracy: 0.9647 - val_loss: 0.0842\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9519 - loss: 0.1119 - val_accuracy: 0.9591 - val_loss: 0.1007\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9536 - loss: 0.1106 - val_accuracy: 0.9622 - val_loss: 0.0858\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9567 - loss: 0.0990 - val_accuracy: 0.9619 - val_loss: 0.0928\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9550 - loss: 0.0997 - val_accuracy: 0.9632 - val_loss: 0.0879\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9598 - loss: 0.0958 - val_accuracy: 0.9610 - val_loss: 0.1015\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9601 - loss: 0.0918 - val_accuracy: 0.9551 - val_loss: 0.1028\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9604 - loss: 0.0913 - val_accuracy: 0.9651 - val_loss: 0.0886\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9622 - loss: 0.0834 - val_accuracy: 0.9591 - val_loss: 0.1013\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9630 - loss: 0.0822 - val_accuracy: 0.9579 - val_loss: 0.0986\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9642 - loss: 0.0824 - val_accuracy: 0.9541 - val_loss: 0.1177\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9657 - loss: 0.0797 - val_accuracy: 0.9569 - val_loss: 0.1012\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9672 - loss: 0.0738 - val_accuracy: 0.9541 - val_loss: 0.1167\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9659 - loss: 0.0771 - val_accuracy: 0.9535 - val_loss: 0.1028\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9719 - loss: 0.0683 - val_accuracy: 0.9573 - val_loss: 0.1102\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9685 - loss: 0.0710 - val_accuracy: 0.9423 - val_loss: 0.1576\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9723 - loss: 0.0641 - val_accuracy: 0.9513 - val_loss: 0.1315\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9737 - loss: 0.0642 - val_accuracy: 0.9516 - val_loss: 0.1317\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9726 - loss: 0.0610 - val_accuracy: 0.9491 - val_loss: 0.1336\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9755 - loss: 0.0577 - val_accuracy: 0.9566 - val_loss: 0.1235\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9774 - loss: 0.0554 - val_accuracy: 0.9582 - val_loss: 0.1168\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9760 - loss: 0.0555 - val_accuracy: 0.9551 - val_loss: 0.1260\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9771 - loss: 0.0525 - val_accuracy: 0.9491 - val_loss: 0.1487\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9778 - loss: 0.0537 - val_accuracy: 0.9573 - val_loss: 0.1230\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9776 - loss: 0.0495 - val_accuracy: 0.9529 - val_loss: 0.1208\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9785 - loss: 0.0480 - val_accuracy: 0.9532 - val_loss: 0.1511\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9802 - loss: 0.0463 - val_accuracy: 0.9395 - val_loss: 0.1661\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9807 - loss: 0.0445 - val_accuracy: 0.9426 - val_loss: 0.1713\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9784 - loss: 0.0471 - val_accuracy: 0.9360 - val_loss: 0.2098\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9812 - loss: 0.0417 - val_accuracy: 0.9385 - val_loss: 0.1956\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9821 - loss: 0.0442 - val_accuracy: 0.9304 - val_loss: 0.2193\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9828 - loss: 0.0388 - val_accuracy: 0.9335 - val_loss: 0.2219\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9811 - loss: 0.0392 - val_accuracy: 0.9382 - val_loss: 0.2113\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9808 - loss: 0.0418 - val_accuracy: 0.9357 - val_loss: 0.2173\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9786 - loss: 0.0448 - val_accuracy: 0.9342 - val_loss: 0.1920\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9793 - loss: 0.0479 - val_accuracy: 0.9342 - val_loss: 0.2017\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9828 - loss: 0.0364 - val_accuracy: 0.9342 - val_loss: 0.2111\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9851 - loss: 0.0357 - val_accuracy: 0.9357 - val_loss: 0.1947\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9874 - loss: 0.0334 - val_accuracy: 0.9429 - val_loss: 0.1866\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9864 - loss: 0.0352 - val_accuracy: 0.9279 - val_loss: 0.2582\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9832 - loss: 0.0430 - val_accuracy: 0.9454 - val_loss: 0.1725\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0359 - val_accuracy: 0.9491 - val_loss: 0.1735\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0313 - val_accuracy: 0.9373 - val_loss: 0.2074\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0318 - val_accuracy: 0.9429 - val_loss: 0.1883\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0297 - val_accuracy: 0.9445 - val_loss: 0.1896\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0299 - val_accuracy: 0.9488 - val_loss: 0.1780\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0299 - val_accuracy: 0.9404 - val_loss: 0.2214\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9870 - loss: 0.0306 - val_accuracy: 0.9451 - val_loss: 0.2143\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9880 - loss: 0.0286 - val_accuracy: 0.9360 - val_loss: 0.2465\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0272 - val_accuracy: 0.9298 - val_loss: 0.2985\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0299 - val_accuracy: 0.9307 - val_loss: 0.2900\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0251 - val_accuracy: 0.9329 - val_loss: 0.2752\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0260 - val_accuracy: 0.9323 - val_loss: 0.2781\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0220 - val_accuracy: 0.9441 - val_loss: 0.2377\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9863 - loss: 0.0284 - val_accuracy: 0.9289 - val_loss: 0.2853\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0319 - val_accuracy: 0.9320 - val_loss: 0.2508\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9899 - loss: 0.0251 - val_accuracy: 0.9404 - val_loss: 0.2125\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0216 - val_accuracy: 0.9314 - val_loss: 0.2649\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0298 - val_accuracy: 0.9420 - val_loss: 0.2318\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0254 - val_accuracy: 0.9445 - val_loss: 0.2135\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9876 - loss: 0.0295 - val_accuracy: 0.9413 - val_loss: 0.2442\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0248 - val_accuracy: 0.9413 - val_loss: 0.2421\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0250 - val_accuracy: 0.9426 - val_loss: 0.2358\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0207 - val_accuracy: 0.9445 - val_loss: 0.2273\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9902 - loss: 0.0226 - val_accuracy: 0.9413 - val_loss: 0.2205\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0233 - val_accuracy: 0.9392 - val_loss: 0.2332\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0260 - val_accuracy: 0.9304 - val_loss: 0.2820\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0231 - val_accuracy: 0.9407 - val_loss: 0.2361\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0225 - val_accuracy: 0.9317 - val_loss: 0.2908\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0237 - val_accuracy: 0.9367 - val_loss: 0.2773\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9887 - loss: 0.0264 - val_accuracy: 0.9310 - val_loss: 0.2875\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0174 - val_accuracy: 0.9282 - val_loss: 0.3232\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0239 - val_accuracy: 0.9232 - val_loss: 0.2917\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0215 - val_accuracy: 0.9445 - val_loss: 0.2408\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0240 - val_accuracy: 0.9345 - val_loss: 0.2502\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0208 - val_accuracy: 0.9435 - val_loss: 0.2381\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0189 - val_accuracy: 0.9373 - val_loss: 0.2564\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0214 - val_accuracy: 0.9298 - val_loss: 0.2988\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0244 - val_accuracy: 0.9223 - val_loss: 0.3522\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0207 - val_accuracy: 0.9417 - val_loss: 0.2318\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0214 - val_accuracy: 0.9398 - val_loss: 0.2543\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0197 - val_accuracy: 0.9301 - val_loss: 0.2893\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0169 - val_accuracy: 0.9367 - val_loss: 0.2879\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0196 - val_accuracy: 0.9270 - val_loss: 0.2775\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9882 - loss: 0.0318 - val_accuracy: 0.9273 - val_loss: 0.2971\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0179 - val_accuracy: 0.9323 - val_loss: 0.2650\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0176 - val_accuracy: 0.9332 - val_loss: 0.2813\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0180 - val_accuracy: 0.9339 - val_loss: 0.3147\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0214 - val_accuracy: 0.9407 - val_loss: 0.2478\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0153 - val_accuracy: 0.9385 - val_loss: 0.2634\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0186 - val_accuracy: 0.9351 - val_loss: 0.2794\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0182 - val_accuracy: 0.9360 - val_loss: 0.2907\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0176 - val_accuracy: 0.9339 - val_loss: 0.3094\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0196 - val_accuracy: 0.9289 - val_loss: 0.3179\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0149 - val_accuracy: 0.9198 - val_loss: 0.3387\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0191 - val_accuracy: 0.9264 - val_loss: 0.3566\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0189 - val_accuracy: 0.9295 - val_loss: 0.3264\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0150 - val_accuracy: 0.9267 - val_loss: 0.3586\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0180 - val_accuracy: 0.9254 - val_loss: 0.3488\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0146 - val_accuracy: 0.9201 - val_loss: 0.3531\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0157 - val_accuracy: 0.9335 - val_loss: 0.3440\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0153 - val_accuracy: 0.9360 - val_loss: 0.3200\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0219 - val_accuracy: 0.9367 - val_loss: 0.2864\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0127 - val_accuracy: 0.9335 - val_loss: 0.3011\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0147 - val_accuracy: 0.9298 - val_loss: 0.3373\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0163 - val_accuracy: 0.9298 - val_loss: 0.3097\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0134 - val_accuracy: 0.9332 - val_loss: 0.2998\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0152 - val_accuracy: 0.9267 - val_loss: 0.3326\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0122 - val_accuracy: 0.9282 - val_loss: 0.3265\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0148 - val_accuracy: 0.9261 - val_loss: 0.3541\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0175 - val_accuracy: 0.9273 - val_loss: 0.3462\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0154 - val_accuracy: 0.9279 - val_loss: 0.3186\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0182 - val_accuracy: 0.9226 - val_loss: 0.3849\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0188 - val_accuracy: 0.9236 - val_loss: 0.3597\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0123 - val_accuracy: 0.9257 - val_loss: 0.3624\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0142 - val_accuracy: 0.9267 - val_loss: 0.3695\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0151 - val_accuracy: 0.9267 - val_loss: 0.3500\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0123 - val_accuracy: 0.9207 - val_loss: 0.3973\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0138 - val_accuracy: 0.9304 - val_loss: 0.3271\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0193 - val_accuracy: 0.9360 - val_loss: 0.3445\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0125 - val_accuracy: 0.9351 - val_loss: 0.3640\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0116 - val_accuracy: 0.9223 - val_loss: 0.4079\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0130 - val_accuracy: 0.9226 - val_loss: 0.4025\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0177 - val_accuracy: 0.9329 - val_loss: 0.3724\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0189 - val_accuracy: 0.9273 - val_loss: 0.3811\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0107 - val_accuracy: 0.9304 - val_loss: 0.3768\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0124 - val_accuracy: 0.9254 - val_loss: 0.3889\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0132 - val_accuracy: 0.9267 - val_loss: 0.3719\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0118 - val_accuracy: 0.9183 - val_loss: 0.3842\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0119 - val_accuracy: 0.9285 - val_loss: 0.3721\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0106 - val_accuracy: 0.9317 - val_loss: 0.3789\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0140 - val_accuracy: 0.9254 - val_loss: 0.3836\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0128 - val_accuracy: 0.9348 - val_loss: 0.3505\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0103 - val_accuracy: 0.9335 - val_loss: 0.3386\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0107 - val_accuracy: 0.9339 - val_loss: 0.3572\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0136 - val_accuracy: 0.9276 - val_loss: 0.3870\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0103 - val_accuracy: 0.9232 - val_loss: 0.4073\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0134 - val_accuracy: 0.9289 - val_loss: 0.3968\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0127 - val_accuracy: 0.9273 - val_loss: 0.4041\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0130 - val_accuracy: 0.9276 - val_loss: 0.3732\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0125 - val_accuracy: 0.9264 - val_loss: 0.4402\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0130 - val_accuracy: 0.9261 - val_loss: 0.3429\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0094 - val_accuracy: 0.9307 - val_loss: 0.3727\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0120 - val_accuracy: 0.9323 - val_loss: 0.3680\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0114 - val_accuracy: 0.9292 - val_loss: 0.3891\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0100 - val_accuracy: 0.9270 - val_loss: 0.3924\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0119 - val_accuracy: 0.9248 - val_loss: 0.3927\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0137 - val_accuracy: 0.9232 - val_loss: 0.3917\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0110 - val_accuracy: 0.9370 - val_loss: 0.3265\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0188 - val_accuracy: 0.9326 - val_loss: 0.3479\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0084 - val_accuracy: 0.9317 - val_loss: 0.3809\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0122 - val_accuracy: 0.9317 - val_loss: 0.3669\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0103 - val_accuracy: 0.9261 - val_loss: 0.4048\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0076 - val_accuracy: 0.9229 - val_loss: 0.4080\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0110 - val_accuracy: 0.9304 - val_loss: 0.3631\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0101 - val_accuracy: 0.9367 - val_loss: 0.3638\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0164 - val_accuracy: 0.9329 - val_loss: 0.3673\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0122 - val_accuracy: 0.9320 - val_loss: 0.3327\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0065 - val_accuracy: 0.9351 - val_loss: 0.3573\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0157 - val_accuracy: 0.9339 - val_loss: 0.3660\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0117 - val_accuracy: 0.9295 - val_loss: 0.3676\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0109 - val_accuracy: 0.9329 - val_loss: 0.3880\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0118 - val_accuracy: 0.9326 - val_loss: 0.3553\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0113 - val_accuracy: 0.9460 - val_loss: 0.3085\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0155 - val_accuracy: 0.9392 - val_loss: 0.3270\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0107 - val_accuracy: 0.9339 - val_loss: 0.3458\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0095 - val_accuracy: 0.9317 - val_loss: 0.3665\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0094 - val_accuracy: 0.9320 - val_loss: 0.3953\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0107 - val_accuracy: 0.9351 - val_loss: 0.3738\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0084 - val_accuracy: 0.9329 - val_loss: 0.3865\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0108 - val_accuracy: 0.9332 - val_loss: 0.3487\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0125 - val_accuracy: 0.9307 - val_loss: 0.3670\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0099 - val_accuracy: 0.9348 - val_loss: 0.3693\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0079 - val_accuracy: 0.9279 - val_loss: 0.3776\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0103 - val_accuracy: 0.9276 - val_loss: 0.4255\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0101 - val_accuracy: 0.9289 - val_loss: 0.3682\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0164 - val_accuracy: 0.9310 - val_loss: 0.3762\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0098 - val_accuracy: 0.9254 - val_loss: 0.3921\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0072 - val_accuracy: 0.9223 - val_loss: 0.4263\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0095 - val_accuracy: 0.9289 - val_loss: 0.3850\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0090 - val_accuracy: 0.9282 - val_loss: 0.3986\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0119 - val_accuracy: 0.9239 - val_loss: 0.4352\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9323 - val_loss: 0.3966\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.9201 - val_loss: 0.4379\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0122 - val_accuracy: 0.9304 - val_loss: 0.4037\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0103 - val_accuracy: 0.9332 - val_loss: 0.3747\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0218 - val_accuracy: 0.9307 - val_loss: 0.3947\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.9226 - val_loss: 0.4692\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0085 - val_accuracy: 0.9251 - val_loss: 0.4428\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0096 - val_accuracy: 0.9314 - val_loss: 0.3897\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0076 - val_accuracy: 0.9279 - val_loss: 0.3925\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0121 - val_accuracy: 0.9248 - val_loss: 0.4473\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0062 - val_accuracy: 0.9261 - val_loss: 0.4606\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0126 - val_accuracy: 0.9229 - val_loss: 0.4378\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.9245 - val_loss: 0.4688\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.9335 - val_loss: 0.3772\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0093 - val_accuracy: 0.9285 - val_loss: 0.4003\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 0.9304 - val_loss: 0.4114\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9320 - val_loss: 0.4259\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0097 - val_accuracy: 0.9304 - val_loss: 0.3930\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0071 - val_accuracy: 0.9285 - val_loss: 0.4286\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0051 - val_accuracy: 0.9370 - val_loss: 0.3810\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0177 - val_accuracy: 0.9342 - val_loss: 0.3793\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9282 - val_loss: 0.4097\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0082 - val_accuracy: 0.9310 - val_loss: 0.3979\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0084 - val_accuracy: 0.9339 - val_loss: 0.3897\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9282 - val_loss: 0.4568\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0057 - val_accuracy: 0.9251 - val_loss: 0.4626\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0094 - val_accuracy: 0.9204 - val_loss: 0.4881\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0103 - val_accuracy: 0.9285 - val_loss: 0.4381\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 0.9285 - val_loss: 0.4337\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0164 - val_accuracy: 0.9254 - val_loss: 0.4442\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.9279 - val_loss: 0.4503\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0064 - val_accuracy: 0.9242 - val_loss: 0.4539\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0116 - val_accuracy: 0.9236 - val_loss: 0.4477\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0071 - val_accuracy: 0.9410 - val_loss: 0.3604\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0105 - val_accuracy: 0.9342 - val_loss: 0.3803\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9285 - val_loss: 0.4211\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0077 - val_accuracy: 0.9295 - val_loss: 0.4051\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0087 - val_accuracy: 0.9264 - val_loss: 0.4424\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9270 - val_loss: 0.4141\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0119 - val_accuracy: 0.9298 - val_loss: 0.4152\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0075 - val_accuracy: 0.9232 - val_loss: 0.4396\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0076 - val_accuracy: 0.9279 - val_loss: 0.4186\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0094 - val_accuracy: 0.9254 - val_loss: 0.4139\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0073 - val_accuracy: 0.9310 - val_loss: 0.4061\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0092 - val_accuracy: 0.9329 - val_loss: 0.3859\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.9292 - val_loss: 0.4130\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0106 - val_accuracy: 0.9295 - val_loss: 0.4223\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0052 - val_accuracy: 0.9307 - val_loss: 0.4205\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 0.9254 - val_loss: 0.4486\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0071 - val_accuracy: 0.9254 - val_loss: 0.4289\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.9267 - val_loss: 0.4287\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0122 - val_accuracy: 0.9261 - val_loss: 0.4469\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0051 - val_accuracy: 0.9229 - val_loss: 0.4755\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0088 - val_accuracy: 0.9351 - val_loss: 0.3913\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0196 - val_accuracy: 0.9385 - val_loss: 0.3618\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.9279 - val_loss: 0.4105\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0071 - val_accuracy: 0.9317 - val_loss: 0.4108\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0085 - val_accuracy: 0.9342 - val_loss: 0.4026\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0078 - val_accuracy: 0.9326 - val_loss: 0.3944\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9257 - val_loss: 0.4286\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0111 - val_accuracy: 0.9257 - val_loss: 0.4539\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 0.9329 - val_loss: 0.4022\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0080 - val_accuracy: 0.9298 - val_loss: 0.4248\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0056 - val_accuracy: 0.9282 - val_loss: 0.4535\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9264 - val_loss: 0.4354\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0065 - val_accuracy: 0.9229 - val_loss: 0.4862\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9304 - val_loss: 0.4455\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9289 - val_loss: 0.4521\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 0.9239 - val_loss: 0.4766\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0085 - val_accuracy: 0.9267 - val_loss: 0.4370\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9335 - val_loss: 0.3987\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.9388 - val_loss: 0.3798\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9329 - val_loss: 0.4263\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9354 - val_loss: 0.4026\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9342 - val_loss: 0.4208\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0129 - val_accuracy: 0.9348 - val_loss: 0.4096\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9298 - val_loss: 0.4031\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.9251 - val_loss: 0.4404\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0076 - val_accuracy: 0.9223 - val_loss: 0.4557\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 0.9251 - val_loss: 0.4508\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0066 - val_accuracy: 0.9220 - val_loss: 0.4758\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0063 - val_accuracy: 0.9254 - val_loss: 0.4651\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0076 - val_accuracy: 0.9264 - val_loss: 0.4194\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0050 - val_accuracy: 0.9326 - val_loss: 0.4171\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0041 - val_accuracy: 0.9401 - val_loss: 0.3980\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0044 - val_accuracy: 0.9367 - val_loss: 0.4365\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0103 - val_accuracy: 0.9273 - val_loss: 0.4088\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 0.9351 - val_loss: 0.4017\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.9339 - val_loss: 0.4316\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0054 - val_accuracy: 0.9392 - val_loss: 0.4111\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.9289 - val_loss: 0.4227\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.9335 - val_loss: 0.4121\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0089 - val_accuracy: 0.9323 - val_loss: 0.4255\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.9279 - val_loss: 0.4659\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 0.9301 - val_loss: 0.4714\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9301 - val_loss: 0.4758\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0073 - val_accuracy: 0.9298 - val_loss: 0.4423\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0095 - val_accuracy: 0.9270 - val_loss: 0.4422\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9242 - val_loss: 0.4476\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9292 - val_loss: 0.4315\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9314 - val_loss: 0.4506\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.9332 - val_loss: 0.4099\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9251 - val_loss: 0.4786\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9273 - val_loss: 0.4714\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.9204 - val_loss: 0.4941\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0068 - val_accuracy: 0.9264 - val_loss: 0.4766\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.9251 - val_loss: 0.4658\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 0.9301 - val_loss: 0.4660\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9273 - val_loss: 0.5057\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0102 - val_accuracy: 0.9282 - val_loss: 0.4720\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9261 - val_loss: 0.4437\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0061 - val_accuracy: 0.9276 - val_loss: 0.4304\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0063 - val_accuracy: 0.9148 - val_loss: 0.5153\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0072 - val_accuracy: 0.9232 - val_loss: 0.4942\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9214 - val_loss: 0.5040\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.9254 - val_loss: 0.4668\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9245 - val_loss: 0.4762\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9239 - val_loss: 0.5191\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0080 - val_accuracy: 0.9261 - val_loss: 0.5000\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0126 - val_accuracy: 0.9304 - val_loss: 0.4231\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9254 - val_loss: 0.4854\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9304 - val_loss: 0.4613\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 0.9245 - val_loss: 0.4701\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0067 - val_accuracy: 0.9289 - val_loss: 0.4602\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.9214 - val_loss: 0.4936\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9226 - val_loss: 0.4850\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.9220 - val_loss: 0.5014\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0082 - val_accuracy: 0.9242 - val_loss: 0.4683\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9239 - val_loss: 0.4642\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0139 - val_accuracy: 0.9204 - val_loss: 0.4872\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0091 - val_accuracy: 0.9226 - val_loss: 0.4864\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.9254 - val_loss: 0.4993\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9276 - val_loss: 0.4804\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 0.9295 - val_loss: 0.4414\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.9270 - val_loss: 0.4499\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0098 - val_accuracy: 0.9310 - val_loss: 0.4427\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9314 - val_loss: 0.4462\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9279 - val_loss: 0.4540\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0046 - val_accuracy: 0.9310 - val_loss: 0.4413\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 0.9304 - val_loss: 0.4431\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9251 - val_loss: 0.4784\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.9254 - val_loss: 0.4860\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0054 - val_accuracy: 0.9279 - val_loss: 0.4829\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0063 - val_accuracy: 0.9229 - val_loss: 0.4878\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0100 - val_accuracy: 0.9189 - val_loss: 0.5102\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0050 - val_accuracy: 0.9217 - val_loss: 0.5303\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.9214 - val_loss: 0.5390\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9236 - val_loss: 0.5011\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0057 - val_accuracy: 0.9298 - val_loss: 0.4565\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.9236 - val_loss: 0.5016\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0067 - val_accuracy: 0.9270 - val_loss: 0.4604\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9211 - val_loss: 0.4837\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.9211 - val_loss: 0.5352\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 0.9198 - val_loss: 0.5229\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.9273 - val_loss: 0.4817\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0041 - val_accuracy: 0.9214 - val_loss: 0.5213\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9245 - val_loss: 0.4775\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9257 - val_loss: 0.4984\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0096 - val_accuracy: 0.9429 - val_loss: 0.3733\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0077 - val_accuracy: 0.9398 - val_loss: 0.4076\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0057 - val_accuracy: 0.9257 - val_loss: 0.4515\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9320 - val_loss: 0.4515\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 0.9335 - val_loss: 0.4161\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9314 - val_loss: 0.4656\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.9279 - val_loss: 0.5025\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.9257 - val_loss: 0.4528\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0088 - val_accuracy: 0.9251 - val_loss: 0.4861\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 0.9261 - val_loss: 0.4774\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9323 - val_loss: 0.4654\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9264 - val_loss: 0.5118\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0058 - val_accuracy: 0.9289 - val_loss: 0.4722\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0038 - val_accuracy: 0.9267 - val_loss: 0.5219\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0116 - val_accuracy: 0.9398 - val_loss: 0.3711\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.9401 - val_loss: 0.3785\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9379 - val_loss: 0.4231\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9354 - val_loss: 0.4287\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9339 - val_loss: 0.4499\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9382 - val_loss: 0.4380\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9289 - val_loss: 0.4459\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9251 - val_loss: 0.4820\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0073 - val_accuracy: 0.9261 - val_loss: 0.4768\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0078 - val_accuracy: 0.9176 - val_loss: 0.4978\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9217 - val_loss: 0.5071\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9279 - val_loss: 0.4970\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0036 - val_accuracy: 0.9254 - val_loss: 0.4994\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0035 - val_accuracy: 0.9301 - val_loss: 0.4646\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.9239 - val_loss: 0.4776\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0086 - val_accuracy: 0.9276 - val_loss: 0.4872\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9257 - val_loss: 0.4872\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9236 - val_loss: 0.4948\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0056 - val_accuracy: 0.9211 - val_loss: 0.5288\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9248 - val_loss: 0.5361\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9236 - val_loss: 0.5539\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0062 - val_accuracy: 0.9220 - val_loss: 0.5372\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0085 - val_accuracy: 0.9176 - val_loss: 0.5490\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0083 - val_accuracy: 0.9273 - val_loss: 0.4532\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9332 - val_loss: 0.4562\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0028 - val_accuracy: 0.9254 - val_loss: 0.4740\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0078 - val_accuracy: 0.9226 - val_loss: 0.5004\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0073 - val_accuracy: 0.9270 - val_loss: 0.4313\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9248 - val_loss: 0.4923\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0030 - val_accuracy: 0.9279 - val_loss: 0.4830\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9285 - val_loss: 0.5157\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0072 - val_accuracy: 0.9239 - val_loss: 0.4941\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9254 - val_loss: 0.5181\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9279 - val_loss: 0.4583\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0040 - val_accuracy: 0.9276 - val_loss: 0.4401\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.9267 - val_loss: 0.4665\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9236 - val_loss: 0.4920\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9295 - val_loss: 0.4934\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0070 - val_accuracy: 0.9248 - val_loss: 0.4673\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0038 - val_accuracy: 0.9192 - val_loss: 0.5084\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9245 - val_loss: 0.4510\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0057 - val_accuracy: 0.9214 - val_loss: 0.4921\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9229 - val_loss: 0.4918\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9211 - val_loss: 0.5408\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9198 - val_loss: 0.5419\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9207 - val_loss: 0.5368\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9242 - val_loss: 0.5320\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9220 - val_loss: 0.5176\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0051 - val_accuracy: 0.9248 - val_loss: 0.5130\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0153 - val_accuracy: 0.9267 - val_loss: 0.4350\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0032 - val_accuracy: 0.9267 - val_loss: 0.4474\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9236 - val_loss: 0.4553\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9214 - val_loss: 0.4920\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.9223 - val_loss: 0.4757\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0090 - val_accuracy: 0.9226 - val_loss: 0.4899\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0059 - val_accuracy: 0.9239 - val_loss: 0.4368\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.9211 - val_loss: 0.4672\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 0.9232 - val_loss: 0.4621\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9242 - val_loss: 0.4649\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9192 - val_loss: 0.4987\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9223 - val_loss: 0.4976\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0065 - val_accuracy: 0.9285 - val_loss: 0.4624\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.9232 - val_loss: 0.4460\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9242 - val_loss: 0.4594\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9223 - val_loss: 0.5188\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.9226 - val_loss: 0.4777\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.9207 - val_loss: 0.5066\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9204 - val_loss: 0.4805\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0045 - val_accuracy: 0.9179 - val_loss: 0.5105\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0023 - val_accuracy: 0.9217 - val_loss: 0.4819\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9164 - val_loss: 0.5397\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9189 - val_loss: 0.5240\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0086 - val_accuracy: 0.9223 - val_loss: 0.4935\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9211 - val_loss: 0.5179\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9220 - val_loss: 0.5232\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9245 - val_loss: 0.4946\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9183 - val_loss: 0.5236\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9179 - val_loss: 0.5175\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0055 - val_accuracy: 0.9179 - val_loss: 0.5216\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9170 - val_loss: 0.4953\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9186 - val_loss: 0.5254\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0179 - val_accuracy: 0.9207 - val_loss: 0.4667\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.9214 - val_loss: 0.4787\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9186 - val_loss: 0.5032\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9211 - val_loss: 0.5273\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0030 - val_accuracy: 0.9186 - val_loss: 0.5281\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0071 - val_accuracy: 0.9270 - val_loss: 0.4539\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0037 - val_accuracy: 0.9220 - val_loss: 0.4571\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9245 - val_loss: 0.4447\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.9242 - val_loss: 0.4843\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 0.9229 - val_loss: 0.5048\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9214 - val_loss: 0.5126\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9226 - val_loss: 0.5221\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0046 - val_accuracy: 0.9223 - val_loss: 0.5255\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9161 - val_loss: 0.5161\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.9186 - val_loss: 0.5149\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9226 - val_loss: 0.5024\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9204 - val_loss: 0.4967\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0036 - val_accuracy: 0.9282 - val_loss: 0.4547\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0070 - val_accuracy: 0.9186 - val_loss: 0.4709\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9192 - val_loss: 0.5101\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 0.9214 - val_loss: 0.4983\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 0.9207 - val_loss: 0.4883\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9261 - val_loss: 0.4537\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9217 - val_loss: 0.4665\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9223 - val_loss: 0.4611\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 9.0067e-04 - val_accuracy: 0.9204 - val_loss: 0.5145\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 9.3497e-04 - val_accuracy: 0.9220 - val_loss: 0.5013\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.9392 - val_loss: 0.4135\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0059 - val_accuracy: 0.9354 - val_loss: 0.4384\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.9292 - val_loss: 0.4562\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0031 - val_accuracy: 0.9332 - val_loss: 0.4611\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9279 - val_loss: 0.4485\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9295 - val_loss: 0.4578\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0082 - val_accuracy: 0.9179 - val_loss: 0.4895\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9232 - val_loss: 0.4894\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9301 - val_loss: 0.4398\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9307 - val_loss: 0.4680\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0057 - val_accuracy: 0.9329 - val_loss: 0.4742\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9270 - val_loss: 0.4757\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0019 - val_accuracy: 0.9282 - val_loss: 0.4769\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9251 - val_loss: 0.4953\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9279 - val_loss: 0.4702\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0059 - val_accuracy: 0.9261 - val_loss: 0.4802\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.9226 - val_loss: 0.4934\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9220 - val_loss: 0.4959\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9236 - val_loss: 0.4871\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.9245 - val_loss: 0.4904\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9307 - val_loss: 0.4496\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0102 - val_accuracy: 0.9295 - val_loss: 0.4173\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 0.9345 - val_loss: 0.3984\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9323 - val_loss: 0.4342\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9257 - val_loss: 0.4807\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9317 - val_loss: 0.4385\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9332 - val_loss: 0.4573\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9310 - val_loss: 0.4543\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.9248 - val_loss: 0.5148\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0085 - val_accuracy: 0.9410 - val_loss: 0.4414\n\n\n\n\nINFO: Training model for R_KNEE_injury_risk...\nINFO: Loaded 9 features for R_KNEE_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 9), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.8944 - loss: 0.2835 - val_accuracy: 0.9498 - val_loss: 0.1188\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9472 - loss: 0.1260 - val_accuracy: 0.9538 - val_loss: 0.1060\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9487 - loss: 0.1179 - val_accuracy: 0.9544 - val_loss: 0.1013\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9530 - loss: 0.1117 - val_accuracy: 0.9526 - val_loss: 0.1014\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9560 - loss: 0.1067 - val_accuracy: 0.9582 - val_loss: 0.0963\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9599 - loss: 0.0967 - val_accuracy: 0.9569 - val_loss: 0.0985\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9595 - loss: 0.0949 - val_accuracy: 0.9513 - val_loss: 0.1108\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9614 - loss: 0.0920 - val_accuracy: 0.9520 - val_loss: 0.1177\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9612 - loss: 0.0922 - val_accuracy: 0.9538 - val_loss: 0.1009\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9614 - loss: 0.0886 - val_accuracy: 0.9513 - val_loss: 0.1062\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9577 - loss: 0.0924 - val_accuracy: 0.9541 - val_loss: 0.1066\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9610 - loss: 0.0905 - val_accuracy: 0.9541 - val_loss: 0.1050\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9598 - loss: 0.0911 - val_accuracy: 0.9529 - val_loss: 0.1126\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9607 - loss: 0.0849 - val_accuracy: 0.9516 - val_loss: 0.1225\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9652 - loss: 0.0789 - val_accuracy: 0.9569 - val_loss: 0.1000\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9634 - loss: 0.0813 - val_accuracy: 0.9523 - val_loss: 0.1073\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9664 - loss: 0.0750 - val_accuracy: 0.9548 - val_loss: 0.1102\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9655 - loss: 0.0771 - val_accuracy: 0.9551 - val_loss: 0.1079\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9672 - loss: 0.0762 - val_accuracy: 0.9566 - val_loss: 0.1059\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9664 - loss: 0.0757 - val_accuracy: 0.9532 - val_loss: 0.1135\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9684 - loss: 0.0732 - val_accuracy: 0.9482 - val_loss: 0.1143\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9716 - loss: 0.0708 - val_accuracy: 0.9544 - val_loss: 0.1062\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9713 - loss: 0.0718 - val_accuracy: 0.9516 - val_loss: 0.1094\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9715 - loss: 0.0641 - val_accuracy: 0.9516 - val_loss: 0.1136\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9742 - loss: 0.0613 - val_accuracy: 0.9466 - val_loss: 0.1208\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9743 - loss: 0.0601 - val_accuracy: 0.9460 - val_loss: 0.1185\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9732 - loss: 0.0626 - val_accuracy: 0.9504 - val_loss: 0.1167\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9752 - loss: 0.0590 - val_accuracy: 0.9451 - val_loss: 0.1237\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9672 - loss: 0.0732 - val_accuracy: 0.9438 - val_loss: 0.1250\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9728 - loss: 0.0614 - val_accuracy: 0.9488 - val_loss: 0.1243\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9748 - loss: 0.0582 - val_accuracy: 0.9460 - val_loss: 0.1254\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9739 - loss: 0.0578 - val_accuracy: 0.9420 - val_loss: 0.1317\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9761 - loss: 0.0563 - val_accuracy: 0.9423 - val_loss: 0.1299\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9733 - loss: 0.0597 - val_accuracy: 0.9379 - val_loss: 0.1469\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9747 - loss: 0.0555 - val_accuracy: 0.9432 - val_loss: 0.1386\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9759 - loss: 0.0539 - val_accuracy: 0.9407 - val_loss: 0.1479\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9784 - loss: 0.0497 - val_accuracy: 0.9417 - val_loss: 0.1540\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9773 - loss: 0.0502 - val_accuracy: 0.9438 - val_loss: 0.1615\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9788 - loss: 0.0480 - val_accuracy: 0.9410 - val_loss: 0.1606\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9774 - loss: 0.0503 - val_accuracy: 0.9357 - val_loss: 0.1836\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9798 - loss: 0.0513 - val_accuracy: 0.9379 - val_loss: 0.1766\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9819 - loss: 0.0470 - val_accuracy: 0.9392 - val_loss: 0.1880\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9770 - loss: 0.0493 - val_accuracy: 0.9310 - val_loss: 0.2326\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9801 - loss: 0.0494 - val_accuracy: 0.9410 - val_loss: 0.1771\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9792 - loss: 0.0461 - val_accuracy: 0.9363 - val_loss: 0.2250\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9800 - loss: 0.0458 - val_accuracy: 0.9417 - val_loss: 0.1911\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9823 - loss: 0.0420 - val_accuracy: 0.9395 - val_loss: 0.1955\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9789 - loss: 0.0466 - val_accuracy: 0.9404 - val_loss: 0.1919\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9809 - loss: 0.0421 - val_accuracy: 0.9463 - val_loss: 0.1829\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9791 - loss: 0.0434 - val_accuracy: 0.9429 - val_loss: 0.1981\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9804 - loss: 0.0482 - val_accuracy: 0.9392 - val_loss: 0.1913\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9840 - loss: 0.0406 - val_accuracy: 0.9413 - val_loss: 0.1864\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9788 - loss: 0.0463 - val_accuracy: 0.9385 - val_loss: 0.2142\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9834 - loss: 0.0383 - val_accuracy: 0.9398 - val_loss: 0.2108\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9844 - loss: 0.0371 - val_accuracy: 0.9438 - val_loss: 0.1861\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9848 - loss: 0.0336 - val_accuracy: 0.9438 - val_loss: 0.2032\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9849 - loss: 0.0363 - val_accuracy: 0.9470 - val_loss: 0.1968\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9791 - loss: 0.0450 - val_accuracy: 0.9432 - val_loss: 0.1968\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9870 - loss: 0.0307 - val_accuracy: 0.9332 - val_loss: 0.2552\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9834 - loss: 0.0374 - val_accuracy: 0.9445 - val_loss: 0.2302\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9848 - loss: 0.0370 - val_accuracy: 0.9404 - val_loss: 0.2306\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0337 - val_accuracy: 0.9354 - val_loss: 0.2437\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9821 - loss: 0.0387 - val_accuracy: 0.9398 - val_loss: 0.2351\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0306 - val_accuracy: 0.9398 - val_loss: 0.2314\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9881 - loss: 0.0329 - val_accuracy: 0.9410 - val_loss: 0.2271\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9872 - loss: 0.0319 - val_accuracy: 0.9363 - val_loss: 0.2481\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9856 - loss: 0.0366 - val_accuracy: 0.9457 - val_loss: 0.2262\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0326 - val_accuracy: 0.9373 - val_loss: 0.2502\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9861 - loss: 0.0304 - val_accuracy: 0.9435 - val_loss: 0.2299\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9876 - loss: 0.0293 - val_accuracy: 0.9426 - val_loss: 0.2420\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0296 - val_accuracy: 0.9448 - val_loss: 0.2307\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0323 - val_accuracy: 0.9426 - val_loss: 0.2524\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9880 - loss: 0.0293 - val_accuracy: 0.9388 - val_loss: 0.2809\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9895 - loss: 0.0268 - val_accuracy: 0.9470 - val_loss: 0.2249\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9881 - loss: 0.0293 - val_accuracy: 0.9438 - val_loss: 0.2242\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9878 - loss: 0.0322 - val_accuracy: 0.9401 - val_loss: 0.2628\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0302 - val_accuracy: 0.9398 - val_loss: 0.2695\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0261 - val_accuracy: 0.9367 - val_loss: 0.2964\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0281 - val_accuracy: 0.9382 - val_loss: 0.2748\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9858 - loss: 0.0297 - val_accuracy: 0.9392 - val_loss: 0.2685\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0285 - val_accuracy: 0.9451 - val_loss: 0.2443\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0263 - val_accuracy: 0.9432 - val_loss: 0.2605\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0253 - val_accuracy: 0.9395 - val_loss: 0.2615\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0281 - val_accuracy: 0.9429 - val_loss: 0.2782\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9897 - loss: 0.0239 - val_accuracy: 0.9448 - val_loss: 0.2627\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0242 - val_accuracy: 0.9432 - val_loss: 0.2758\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0267 - val_accuracy: 0.9401 - val_loss: 0.2862\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0267 - val_accuracy: 0.9395 - val_loss: 0.3155\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9906 - loss: 0.0252 - val_accuracy: 0.9460 - val_loss: 0.2391\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9897 - loss: 0.0260 - val_accuracy: 0.9448 - val_loss: 0.2436\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9892 - loss: 0.0251 - val_accuracy: 0.9420 - val_loss: 0.2754\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0250 - val_accuracy: 0.9460 - val_loss: 0.2579\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0192 - val_accuracy: 0.9417 - val_loss: 0.2941\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0194 - val_accuracy: 0.9438 - val_loss: 0.2830\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9880 - loss: 0.0307 - val_accuracy: 0.9435 - val_loss: 0.2530\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0184 - val_accuracy: 0.9454 - val_loss: 0.2575\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0222 - val_accuracy: 0.9463 - val_loss: 0.2672\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0225 - val_accuracy: 0.9413 - val_loss: 0.3008\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9900 - loss: 0.0265 - val_accuracy: 0.9435 - val_loss: 0.2948\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0263 - val_accuracy: 0.9451 - val_loss: 0.2846\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9914 - loss: 0.0200 - val_accuracy: 0.9451 - val_loss: 0.2907\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9900 - loss: 0.0242 - val_accuracy: 0.9401 - val_loss: 0.2970\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0222 - val_accuracy: 0.9448 - val_loss: 0.2859\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9915 - loss: 0.0201 - val_accuracy: 0.9373 - val_loss: 0.2838\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0281 - val_accuracy: 0.9488 - val_loss: 0.2689\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0215 - val_accuracy: 0.9435 - val_loss: 0.2803\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0197 - val_accuracy: 0.9460 - val_loss: 0.2680\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9920 - loss: 0.0194 - val_accuracy: 0.9426 - val_loss: 0.3108\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0261 - val_accuracy: 0.9479 - val_loss: 0.2534\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0209 - val_accuracy: 0.9473 - val_loss: 0.2541\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0268 - val_accuracy: 0.9451 - val_loss: 0.2939\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0176 - val_accuracy: 0.9438 - val_loss: 0.2758\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0188 - val_accuracy: 0.9404 - val_loss: 0.3206\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0207 - val_accuracy: 0.9438 - val_loss: 0.2938\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0216 - val_accuracy: 0.9460 - val_loss: 0.2634\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0175 - val_accuracy: 0.9395 - val_loss: 0.3311\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9920 - loss: 0.0221 - val_accuracy: 0.9457 - val_loss: 0.2689\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9917 - loss: 0.0180 - val_accuracy: 0.9491 - val_loss: 0.2600\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0183 - val_accuracy: 0.9420 - val_loss: 0.2868\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0150 - val_accuracy: 0.9466 - val_loss: 0.2607\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0201 - val_accuracy: 0.9451 - val_loss: 0.2770\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0228 - val_accuracy: 0.9445 - val_loss: 0.2790\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9915 - loss: 0.0192 - val_accuracy: 0.9460 - val_loss: 0.2962\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0191 - val_accuracy: 0.9454 - val_loss: 0.2919\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0176 - val_accuracy: 0.9423 - val_loss: 0.2923\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0181 - val_accuracy: 0.9388 - val_loss: 0.3242\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0250 - val_accuracy: 0.9438 - val_loss: 0.2754\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0159 - val_accuracy: 0.9413 - val_loss: 0.3251\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0200 - val_accuracy: 0.9448 - val_loss: 0.2953\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0135 - val_accuracy: 0.9438 - val_loss: 0.2967\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0157 - val_accuracy: 0.9482 - val_loss: 0.2471\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0154 - val_accuracy: 0.9413 - val_loss: 0.3143\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0270 - val_accuracy: 0.9388 - val_loss: 0.3339\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0161 - val_accuracy: 0.9441 - val_loss: 0.2779\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0179 - val_accuracy: 0.9426 - val_loss: 0.3108\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0158 - val_accuracy: 0.9441 - val_loss: 0.3115\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0214 - val_accuracy: 0.9441 - val_loss: 0.2794\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0151 - val_accuracy: 0.9423 - val_loss: 0.2824\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0176 - val_accuracy: 0.9457 - val_loss: 0.2814\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0200 - val_accuracy: 0.9404 - val_loss: 0.3101\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0147 - val_accuracy: 0.9438 - val_loss: 0.2965\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0133 - val_accuracy: 0.9417 - val_loss: 0.3037\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0175 - val_accuracy: 0.9445 - val_loss: 0.3165\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0144 - val_accuracy: 0.9420 - val_loss: 0.3190\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0143 - val_accuracy: 0.9382 - val_loss: 0.3441\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0165 - val_accuracy: 0.9470 - val_loss: 0.2933\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0165 - val_accuracy: 0.9476 - val_loss: 0.2905\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0184 - val_accuracy: 0.9420 - val_loss: 0.3325\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0158 - val_accuracy: 0.9466 - val_loss: 0.3012\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0143 - val_accuracy: 0.9420 - val_loss: 0.3250\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0203 - val_accuracy: 0.9445 - val_loss: 0.2995\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0138 - val_accuracy: 0.9457 - val_loss: 0.2927\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0127 - val_accuracy: 0.9382 - val_loss: 0.3578\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0176 - val_accuracy: 0.9463 - val_loss: 0.2918\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0131 - val_accuracy: 0.9479 - val_loss: 0.2860\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0144 - val_accuracy: 0.9441 - val_loss: 0.3239\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0173 - val_accuracy: 0.9451 - val_loss: 0.3046\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0167 - val_accuracy: 0.9404 - val_loss: 0.3402\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0148 - val_accuracy: 0.9470 - val_loss: 0.2885\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0095 - val_accuracy: 0.9410 - val_loss: 0.3247\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0203 - val_accuracy: 0.9370 - val_loss: 0.3624\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0156 - val_accuracy: 0.9488 - val_loss: 0.2678\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0124 - val_accuracy: 0.9432 - val_loss: 0.3240\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0133 - val_accuracy: 0.9426 - val_loss: 0.3423\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0175 - val_accuracy: 0.9448 - val_loss: 0.3183\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0105 - val_accuracy: 0.9392 - val_loss: 0.3653\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0148 - val_accuracy: 0.9441 - val_loss: 0.3189\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0156 - val_accuracy: 0.9438 - val_loss: 0.3280\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0147 - val_accuracy: 0.9457 - val_loss: 0.3190\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0105 - val_accuracy: 0.9445 - val_loss: 0.3135\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0188 - val_accuracy: 0.9460 - val_loss: 0.3032\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0106 - val_accuracy: 0.9410 - val_loss: 0.3465\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0183 - val_accuracy: 0.9417 - val_loss: 0.3467\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0165 - val_accuracy: 0.9398 - val_loss: 0.3266\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0156 - val_accuracy: 0.9466 - val_loss: 0.2884\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0113 - val_accuracy: 0.9426 - val_loss: 0.3271\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0109 - val_accuracy: 0.9426 - val_loss: 0.3374\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0099 - val_accuracy: 0.9407 - val_loss: 0.3758\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0161 - val_accuracy: 0.9498 - val_loss: 0.2885\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0118 - val_accuracy: 0.9417 - val_loss: 0.3399\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0115 - val_accuracy: 0.9407 - val_loss: 0.3568\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0135 - val_accuracy: 0.9354 - val_loss: 0.3835\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0166 - val_accuracy: 0.9413 - val_loss: 0.3594\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0114 - val_accuracy: 0.9401 - val_loss: 0.3736\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0150 - val_accuracy: 0.9423 - val_loss: 0.3486\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0103 - val_accuracy: 0.9423 - val_loss: 0.3589\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0158 - val_accuracy: 0.9432 - val_loss: 0.3603\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0106 - val_accuracy: 0.9423 - val_loss: 0.3423\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0120 - val_accuracy: 0.9404 - val_loss: 0.3760\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0134 - val_accuracy: 0.9413 - val_loss: 0.3248\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0094 - val_accuracy: 0.9410 - val_loss: 0.3751\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0130 - val_accuracy: 0.9404 - val_loss: 0.3597\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0147 - val_accuracy: 0.9435 - val_loss: 0.3710\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0127 - val_accuracy: 0.9438 - val_loss: 0.3263\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0146 - val_accuracy: 0.9423 - val_loss: 0.3593\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0110 - val_accuracy: 0.9438 - val_loss: 0.3654\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0132 - val_accuracy: 0.9423 - val_loss: 0.3495\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0100 - val_accuracy: 0.9441 - val_loss: 0.3183\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0119 - val_accuracy: 0.9398 - val_loss: 0.3614\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0136 - val_accuracy: 0.9451 - val_loss: 0.3327\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0116 - val_accuracy: 0.9451 - val_loss: 0.3225\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0122 - val_accuracy: 0.9438 - val_loss: 0.3439\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0129 - val_accuracy: 0.9441 - val_loss: 0.3561\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0116 - val_accuracy: 0.9435 - val_loss: 0.3406\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0110 - val_accuracy: 0.9420 - val_loss: 0.3433\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0152 - val_accuracy: 0.9457 - val_loss: 0.3495\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0132 - val_accuracy: 0.9410 - val_loss: 0.3541\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0104 - val_accuracy: 0.9451 - val_loss: 0.3331\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0089 - val_accuracy: 0.9429 - val_loss: 0.3454\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0121 - val_accuracy: 0.9435 - val_loss: 0.3431\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0105 - val_accuracy: 0.9404 - val_loss: 0.3630\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0104 - val_accuracy: 0.9404 - val_loss: 0.3565\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0098 - val_accuracy: 0.9423 - val_loss: 0.3815\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0146 - val_accuracy: 0.9438 - val_loss: 0.3584\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0122 - val_accuracy: 0.9435 - val_loss: 0.3285\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0122 - val_accuracy: 0.9423 - val_loss: 0.3464\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0108 - val_accuracy: 0.9476 - val_loss: 0.3115\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0116 - val_accuracy: 0.9420 - val_loss: 0.3480\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0092 - val_accuracy: 0.9432 - val_loss: 0.3543\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0099 - val_accuracy: 0.9457 - val_loss: 0.3226\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0099 - val_accuracy: 0.9432 - val_loss: 0.3474\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0106 - val_accuracy: 0.9373 - val_loss: 0.4068\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0127 - val_accuracy: 0.9441 - val_loss: 0.3432\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 0.9417 - val_loss: 0.3700\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0131 - val_accuracy: 0.9454 - val_loss: 0.3366\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0133 - val_accuracy: 0.9404 - val_loss: 0.3859\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0118 - val_accuracy: 0.9441 - val_loss: 0.3527\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0106 - val_accuracy: 0.9429 - val_loss: 0.3523\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0119 - val_accuracy: 0.9410 - val_loss: 0.3664\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0080 - val_accuracy: 0.9429 - val_loss: 0.3585\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0069 - val_accuracy: 0.9438 - val_loss: 0.3637\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0123 - val_accuracy: 0.9401 - val_loss: 0.3980\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0102 - val_accuracy: 0.9454 - val_loss: 0.3200\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0084 - val_accuracy: 0.9420 - val_loss: 0.3781\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0096 - val_accuracy: 0.9388 - val_loss: 0.3675\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.9501 - val_loss: 0.3137\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0143 - val_accuracy: 0.9457 - val_loss: 0.3342\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0182 - val_accuracy: 0.9448 - val_loss: 0.3348\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0136 - val_accuracy: 0.9457 - val_loss: 0.3275\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0125 - val_accuracy: 0.9463 - val_loss: 0.3382\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0094 - val_accuracy: 0.9463 - val_loss: 0.3404\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0083 - val_accuracy: 0.9460 - val_loss: 0.3569\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0096 - val_accuracy: 0.9470 - val_loss: 0.3369\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0091 - val_accuracy: 0.9441 - val_loss: 0.3507\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0072 - val_accuracy: 0.9441 - val_loss: 0.3716\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0151 - val_accuracy: 0.9457 - val_loss: 0.3296\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0094 - val_accuracy: 0.9432 - val_loss: 0.3768\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0087 - val_accuracy: 0.9432 - val_loss: 0.3361\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0092 - val_accuracy: 0.9426 - val_loss: 0.3572\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0096 - val_accuracy: 0.9413 - val_loss: 0.3530\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0076 - val_accuracy: 0.9423 - val_loss: 0.3479\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0167 - val_accuracy: 0.9463 - val_loss: 0.3223\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0176 - val_accuracy: 0.9382 - val_loss: 0.3576\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0100 - val_accuracy: 0.9420 - val_loss: 0.3650\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0094 - val_accuracy: 0.9413 - val_loss: 0.3527\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0084 - val_accuracy: 0.9429 - val_loss: 0.3793\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0108 - val_accuracy: 0.9423 - val_loss: 0.3391\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0123 - val_accuracy: 0.9432 - val_loss: 0.3312\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0091 - val_accuracy: 0.9407 - val_loss: 0.3613\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0114 - val_accuracy: 0.9417 - val_loss: 0.3707\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0100 - val_accuracy: 0.9454 - val_loss: 0.3364\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.9451 - val_loss: 0.3518\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0078 - val_accuracy: 0.9441 - val_loss: 0.3261\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0130 - val_accuracy: 0.9410 - val_loss: 0.3621\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.9429 - val_loss: 0.3609\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0072 - val_accuracy: 0.9410 - val_loss: 0.3752\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0095 - val_accuracy: 0.9413 - val_loss: 0.3790\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0115 - val_accuracy: 0.9407 - val_loss: 0.3818\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0065 - val_accuracy: 0.9395 - val_loss: 0.3783\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 0.9417 - val_loss: 0.3571\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0058 - val_accuracy: 0.9420 - val_loss: 0.3850\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0107 - val_accuracy: 0.9438 - val_loss: 0.3824\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0082 - val_accuracy: 0.9407 - val_loss: 0.3879\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9457 - val_loss: 0.3608\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0073 - val_accuracy: 0.9429 - val_loss: 0.3572\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.9429 - val_loss: 0.3809\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0064 - val_accuracy: 0.9445 - val_loss: 0.3946\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0119 - val_accuracy: 0.9457 - val_loss: 0.4044\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0078 - val_accuracy: 0.9457 - val_loss: 0.3526\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0103 - val_accuracy: 0.9438 - val_loss: 0.3802\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 0.9457 - val_loss: 0.3681\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0088 - val_accuracy: 0.9445 - val_loss: 0.3848\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0083 - val_accuracy: 0.9485 - val_loss: 0.3471\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0085 - val_accuracy: 0.9460 - val_loss: 0.3848\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0088 - val_accuracy: 0.9457 - val_loss: 0.3417\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0092 - val_accuracy: 0.9445 - val_loss: 0.3780\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9470 - val_loss: 0.3669\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0090 - val_accuracy: 0.9441 - val_loss: 0.3757\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0062 - val_accuracy: 0.9454 - val_loss: 0.3782\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.9445 - val_loss: 0.3795\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0136 - val_accuracy: 0.9485 - val_loss: 0.3717\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9451 - val_loss: 0.3905\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0090 - val_accuracy: 0.9457 - val_loss: 0.3934\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0088 - val_accuracy: 0.9423 - val_loss: 0.4112\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0071 - val_accuracy: 0.9413 - val_loss: 0.4117\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.9473 - val_loss: 0.3538\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0082 - val_accuracy: 0.9457 - val_loss: 0.3818\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0086 - val_accuracy: 0.9473 - val_loss: 0.3628\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0074 - val_accuracy: 0.9454 - val_loss: 0.3606\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0080 - val_accuracy: 0.9451 - val_loss: 0.3879\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0094 - val_accuracy: 0.9398 - val_loss: 0.4081\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0079 - val_accuracy: 0.9463 - val_loss: 0.3779\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0106 - val_accuracy: 0.9410 - val_loss: 0.3923\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0075 - val_accuracy: 0.9429 - val_loss: 0.3757\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9429 - val_loss: 0.3852\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0110 - val_accuracy: 0.9451 - val_loss: 0.4050\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0073 - val_accuracy: 0.9460 - val_loss: 0.3611\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0109 - val_accuracy: 0.9407 - val_loss: 0.4106\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9476 - val_loss: 0.3633\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0083 - val_accuracy: 0.9423 - val_loss: 0.3784\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 0.9451 - val_loss: 0.3734\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0195 - val_accuracy: 0.9429 - val_loss: 0.3942\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0073 - val_accuracy: 0.9460 - val_loss: 0.3437\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0084 - val_accuracy: 0.9457 - val_loss: 0.3716\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0073 - val_accuracy: 0.9410 - val_loss: 0.4064\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0073 - val_accuracy: 0.9457 - val_loss: 0.3872\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0067 - val_accuracy: 0.9441 - val_loss: 0.4024\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.9441 - val_loss: 0.3844\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9438 - val_loss: 0.4062\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0091 - val_accuracy: 0.9445 - val_loss: 0.3885\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0096 - val_accuracy: 0.9495 - val_loss: 0.3375\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0075 - val_accuracy: 0.9448 - val_loss: 0.3611\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0097 - val_accuracy: 0.9491 - val_loss: 0.3398\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0060 - val_accuracy: 0.9485 - val_loss: 0.3462\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.9423 - val_loss: 0.4065\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0055 - val_accuracy: 0.9473 - val_loss: 0.3651\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0046 - val_accuracy: 0.9470 - val_loss: 0.3896\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0075 - val_accuracy: 0.9463 - val_loss: 0.3759\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0202 - val_accuracy: 0.9463 - val_loss: 0.3829\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0086 - val_accuracy: 0.9426 - val_loss: 0.3986\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9460 - val_loss: 0.3626\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0079 - val_accuracy: 0.9441 - val_loss: 0.3782\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0082 - val_accuracy: 0.9448 - val_loss: 0.3719\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0120 - val_accuracy: 0.9441 - val_loss: 0.3597\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.9454 - val_loss: 0.3705\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9435 - val_loss: 0.3943\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 0.9491 - val_loss: 0.3352\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0141 - val_accuracy: 0.9463 - val_loss: 0.3638\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9429 - val_loss: 0.3847\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9445 - val_loss: 0.3849\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0075 - val_accuracy: 0.9429 - val_loss: 0.4144\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0069 - val_accuracy: 0.9423 - val_loss: 0.4100\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0074 - val_accuracy: 0.9457 - val_loss: 0.4120\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0114 - val_accuracy: 0.9473 - val_loss: 0.3872\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0062 - val_accuracy: 0.9445 - val_loss: 0.3986\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0091 - val_accuracy: 0.9479 - val_loss: 0.3753\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0056 - val_accuracy: 0.9448 - val_loss: 0.4359\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0093 - val_accuracy: 0.9466 - val_loss: 0.3661\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0085 - val_accuracy: 0.9476 - val_loss: 0.3755\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0071 - val_accuracy: 0.9470 - val_loss: 0.3827\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0076 - val_accuracy: 0.9466 - val_loss: 0.4008\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0069 - val_accuracy: 0.9498 - val_loss: 0.3570\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0104 - val_accuracy: 0.9454 - val_loss: 0.3846\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0055 - val_accuracy: 0.9420 - val_loss: 0.3952\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0071 - val_accuracy: 0.9423 - val_loss: 0.4097\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0054 - val_accuracy: 0.9435 - val_loss: 0.3974\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0064 - val_accuracy: 0.9435 - val_loss: 0.3996\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9448 - val_loss: 0.3991\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0059 - val_accuracy: 0.9482 - val_loss: 0.3711\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0089 - val_accuracy: 0.9454 - val_loss: 0.4106\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.9470 - val_loss: 0.3786\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0075 - val_accuracy: 0.9432 - val_loss: 0.3965\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0079 - val_accuracy: 0.9463 - val_loss: 0.3906\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0066 - val_accuracy: 0.9457 - val_loss: 0.3759\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.9476 - val_loss: 0.3654\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0055 - val_accuracy: 0.9473 - val_loss: 0.3871\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0107 - val_accuracy: 0.9429 - val_loss: 0.3761\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0065 - val_accuracy: 0.9435 - val_loss: 0.4045\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9451 - val_loss: 0.3801\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0052 - val_accuracy: 0.9457 - val_loss: 0.3825\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0062 - val_accuracy: 0.9466 - val_loss: 0.4066\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0092 - val_accuracy: 0.9420 - val_loss: 0.4185\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.9417 - val_loss: 0.4040\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0068 - val_accuracy: 0.9451 - val_loss: 0.4040\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0055 - val_accuracy: 0.9410 - val_loss: 0.4303\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9423 - val_loss: 0.4098\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0096 - val_accuracy: 0.9404 - val_loss: 0.4067\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0061 - val_accuracy: 0.9451 - val_loss: 0.3934\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0051 - val_accuracy: 0.9435 - val_loss: 0.3924\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0057 - val_accuracy: 0.9454 - val_loss: 0.3992\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0075 - val_accuracy: 0.9488 - val_loss: 0.3693\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 0.9454 - val_loss: 0.3811\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.9423 - val_loss: 0.3979\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9432 - val_loss: 0.4057\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 0.9435 - val_loss: 0.4358\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9479 - val_loss: 0.3678\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0084 - val_accuracy: 0.9423 - val_loss: 0.4028\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0101 - val_accuracy: 0.9510 - val_loss: 0.3552\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0050 - val_accuracy: 0.9476 - val_loss: 0.3722\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0073 - val_accuracy: 0.9473 - val_loss: 0.3700\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0069 - val_accuracy: 0.9448 - val_loss: 0.3894\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0036 - val_accuracy: 0.9441 - val_loss: 0.4069\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.9463 - val_loss: 0.3660\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0083 - val_accuracy: 0.9470 - val_loss: 0.3782\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0071 - val_accuracy: 0.9463 - val_loss: 0.3722\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0076 - val_accuracy: 0.9460 - val_loss: 0.4056\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0109 - val_accuracy: 0.9466 - val_loss: 0.3740\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.9457 - val_loss: 0.3755\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9473 - val_loss: 0.3497\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9466 - val_loss: 0.3762\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0058 - val_accuracy: 0.9441 - val_loss: 0.4173\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0056 - val_accuracy: 0.9466 - val_loss: 0.3917\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9454 - val_loss: 0.3843\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0089 - val_accuracy: 0.9495 - val_loss: 0.3861\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9473 - val_loss: 0.4046\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0044 - val_accuracy: 0.9463 - val_loss: 0.3882\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9448 - val_loss: 0.3879\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0069 - val_accuracy: 0.9485 - val_loss: 0.3865\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.9485 - val_loss: 0.3629\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 0.9410 - val_loss: 0.4413\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.9438 - val_loss: 0.3944\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.9426 - val_loss: 0.3922\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0062 - val_accuracy: 0.9423 - val_loss: 0.4155\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0085 - val_accuracy: 0.9454 - val_loss: 0.4122\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0054 - val_accuracy: 0.9441 - val_loss: 0.3837\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0078 - val_accuracy: 0.9457 - val_loss: 0.3897\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0041 - val_accuracy: 0.9466 - val_loss: 0.4019\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9479 - val_loss: 0.3718\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0066 - val_accuracy: 0.9451 - val_loss: 0.3832\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9429 - val_loss: 0.4154\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0051 - val_accuracy: 0.9454 - val_loss: 0.3693\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0065 - val_accuracy: 0.9448 - val_loss: 0.4024\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9457 - val_loss: 0.4116\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.9463 - val_loss: 0.4097\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0064 - val_accuracy: 0.9429 - val_loss: 0.4380\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0099 - val_accuracy: 0.9457 - val_loss: 0.4163\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0059 - val_accuracy: 0.9463 - val_loss: 0.4076\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0062 - val_accuracy: 0.9457 - val_loss: 0.3906\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0113 - val_accuracy: 0.9485 - val_loss: 0.3745\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0066 - val_accuracy: 0.9460 - val_loss: 0.3863\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0041 - val_accuracy: 0.9476 - val_loss: 0.3814\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0070 - val_accuracy: 0.9479 - val_loss: 0.3849\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0064 - val_accuracy: 0.9435 - val_loss: 0.3890\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.9466 - val_loss: 0.3932\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9482 - val_loss: 0.3873\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0095 - val_accuracy: 0.9504 - val_loss: 0.3647\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9454 - val_loss: 0.4008\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0048 - val_accuracy: 0.9488 - val_loss: 0.3608\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0065 - val_accuracy: 0.9417 - val_loss: 0.4249\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0152 - val_accuracy: 0.9441 - val_loss: 0.3940\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.9460 - val_loss: 0.3835\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.9470 - val_loss: 0.4020\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.9498 - val_loss: 0.3575\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.9501 - val_loss: 0.3795\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9495 - val_loss: 0.3899\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.9445 - val_loss: 0.4342\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0085 - val_accuracy: 0.9479 - val_loss: 0.3919\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0059 - val_accuracy: 0.9426 - val_loss: 0.4128\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9429 - val_loss: 0.3923\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0040 - val_accuracy: 0.9445 - val_loss: 0.3875\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0041 - val_accuracy: 0.9423 - val_loss: 0.4335\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0093 - val_accuracy: 0.9438 - val_loss: 0.4214\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0070 - val_accuracy: 0.9479 - val_loss: 0.3963\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9451 - val_loss: 0.3837\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0065 - val_accuracy: 0.9463 - val_loss: 0.3943\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9463 - val_loss: 0.4081\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9445 - val_loss: 0.3886\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9473 - val_loss: 0.3640\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0056 - val_accuracy: 0.9463 - val_loss: 0.3788\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.9479 - val_loss: 0.3727\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0057 - val_accuracy: 0.9479 - val_loss: 0.3987\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0054 - val_accuracy: 0.9454 - val_loss: 0.4206\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0053 - val_accuracy: 0.9438 - val_loss: 0.4167\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9463 - val_loss: 0.4018\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0054 - val_accuracy: 0.9448 - val_loss: 0.4129\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0096 - val_accuracy: 0.9485 - val_loss: 0.3488\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0063 - val_accuracy: 0.9451 - val_loss: 0.3735\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 0.9470 - val_loss: 0.3879\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.9460 - val_loss: 0.4007\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0057 - val_accuracy: 0.9445 - val_loss: 0.4206\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0110 - val_accuracy: 0.9463 - val_loss: 0.3952\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9463 - val_loss: 0.4014\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.9429 - val_loss: 0.4061\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0059 - val_accuracy: 0.9423 - val_loss: 0.4102\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0044 - val_accuracy: 0.9460 - val_loss: 0.4198\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0035 - val_accuracy: 0.9470 - val_loss: 0.4093\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0076 - val_accuracy: 0.9432 - val_loss: 0.4140\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0057 - val_accuracy: 0.9451 - val_loss: 0.4311\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0051 - val_accuracy: 0.9476 - val_loss: 0.3849\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.9429 - val_loss: 0.4361\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9491 - val_loss: 0.3956\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0101 - val_accuracy: 0.9501 - val_loss: 0.3724\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.9466 - val_loss: 0.4005\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0048 - val_accuracy: 0.9441 - val_loss: 0.4097\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9488 - val_loss: 0.3845\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0095 - val_accuracy: 0.9451 - val_loss: 0.4044\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0050 - val_accuracy: 0.9441 - val_loss: 0.4041\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.9491 - val_loss: 0.3863\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9485 - val_loss: 0.3825\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0052 - val_accuracy: 0.9479 - val_loss: 0.3925\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9429 - val_loss: 0.4044\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0075 - val_accuracy: 0.9426 - val_loss: 0.4214\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0064 - val_accuracy: 0.9473 - val_loss: 0.4044\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9466 - val_loss: 0.4089\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.9479 - val_loss: 0.3985\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9454 - val_loss: 0.4293\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0068 - val_accuracy: 0.9482 - val_loss: 0.3978\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9485 - val_loss: 0.3923\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0044 - val_accuracy: 0.9466 - val_loss: 0.4112\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9473 - val_loss: 0.4147\n\n\n\n\nINFO: Training model for L_HIP_injury_risk...\nINFO: Loaded 10 features for L_HIP_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 10), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.9067 - loss: 0.2612 - val_accuracy: 0.9666 - val_loss: 0.0911\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9528 - loss: 0.1341 - val_accuracy: 0.9638 - val_loss: 0.0950\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9565 - loss: 0.1233 - val_accuracy: 0.9632 - val_loss: 0.0957\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9581 - loss: 0.1187 - val_accuracy: 0.9607 - val_loss: 0.1016\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9530 - loss: 0.1262 - val_accuracy: 0.9660 - val_loss: 0.0834\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9576 - loss: 0.1161 - val_accuracy: 0.9557 - val_loss: 0.1130\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9597 - loss: 0.1118 - val_accuracy: 0.9610 - val_loss: 0.0992\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9532 - loss: 0.1198 - val_accuracy: 0.9626 - val_loss: 0.0868\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9567 - loss: 0.1110 - val_accuracy: 0.9660 - val_loss: 0.0889\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9610 - loss: 0.1035 - val_accuracy: 0.9632 - val_loss: 0.0870\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9575 - loss: 0.1103 - val_accuracy: 0.9601 - val_loss: 0.0949\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9594 - loss: 0.1059 - val_accuracy: 0.9616 - val_loss: 0.0908\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9621 - loss: 0.1039 - val_accuracy: 0.9638 - val_loss: 0.0852\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9621 - loss: 0.1005 - val_accuracy: 0.9604 - val_loss: 0.0989\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9609 - loss: 0.1045 - val_accuracy: 0.9654 - val_loss: 0.0888\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9648 - loss: 0.0972 - val_accuracy: 0.9610 - val_loss: 0.1003\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9591 - loss: 0.0985 - val_accuracy: 0.9613 - val_loss: 0.0934\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9625 - loss: 0.0991 - val_accuracy: 0.9616 - val_loss: 0.0922\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9606 - loss: 0.1049 - val_accuracy: 0.9616 - val_loss: 0.0929\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9620 - loss: 0.1001 - val_accuracy: 0.9619 - val_loss: 0.0951\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9608 - loss: 0.0984 - val_accuracy: 0.9610 - val_loss: 0.0972\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9620 - loss: 0.0911 - val_accuracy: 0.9594 - val_loss: 0.1035\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9623 - loss: 0.0967 - val_accuracy: 0.9619 - val_loss: 0.0953\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9623 - loss: 0.0971 - val_accuracy: 0.9594 - val_loss: 0.0940\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9640 - loss: 0.0911 - val_accuracy: 0.9622 - val_loss: 0.0924\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9655 - loss: 0.0892 - val_accuracy: 0.9610 - val_loss: 0.1082\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9624 - loss: 0.0958 - val_accuracy: 0.9638 - val_loss: 0.0941\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9595 - loss: 0.0978 - val_accuracy: 0.9579 - val_loss: 0.1093\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9680 - loss: 0.0849 - val_accuracy: 0.9638 - val_loss: 0.1043\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9643 - loss: 0.0883 - val_accuracy: 0.9582 - val_loss: 0.1182\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9633 - loss: 0.0881 - val_accuracy: 0.9632 - val_loss: 0.1005\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9665 - loss: 0.0837 - val_accuracy: 0.9657 - val_loss: 0.1015\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9671 - loss: 0.0840 - val_accuracy: 0.9632 - val_loss: 0.0986\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9679 - loss: 0.0775 - val_accuracy: 0.9616 - val_loss: 0.0969\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9676 - loss: 0.0818 - val_accuracy: 0.9582 - val_loss: 0.1101\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9698 - loss: 0.0733 - val_accuracy: 0.9598 - val_loss: 0.0948\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9697 - loss: 0.0746 - val_accuracy: 0.9598 - val_loss: 0.1101\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9660 - loss: 0.0786 - val_accuracy: 0.9582 - val_loss: 0.1100\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9684 - loss: 0.0785 - val_accuracy: 0.9619 - val_loss: 0.1121\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9722 - loss: 0.0695 - val_accuracy: 0.9569 - val_loss: 0.1284\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9684 - loss: 0.0755 - val_accuracy: 0.9563 - val_loss: 0.1170\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9692 - loss: 0.0730 - val_accuracy: 0.9563 - val_loss: 0.1120\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9703 - loss: 0.0714 - val_accuracy: 0.9585 - val_loss: 0.1068\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9702 - loss: 0.0713 - val_accuracy: 0.9557 - val_loss: 0.1289\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9737 - loss: 0.0656 - val_accuracy: 0.9582 - val_loss: 0.1114\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9714 - loss: 0.0682 - val_accuracy: 0.9513 - val_loss: 0.1274\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9724 - loss: 0.0659 - val_accuracy: 0.9591 - val_loss: 0.1207\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9734 - loss: 0.0666 - val_accuracy: 0.9573 - val_loss: 0.1280\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9744 - loss: 0.0623 - val_accuracy: 0.9557 - val_loss: 0.1233\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9746 - loss: 0.0604 - val_accuracy: 0.9573 - val_loss: 0.1319\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9735 - loss: 0.0678 - val_accuracy: 0.9535 - val_loss: 0.1264\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9755 - loss: 0.0575 - val_accuracy: 0.9548 - val_loss: 0.1287\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9743 - loss: 0.0630 - val_accuracy: 0.9591 - val_loss: 0.1297\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9782 - loss: 0.0559 - val_accuracy: 0.9526 - val_loss: 0.1452\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9723 - loss: 0.0586 - val_accuracy: 0.9582 - val_loss: 0.1392\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9760 - loss: 0.0563 - val_accuracy: 0.9576 - val_loss: 0.1372\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9762 - loss: 0.0563 - val_accuracy: 0.9563 - val_loss: 0.1302\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9766 - loss: 0.0554 - val_accuracy: 0.9548 - val_loss: 0.1583\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9767 - loss: 0.0520 - val_accuracy: 0.9548 - val_loss: 0.1532\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9766 - loss: 0.0576 - val_accuracy: 0.9529 - val_loss: 0.1483\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9773 - loss: 0.0518 - val_accuracy: 0.9557 - val_loss: 0.1555\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9807 - loss: 0.0497 - val_accuracy: 0.9538 - val_loss: 0.1447\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9795 - loss: 0.0487 - val_accuracy: 0.9563 - val_loss: 0.1626\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9783 - loss: 0.0496 - val_accuracy: 0.9541 - val_loss: 0.1719\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9774 - loss: 0.0535 - val_accuracy: 0.9566 - val_loss: 0.1455\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9790 - loss: 0.0478 - val_accuracy: 0.9535 - val_loss: 0.1570\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9799 - loss: 0.0470 - val_accuracy: 0.9504 - val_loss: 0.1778\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9814 - loss: 0.0435 - val_accuracy: 0.9495 - val_loss: 0.1750\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9794 - loss: 0.0456 - val_accuracy: 0.9585 - val_loss: 0.1538\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9808 - loss: 0.0453 - val_accuracy: 0.9563 - val_loss: 0.1702\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9809 - loss: 0.0436 - val_accuracy: 0.9554 - val_loss: 0.1593\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9811 - loss: 0.0450 - val_accuracy: 0.9460 - val_loss: 0.1865\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9808 - loss: 0.0453 - val_accuracy: 0.9520 - val_loss: 0.1907\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9816 - loss: 0.0479 - val_accuracy: 0.9510 - val_loss: 0.1923\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9803 - loss: 0.0442 - val_accuracy: 0.9569 - val_loss: 0.1796\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9816 - loss: 0.0438 - val_accuracy: 0.9507 - val_loss: 0.1906\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9825 - loss: 0.0407 - val_accuracy: 0.9520 - val_loss: 0.1959\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9807 - loss: 0.0476 - val_accuracy: 0.9560 - val_loss: 0.1901\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9813 - loss: 0.0444 - val_accuracy: 0.9513 - val_loss: 0.1879\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9841 - loss: 0.0371 - val_accuracy: 0.9557 - val_loss: 0.1777\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9833 - loss: 0.0387 - val_accuracy: 0.9535 - val_loss: 0.1894\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9864 - loss: 0.0332 - val_accuracy: 0.9551 - val_loss: 0.1931\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9857 - loss: 0.0349 - val_accuracy: 0.9548 - val_loss: 0.1843\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9808 - loss: 0.0425 - val_accuracy: 0.9513 - val_loss: 0.2064\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9844 - loss: 0.0353 - val_accuracy: 0.9526 - val_loss: 0.1945\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9819 - loss: 0.0417 - val_accuracy: 0.9501 - val_loss: 0.2119\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9857 - loss: 0.0343 - val_accuracy: 0.9526 - val_loss: 0.1963\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0349 - val_accuracy: 0.9535 - val_loss: 0.2183\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9856 - loss: 0.0340 - val_accuracy: 0.9523 - val_loss: 0.1954\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9857 - loss: 0.0321 - val_accuracy: 0.9504 - val_loss: 0.2258\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0345 - val_accuracy: 0.9507 - val_loss: 0.2322\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9857 - loss: 0.0340 - val_accuracy: 0.9529 - val_loss: 0.2142\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9862 - loss: 0.0365 - val_accuracy: 0.9520 - val_loss: 0.2141\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9830 - loss: 0.0407 - val_accuracy: 0.9535 - val_loss: 0.2075\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0272 - val_accuracy: 0.9516 - val_loss: 0.2048\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9879 - loss: 0.0294 - val_accuracy: 0.9501 - val_loss: 0.2292\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9846 - loss: 0.0350 - val_accuracy: 0.9482 - val_loss: 0.2502\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9873 - loss: 0.0305 - val_accuracy: 0.9504 - val_loss: 0.2197\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9859 - loss: 0.0310 - val_accuracy: 0.9526 - val_loss: 0.2213\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0300 - val_accuracy: 0.9473 - val_loss: 0.2396\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9864 - loss: 0.0300 - val_accuracy: 0.9535 - val_loss: 0.2240\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9881 - loss: 0.0252 - val_accuracy: 0.9473 - val_loss: 0.2409\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0301 - val_accuracy: 0.9485 - val_loss: 0.2188\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0309 - val_accuracy: 0.9482 - val_loss: 0.2365\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0267 - val_accuracy: 0.9498 - val_loss: 0.2236\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9876 - loss: 0.0314 - val_accuracy: 0.9526 - val_loss: 0.2178\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9896 - loss: 0.0245 - val_accuracy: 0.9476 - val_loss: 0.2396\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0267 - val_accuracy: 0.9510 - val_loss: 0.2540\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9902 - loss: 0.0237 - val_accuracy: 0.9482 - val_loss: 0.2493\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9866 - loss: 0.0274 - val_accuracy: 0.9510 - val_loss: 0.2469\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9892 - loss: 0.0274 - val_accuracy: 0.9482 - val_loss: 0.2440\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9883 - loss: 0.0270 - val_accuracy: 0.9538 - val_loss: 0.2491\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0253 - val_accuracy: 0.9507 - val_loss: 0.2345\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9886 - loss: 0.0258 - val_accuracy: 0.9451 - val_loss: 0.2704\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9894 - loss: 0.0265 - val_accuracy: 0.9476 - val_loss: 0.2590\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9877 - loss: 0.0264 - val_accuracy: 0.9520 - val_loss: 0.2532\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9893 - loss: 0.0245 - val_accuracy: 0.9466 - val_loss: 0.2543\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0241 - val_accuracy: 0.9482 - val_loss: 0.2650\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9895 - loss: 0.0237 - val_accuracy: 0.9516 - val_loss: 0.2357\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9902 - loss: 0.0257 - val_accuracy: 0.9498 - val_loss: 0.2510\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9911 - loss: 0.0194 - val_accuracy: 0.9485 - val_loss: 0.2640\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0201 - val_accuracy: 0.9473 - val_loss: 0.2605\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0227 - val_accuracy: 0.9482 - val_loss: 0.2620\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9904 - loss: 0.0245 - val_accuracy: 0.9504 - val_loss: 0.2615\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0186 - val_accuracy: 0.9426 - val_loss: 0.2777\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9884 - loss: 0.0333 - val_accuracy: 0.9532 - val_loss: 0.2522\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0226 - val_accuracy: 0.9507 - val_loss: 0.2681\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0223 - val_accuracy: 0.9413 - val_loss: 0.2851\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0246 - val_accuracy: 0.9479 - val_loss: 0.2781\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0245 - val_accuracy: 0.9413 - val_loss: 0.2958\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9905 - loss: 0.0251 - val_accuracy: 0.9488 - val_loss: 0.2805\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0177 - val_accuracy: 0.9498 - val_loss: 0.2947\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0200 - val_accuracy: 0.9473 - val_loss: 0.2650\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9912 - loss: 0.0206 - val_accuracy: 0.9507 - val_loss: 0.2738\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0230 - val_accuracy: 0.9435 - val_loss: 0.2937\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9890 - loss: 0.0241 - val_accuracy: 0.9495 - val_loss: 0.2681\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9909 - loss: 0.0215 - val_accuracy: 0.9476 - val_loss: 0.2972\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9904 - loss: 0.0237 - val_accuracy: 0.9482 - val_loss: 0.2734\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0208 - val_accuracy: 0.9470 - val_loss: 0.2776\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0208 - val_accuracy: 0.9513 - val_loss: 0.2859\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0158 - val_accuracy: 0.9488 - val_loss: 0.2849\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0184 - val_accuracy: 0.9532 - val_loss: 0.2618\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9907 - loss: 0.0226 - val_accuracy: 0.9473 - val_loss: 0.3052\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0200 - val_accuracy: 0.9435 - val_loss: 0.2931\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0177 - val_accuracy: 0.9460 - val_loss: 0.3134\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9898 - loss: 0.0228 - val_accuracy: 0.9485 - val_loss: 0.2934\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0162 - val_accuracy: 0.9526 - val_loss: 0.2752\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0178 - val_accuracy: 0.9441 - val_loss: 0.2909\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0190 - val_accuracy: 0.9432 - val_loss: 0.3206\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0189 - val_accuracy: 0.9479 - val_loss: 0.2998\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9901 - loss: 0.0228 - val_accuracy: 0.9488 - val_loss: 0.2918\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0164 - val_accuracy: 0.9466 - val_loss: 0.3044\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0158 - val_accuracy: 0.9479 - val_loss: 0.2946\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9914 - loss: 0.0192 - val_accuracy: 0.9463 - val_loss: 0.2970\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0162 - val_accuracy: 0.9438 - val_loss: 0.3026\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0184 - val_accuracy: 0.9460 - val_loss: 0.3055\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0166 - val_accuracy: 0.9466 - val_loss: 0.2954\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0179 - val_accuracy: 0.9410 - val_loss: 0.3028\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0186 - val_accuracy: 0.9445 - val_loss: 0.2907\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0166 - val_accuracy: 0.9473 - val_loss: 0.2842\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0149 - val_accuracy: 0.9457 - val_loss: 0.3090\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0164 - val_accuracy: 0.9413 - val_loss: 0.3037\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9902 - loss: 0.0226 - val_accuracy: 0.9451 - val_loss: 0.2981\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0167 - val_accuracy: 0.9454 - val_loss: 0.3043\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0173 - val_accuracy: 0.9441 - val_loss: 0.2967\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0140 - val_accuracy: 0.9454 - val_loss: 0.3176\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9916 - loss: 0.0220 - val_accuracy: 0.9395 - val_loss: 0.3079\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9906 - loss: 0.0213 - val_accuracy: 0.9445 - val_loss: 0.2846\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9922 - loss: 0.0182 - val_accuracy: 0.9470 - val_loss: 0.3023\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0158 - val_accuracy: 0.9410 - val_loss: 0.3210\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0143 - val_accuracy: 0.9417 - val_loss: 0.3143\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0174 - val_accuracy: 0.9448 - val_loss: 0.3047\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9893 - loss: 0.0270 - val_accuracy: 0.9466 - val_loss: 0.3029\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0139 - val_accuracy: 0.9413 - val_loss: 0.3315\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0137 - val_accuracy: 0.9466 - val_loss: 0.2966\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9932 - loss: 0.0157 - val_accuracy: 0.9445 - val_loss: 0.3131\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0119 - val_accuracy: 0.9398 - val_loss: 0.3353\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9903 - loss: 0.0280 - val_accuracy: 0.9395 - val_loss: 0.3126\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9913 - loss: 0.0223 - val_accuracy: 0.9463 - val_loss: 0.3077\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0158 - val_accuracy: 0.9495 - val_loss: 0.3057\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0121 - val_accuracy: 0.9417 - val_loss: 0.3396\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0158 - val_accuracy: 0.9460 - val_loss: 0.3045\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0146 - val_accuracy: 0.9485 - val_loss: 0.3149\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0209 - val_accuracy: 0.9435 - val_loss: 0.3129\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0171 - val_accuracy: 0.9463 - val_loss: 0.3104\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0110 - val_accuracy: 0.9407 - val_loss: 0.3434\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9931 - loss: 0.0173 - val_accuracy: 0.9432 - val_loss: 0.3103\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0109 - val_accuracy: 0.9435 - val_loss: 0.3396\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9896 - loss: 0.0231 - val_accuracy: 0.9463 - val_loss: 0.3040\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0149 - val_accuracy: 0.9438 - val_loss: 0.3187\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0119 - val_accuracy: 0.9426 - val_loss: 0.3149\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0116 - val_accuracy: 0.9482 - val_loss: 0.3148\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0170 - val_accuracy: 0.9432 - val_loss: 0.3289\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0136 - val_accuracy: 0.9438 - val_loss: 0.3622\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0151 - val_accuracy: 0.9432 - val_loss: 0.3412\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0149 - val_accuracy: 0.9435 - val_loss: 0.3271\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0111 - val_accuracy: 0.9454 - val_loss: 0.3272\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0142 - val_accuracy: 0.9401 - val_loss: 0.3341\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0141 - val_accuracy: 0.9445 - val_loss: 0.3231\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0105 - val_accuracy: 0.9445 - val_loss: 0.3424\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0150 - val_accuracy: 0.9488 - val_loss: 0.3151\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0183 - val_accuracy: 0.9473 - val_loss: 0.3149\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0175 - val_accuracy: 0.9451 - val_loss: 0.3232\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0135 - val_accuracy: 0.9507 - val_loss: 0.3015\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0135 - val_accuracy: 0.9460 - val_loss: 0.3354\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0117 - val_accuracy: 0.9466 - val_loss: 0.3165\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0103 - val_accuracy: 0.9441 - val_loss: 0.3224\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0148 - val_accuracy: 0.9432 - val_loss: 0.3383\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0165 - val_accuracy: 0.9417 - val_loss: 0.3440\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0127 - val_accuracy: 0.9423 - val_loss: 0.3205\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0121 - val_accuracy: 0.9385 - val_loss: 0.3644\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0133 - val_accuracy: 0.9420 - val_loss: 0.3421\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0146 - val_accuracy: 0.9451 - val_loss: 0.3310\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0124 - val_accuracy: 0.9445 - val_loss: 0.3298\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0088 - val_accuracy: 0.9448 - val_loss: 0.3349\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0095 - val_accuracy: 0.9476 - val_loss: 0.3305\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0139 - val_accuracy: 0.9379 - val_loss: 0.3600\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9934 - loss: 0.0157 - val_accuracy: 0.9438 - val_loss: 0.3465\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0125 - val_accuracy: 0.9417 - val_loss: 0.3380\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0107 - val_accuracy: 0.9423 - val_loss: 0.3345\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0105 - val_accuracy: 0.9441 - val_loss: 0.3357\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0107 - val_accuracy: 0.9438 - val_loss: 0.3360\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0144 - val_accuracy: 0.9432 - val_loss: 0.3316\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0134 - val_accuracy: 0.9385 - val_loss: 0.3642\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0112 - val_accuracy: 0.9379 - val_loss: 0.3536\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0109 - val_accuracy: 0.9438 - val_loss: 0.3352\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0105 - val_accuracy: 0.9463 - val_loss: 0.3392\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0157 - val_accuracy: 0.9401 - val_loss: 0.3360\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0108 - val_accuracy: 0.9454 - val_loss: 0.3459\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0102 - val_accuracy: 0.9410 - val_loss: 0.3635\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0088 - val_accuracy: 0.9429 - val_loss: 0.3305\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0097 - val_accuracy: 0.9426 - val_loss: 0.3519\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0201 - val_accuracy: 0.9410 - val_loss: 0.3599\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0095 - val_accuracy: 0.9438 - val_loss: 0.3323\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0096 - val_accuracy: 0.9460 - val_loss: 0.3574\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0095 - val_accuracy: 0.9429 - val_loss: 0.3788\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0126 - val_accuracy: 0.9454 - val_loss: 0.3507\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0085 - val_accuracy: 0.9451 - val_loss: 0.3573\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0113 - val_accuracy: 0.9448 - val_loss: 0.3543\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0158 - val_accuracy: 0.9457 - val_loss: 0.3392\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0138 - val_accuracy: 0.9448 - val_loss: 0.3336\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0099 - val_accuracy: 0.9426 - val_loss: 0.3658\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0076 - val_accuracy: 0.9420 - val_loss: 0.3760\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.9429 - val_loss: 0.3702\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0123 - val_accuracy: 0.9423 - val_loss: 0.3649\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0108 - val_accuracy: 0.9473 - val_loss: 0.3534\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0112 - val_accuracy: 0.9392 - val_loss: 0.3877\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0133 - val_accuracy: 0.9448 - val_loss: 0.3441\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0084 - val_accuracy: 0.9454 - val_loss: 0.3578\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0098 - val_accuracy: 0.9426 - val_loss: 0.3712\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0129 - val_accuracy: 0.9392 - val_loss: 0.3845\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0125 - val_accuracy: 0.9426 - val_loss: 0.3601\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0124 - val_accuracy: 0.9413 - val_loss: 0.3683\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0079 - val_accuracy: 0.9429 - val_loss: 0.3666\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0078 - val_accuracy: 0.9470 - val_loss: 0.3553\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0078 - val_accuracy: 0.9463 - val_loss: 0.3610\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0125 - val_accuracy: 0.9429 - val_loss: 0.3655\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0092 - val_accuracy: 0.9435 - val_loss: 0.3580\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0075 - val_accuracy: 0.9413 - val_loss: 0.3901\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0116 - val_accuracy: 0.9438 - val_loss: 0.3613\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0091 - val_accuracy: 0.9479 - val_loss: 0.3632\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.9398 - val_loss: 0.4089\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0114 - val_accuracy: 0.9473 - val_loss: 0.3415\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0141 - val_accuracy: 0.9441 - val_loss: 0.3419\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0107 - val_accuracy: 0.9438 - val_loss: 0.3595\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0147 - val_accuracy: 0.9417 - val_loss: 0.3666\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0110 - val_accuracy: 0.9410 - val_loss: 0.3830\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0102 - val_accuracy: 0.9404 - val_loss: 0.3567\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0063 - val_accuracy: 0.9420 - val_loss: 0.3424\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 0.9413 - val_loss: 0.3870\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0067 - val_accuracy: 0.9404 - val_loss: 0.3783\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0120 - val_accuracy: 0.9401 - val_loss: 0.3845\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0193 - val_accuracy: 0.9420 - val_loss: 0.3703\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0089 - val_accuracy: 0.9423 - val_loss: 0.3625\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0083 - val_accuracy: 0.9445 - val_loss: 0.3572\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0197 - val_accuracy: 0.9451 - val_loss: 0.3399\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.9429 - val_loss: 0.3302\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0106 - val_accuracy: 0.9417 - val_loss: 0.3523\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0115 - val_accuracy: 0.9441 - val_loss: 0.3593\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0062 - val_accuracy: 0.9420 - val_loss: 0.3736\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0064 - val_accuracy: 0.9466 - val_loss: 0.3634\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0077 - val_accuracy: 0.9423 - val_loss: 0.3942\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0103 - val_accuracy: 0.9432 - val_loss: 0.3958\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0100 - val_accuracy: 0.9410 - val_loss: 0.3736\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.9435 - val_loss: 0.3724\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0080 - val_accuracy: 0.9395 - val_loss: 0.3946\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0069 - val_accuracy: 0.9407 - val_loss: 0.3882\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.9410 - val_loss: 0.3984\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0085 - val_accuracy: 0.9404 - val_loss: 0.3988\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.9426 - val_loss: 0.3878\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0142 - val_accuracy: 0.9410 - val_loss: 0.3803\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0047 - val_accuracy: 0.9451 - val_loss: 0.3773\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0113 - val_accuracy: 0.9367 - val_loss: 0.3927\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0061 - val_accuracy: 0.9407 - val_loss: 0.3786\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0074 - val_accuracy: 0.9432 - val_loss: 0.3486\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0088 - val_accuracy: 0.9438 - val_loss: 0.3584\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0098 - val_accuracy: 0.9401 - val_loss: 0.3775\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.9413 - val_loss: 0.3808\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0119 - val_accuracy: 0.9413 - val_loss: 0.3737\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.9441 - val_loss: 0.3794\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0085 - val_accuracy: 0.9479 - val_loss: 0.3533\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0192 - val_accuracy: 0.9445 - val_loss: 0.3454\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0060 - val_accuracy: 0.9432 - val_loss: 0.3523\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0078 - val_accuracy: 0.9448 - val_loss: 0.3608\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0050 - val_accuracy: 0.9438 - val_loss: 0.3659\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0061 - val_accuracy: 0.9438 - val_loss: 0.3798\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0061 - val_accuracy: 0.9460 - val_loss: 0.3875\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.9445 - val_loss: 0.3685\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0101 - val_accuracy: 0.9445 - val_loss: 0.3938\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 0.9441 - val_loss: 0.3835\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0075 - val_accuracy: 0.9463 - val_loss: 0.3522\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0112 - val_accuracy: 0.9473 - val_loss: 0.3352\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9466 - val_loss: 0.3695\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.9385 - val_loss: 0.3889\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0068 - val_accuracy: 0.9420 - val_loss: 0.3906\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0065 - val_accuracy: 0.9429 - val_loss: 0.3794\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9445 - val_loss: 0.3968\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0102 - val_accuracy: 0.9417 - val_loss: 0.3917\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.9451 - val_loss: 0.3812\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 0.9488 - val_loss: 0.3555\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0130 - val_accuracy: 0.9429 - val_loss: 0.3707\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0108 - val_accuracy: 0.9420 - val_loss: 0.3906\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0100 - val_accuracy: 0.9395 - val_loss: 0.4023\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0099 - val_accuracy: 0.9426 - val_loss: 0.3883\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0077 - val_accuracy: 0.9413 - val_loss: 0.4090\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.9466 - val_loss: 0.3465\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0083 - val_accuracy: 0.9420 - val_loss: 0.3716\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9413 - val_loss: 0.4107\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.9429 - val_loss: 0.3808\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.9460 - val_loss: 0.3800\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0129 - val_accuracy: 0.9413 - val_loss: 0.4069\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9426 - val_loss: 0.3969\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0047 - val_accuracy: 0.9441 - val_loss: 0.3887\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0055 - val_accuracy: 0.9441 - val_loss: 0.3974\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0044 - val_accuracy: 0.9504 - val_loss: 0.3680\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0107 - val_accuracy: 0.9451 - val_loss: 0.3814\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0128 - val_accuracy: 0.9413 - val_loss: 0.4039\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0043 - val_accuracy: 0.9463 - val_loss: 0.3863\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0132 - val_accuracy: 0.9417 - val_loss: 0.3778\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.9435 - val_loss: 0.3773\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0096 - val_accuracy: 0.9435 - val_loss: 0.3727\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9448 - val_loss: 0.4057\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0076 - val_accuracy: 0.9429 - val_loss: 0.3851\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.9451 - val_loss: 0.3721\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0101 - val_accuracy: 0.9435 - val_loss: 0.3664\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0060 - val_accuracy: 0.9454 - val_loss: 0.3695\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0121 - val_accuracy: 0.9417 - val_loss: 0.3925\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9423 - val_loss: 0.3754\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0070 - val_accuracy: 0.9420 - val_loss: 0.3624\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 0.9395 - val_loss: 0.4190\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.9451 - val_loss: 0.3765\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0087 - val_accuracy: 0.9441 - val_loss: 0.3822\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0066 - val_accuracy: 0.9410 - val_loss: 0.3769\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9429 - val_loss: 0.3597\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0124 - val_accuracy: 0.9413 - val_loss: 0.3861\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9426 - val_loss: 0.3885\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0085 - val_accuracy: 0.9454 - val_loss: 0.3884\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0056 - val_accuracy: 0.9463 - val_loss: 0.3706\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.9426 - val_loss: 0.4020\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9448 - val_loss: 0.3943\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9417 - val_loss: 0.3986\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.9460 - val_loss: 0.3832\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9420 - val_loss: 0.3989\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0170 - val_accuracy: 0.9426 - val_loss: 0.3872\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9423 - val_loss: 0.3985\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0044 - val_accuracy: 0.9401 - val_loss: 0.3911\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0045 - val_accuracy: 0.9473 - val_loss: 0.3786\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0110 - val_accuracy: 0.9404 - val_loss: 0.3992\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0116 - val_accuracy: 0.9410 - val_loss: 0.4094\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9438 - val_loss: 0.3874\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.9441 - val_loss: 0.3872\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9441 - val_loss: 0.3900\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.9410 - val_loss: 0.3838\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0079 - val_accuracy: 0.9457 - val_loss: 0.3888\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0043 - val_accuracy: 0.9410 - val_loss: 0.4134\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9423 - val_loss: 0.3931\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9441 - val_loss: 0.3843\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0073 - val_accuracy: 0.9463 - val_loss: 0.3982\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0075 - val_accuracy: 0.9460 - val_loss: 0.3678\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9441 - val_loss: 0.4189\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9470 - val_loss: 0.3921\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0043 - val_accuracy: 0.9432 - val_loss: 0.4125\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0096 - val_accuracy: 0.9432 - val_loss: 0.3853\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9457 - val_loss: 0.3966\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9401 - val_loss: 0.4183\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9441 - val_loss: 0.4161\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.9448 - val_loss: 0.4094\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 0.9451 - val_loss: 0.3903\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9466 - val_loss: 0.4021\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9479 - val_loss: 0.3940\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0070 - val_accuracy: 0.9426 - val_loss: 0.4143\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0109 - val_accuracy: 0.9466 - val_loss: 0.3936\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9441 - val_loss: 0.4113\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0059 - val_accuracy: 0.9473 - val_loss: 0.3883\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9398 - val_loss: 0.4316\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0057 - val_accuracy: 0.9420 - val_loss: 0.4214\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0073 - val_accuracy: 0.9460 - val_loss: 0.3927\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.9445 - val_loss: 0.3979\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9482 - val_loss: 0.3880\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0091 - val_accuracy: 0.9470 - val_loss: 0.3601\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0079 - val_accuracy: 0.9413 - val_loss: 0.4321\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0100 - val_accuracy: 0.9473 - val_loss: 0.3806\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9432 - val_loss: 0.3864\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9432 - val_loss: 0.3965\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0053 - val_accuracy: 0.9426 - val_loss: 0.3960\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9451 - val_loss: 0.3983\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0026 - val_accuracy: 0.9432 - val_loss: 0.4087\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.9441 - val_loss: 0.3962\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 0.9463 - val_loss: 0.3806\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9392 - val_loss: 0.4436\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0072 - val_accuracy: 0.9404 - val_loss: 0.4268\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9432 - val_loss: 0.4348\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0076 - val_accuracy: 0.9454 - val_loss: 0.3876\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9445 - val_loss: 0.3729\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0057 - val_accuracy: 0.9476 - val_loss: 0.3669\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0065 - val_accuracy: 0.9441 - val_loss: 0.3996\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9448 - val_loss: 0.3972\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9463 - val_loss: 0.3985\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0108 - val_accuracy: 0.9451 - val_loss: 0.3948\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9404 - val_loss: 0.4137\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9454 - val_loss: 0.4046\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9438 - val_loss: 0.4185\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0025 - val_accuracy: 0.9482 - val_loss: 0.3945\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.9429 - val_loss: 0.4140\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0114 - val_accuracy: 0.9445 - val_loss: 0.4087\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0084 - val_accuracy: 0.9451 - val_loss: 0.3995\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9470 - val_loss: 0.4069\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9441 - val_loss: 0.4040\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9445 - val_loss: 0.4132\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0036 - val_accuracy: 0.9426 - val_loss: 0.4274\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.9454 - val_loss: 0.4159\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0080 - val_accuracy: 0.9435 - val_loss: 0.4023\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9441 - val_loss: 0.3931\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.9441 - val_loss: 0.4099\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9488 - val_loss: 0.3990\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9429 - val_loss: 0.4130\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9441 - val_loss: 0.3992\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9466 - val_loss: 0.3901\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 0.9482 - val_loss: 0.3959\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9429 - val_loss: 0.4250\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9470 - val_loss: 0.3848\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9435 - val_loss: 0.4384\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0094 - val_accuracy: 0.9441 - val_loss: 0.3849\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 0.9476 - val_loss: 0.3911\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0066 - val_accuracy: 0.9460 - val_loss: 0.3926\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0022 - val_accuracy: 0.9420 - val_loss: 0.4061\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9445 - val_loss: 0.4083\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 9.7772e-04 - val_accuracy: 0.9479 - val_loss: 0.3960\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.9438 - val_loss: 0.4001\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0143 - val_accuracy: 0.9441 - val_loss: 0.3961\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.9457 - val_loss: 0.3975\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9466 - val_loss: 0.3992\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9482 - val_loss: 0.4026\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9460 - val_loss: 0.4161\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0159 - val_accuracy: 0.9457 - val_loss: 0.3472\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9491 - val_loss: 0.3563\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9426 - val_loss: 0.3873\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.9466 - val_loss: 0.3829\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9479 - val_loss: 0.3835\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0044 - val_accuracy: 0.9460 - val_loss: 0.4104\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9457 - val_loss: 0.4088\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9426 - val_loss: 0.4276\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0116 - val_accuracy: 0.9482 - val_loss: 0.3853\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9441 - val_loss: 0.3877\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9441 - val_loss: 0.4037\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0036 - val_accuracy: 0.9448 - val_loss: 0.4097\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0083 - val_accuracy: 0.9441 - val_loss: 0.4034\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0045 - val_accuracy: 0.9429 - val_loss: 0.4182\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.9404 - val_loss: 0.4213\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.9438 - val_loss: 0.4007\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9429 - val_loss: 0.4203\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9470 - val_loss: 0.4024\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 0.9445 - val_loss: 0.4145\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0032 - val_accuracy: 0.9432 - val_loss: 0.4121\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9441 - val_loss: 0.4150\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 9.7396e-04 - val_accuracy: 0.9448 - val_loss: 0.4289\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9448 - val_loss: 0.4241\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0133 - val_accuracy: 0.9438 - val_loss: 0.4227\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9417 - val_loss: 0.4283\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9432 - val_loss: 0.4444\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.9432 - val_loss: 0.4129\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0067 - val_accuracy: 0.9448 - val_loss: 0.4043\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0080 - val_accuracy: 0.9438 - val_loss: 0.3919\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9457 - val_loss: 0.3873\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9441 - val_loss: 0.3899\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9473 - val_loss: 0.3852\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9470 - val_loss: 0.3880\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 8.2773e-04 - val_accuracy: 0.9463 - val_loss: 0.3987\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 4.7850e-04 - val_accuracy: 0.9451 - val_loss: 0.4108\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9429 - val_loss: 0.4046\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9454 - val_loss: 0.3967\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0103 - val_accuracy: 0.9448 - val_loss: 0.3992\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0116 - val_accuracy: 0.9435 - val_loss: 0.4110\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9423 - val_loss: 0.4041\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9435 - val_loss: 0.4060\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9460 - val_loss: 0.4144\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9423 - val_loss: 0.4292\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0084 - val_accuracy: 0.9451 - val_loss: 0.4098\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 7.6209e-04 - val_accuracy: 0.9454 - val_loss: 0.4224\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9423 - val_loss: 0.4466\n\n\n\n\nINFO: Training model for R_HIP_injury_risk...\nINFO: Loaded 10 features for R_HIP_injury_risk\nINFO: Features have been scaled using StandardScaler.\nINFO: Created LSTM sequences: (12831, 5, 10), (12831,)\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\nEpoch 1/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 2s 2ms/step - accuracy: 0.9008 - loss: 0.2734 - val_accuracy: 0.9516 - val_loss: 0.1382\n\nEpoch 2/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9478 - loss: 0.1260 - val_accuracy: 0.9591 - val_loss: 0.1018\n\nEpoch 3/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9497 - loss: 0.1182 - val_accuracy: 0.9585 - val_loss: 0.0930\n\nEpoch 4/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9531 - loss: 0.1027 - val_accuracy: 0.9551 - val_loss: 0.1113\n\nEpoch 5/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9569 - loss: 0.0973 - val_accuracy: 0.9598 - val_loss: 0.0920\n\nEpoch 6/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9601 - loss: 0.0922 - val_accuracy: 0.9569 - val_loss: 0.1015\n\nEpoch 7/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9611 - loss: 0.0905 - val_accuracy: 0.9548 - val_loss: 0.1108\n\nEpoch 8/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9612 - loss: 0.0830 - val_accuracy: 0.9535 - val_loss: 0.1134\n\nEpoch 9/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9602 - loss: 0.0879 - val_accuracy: 0.9551 - val_loss: 0.1109\n\nEpoch 10/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9649 - loss: 0.0815 - val_accuracy: 0.9516 - val_loss: 0.1197\n\nEpoch 11/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9620 - loss: 0.0855 - val_accuracy: 0.9613 - val_loss: 0.0958\n\nEpoch 12/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9651 - loss: 0.0779 - val_accuracy: 0.9554 - val_loss: 0.0971\n\nEpoch 13/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9637 - loss: 0.0783 - val_accuracy: 0.9548 - val_loss: 0.1052\n\nEpoch 14/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9668 - loss: 0.0748 - val_accuracy: 0.9601 - val_loss: 0.0988\n\nEpoch 15/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9667 - loss: 0.0755 - val_accuracy: 0.9588 - val_loss: 0.1011\n\nEpoch 16/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9670 - loss: 0.0767 - val_accuracy: 0.9523 - val_loss: 0.1165\n\nEpoch 17/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9659 - loss: 0.0712 - val_accuracy: 0.9538 - val_loss: 0.1248\n\nEpoch 18/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9670 - loss: 0.0750 - val_accuracy: 0.9529 - val_loss: 0.1165\n\nEpoch 19/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9744 - loss: 0.0631 - val_accuracy: 0.9516 - val_loss: 0.1302\n\nEpoch 20/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9684 - loss: 0.0716 - val_accuracy: 0.9526 - val_loss: 0.1202\n\nEpoch 21/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9682 - loss: 0.0693 - val_accuracy: 0.9598 - val_loss: 0.0987\n\nEpoch 22/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9704 - loss: 0.0635 - val_accuracy: 0.9582 - val_loss: 0.1213\n\nEpoch 23/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9724 - loss: 0.0618 - val_accuracy: 0.9476 - val_loss: 0.1397\n\nEpoch 24/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9733 - loss: 0.0617 - val_accuracy: 0.9476 - val_loss: 0.1198\n\nEpoch 25/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9737 - loss: 0.0612 - val_accuracy: 0.9488 - val_loss: 0.1209\n\nEpoch 26/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9768 - loss: 0.0526 - val_accuracy: 0.9466 - val_loss: 0.1309\n\nEpoch 27/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9758 - loss: 0.0571 - val_accuracy: 0.9491 - val_loss: 0.1392\n\nEpoch 28/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9746 - loss: 0.0520 - val_accuracy: 0.9523 - val_loss: 0.1283\n\nEpoch 29/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9764 - loss: 0.0543 - val_accuracy: 0.9495 - val_loss: 0.1397\n\nEpoch 30/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9771 - loss: 0.0521 - val_accuracy: 0.9520 - val_loss: 0.1254\n\nEpoch 31/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9781 - loss: 0.0524 - val_accuracy: 0.9488 - val_loss: 0.1387\n\nEpoch 32/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9790 - loss: 0.0484 - val_accuracy: 0.9507 - val_loss: 0.1479\n\nEpoch 33/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9820 - loss: 0.0455 - val_accuracy: 0.9516 - val_loss: 0.1424\n\nEpoch 34/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9795 - loss: 0.0459 - val_accuracy: 0.9523 - val_loss: 0.1453\n\nEpoch 35/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9830 - loss: 0.0394 - val_accuracy: 0.9548 - val_loss: 0.1239\n\nEpoch 36/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9809 - loss: 0.0430 - val_accuracy: 0.9538 - val_loss: 0.1559\n\nEpoch 37/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9805 - loss: 0.0431 - val_accuracy: 0.9482 - val_loss: 0.1634\n\nEpoch 38/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9817 - loss: 0.0432 - val_accuracy: 0.9560 - val_loss: 0.1273\n\nEpoch 39/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9813 - loss: 0.0428 - val_accuracy: 0.9535 - val_loss: 0.1451\n\nEpoch 40/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9812 - loss: 0.0421 - val_accuracy: 0.9463 - val_loss: 0.1698\n\nEpoch 41/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0351 - val_accuracy: 0.9457 - val_loss: 0.1826\n\nEpoch 42/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9818 - loss: 0.0394 - val_accuracy: 0.9510 - val_loss: 0.1424\n\nEpoch 43/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9845 - loss: 0.0377 - val_accuracy: 0.9560 - val_loss: 0.1438\n\nEpoch 44/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9855 - loss: 0.0341 - val_accuracy: 0.9566 - val_loss: 0.1499\n\nEpoch 45/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9871 - loss: 0.0320 - val_accuracy: 0.9566 - val_loss: 0.1471\n\nEpoch 46/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9848 - loss: 0.0359 - val_accuracy: 0.9501 - val_loss: 0.1746\n\nEpoch 47/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9855 - loss: 0.0327 - val_accuracy: 0.9520 - val_loss: 0.1664\n\nEpoch 48/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9868 - loss: 0.0312 - val_accuracy: 0.9482 - val_loss: 0.1548\n\nEpoch 49/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9834 - loss: 0.0374 - val_accuracy: 0.9488 - val_loss: 0.1767\n\nEpoch 50/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9869 - loss: 0.0318 - val_accuracy: 0.9485 - val_loss: 0.1848\n\nEpoch 51/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9854 - loss: 0.0348 - val_accuracy: 0.9495 - val_loss: 0.1877\n\nEpoch 52/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9875 - loss: 0.0278 - val_accuracy: 0.9498 - val_loss: 0.1626\n\nEpoch 53/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9865 - loss: 0.0330 - val_accuracy: 0.9526 - val_loss: 0.1628\n\nEpoch 54/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9888 - loss: 0.0280 - val_accuracy: 0.9504 - val_loss: 0.1665\n\nEpoch 55/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9881 - loss: 0.0285 - val_accuracy: 0.9516 - val_loss: 0.1571\n\nEpoch 56/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9874 - loss: 0.0312 - val_accuracy: 0.9504 - val_loss: 0.1818\n\nEpoch 57/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9880 - loss: 0.0288 - val_accuracy: 0.9551 - val_loss: 0.1754\n\nEpoch 58/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9843 - loss: 0.0346 - val_accuracy: 0.9501 - val_loss: 0.1798\n\nEpoch 59/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0250 - val_accuracy: 0.9548 - val_loss: 0.1554\n\nEpoch 60/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9893 - loss: 0.0246 - val_accuracy: 0.9498 - val_loss: 0.1815\n\nEpoch 61/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9902 - loss: 0.0255 - val_accuracy: 0.9557 - val_loss: 0.1699\n\nEpoch 62/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9891 - loss: 0.0265 - val_accuracy: 0.9498 - val_loss: 0.2014\n\nEpoch 63/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9880 - loss: 0.0259 - val_accuracy: 0.9523 - val_loss: 0.2027\n\nEpoch 64/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9896 - loss: 0.0234 - val_accuracy: 0.9488 - val_loss: 0.1863\n\nEpoch 65/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9897 - loss: 0.0258 - val_accuracy: 0.9557 - val_loss: 0.1946\n\nEpoch 66/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9915 - loss: 0.0209 - val_accuracy: 0.9495 - val_loss: 0.1956\n\nEpoch 67/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0242 - val_accuracy: 0.9535 - val_loss: 0.1767\n\nEpoch 68/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9909 - loss: 0.0226 - val_accuracy: 0.9445 - val_loss: 0.2235\n\nEpoch 69/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0244 - val_accuracy: 0.9485 - val_loss: 0.2129\n\nEpoch 70/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9885 - loss: 0.0282 - val_accuracy: 0.9507 - val_loss: 0.2153\n\nEpoch 71/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9908 - loss: 0.0225 - val_accuracy: 0.9507 - val_loss: 0.2127\n\nEpoch 72/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0221 - val_accuracy: 0.9523 - val_loss: 0.2068\n\nEpoch 73/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0235 - val_accuracy: 0.9485 - val_loss: 0.2090\n\nEpoch 74/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9916 - loss: 0.0223 - val_accuracy: 0.9457 - val_loss: 0.2347\n\nEpoch 75/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9902 - loss: 0.0247 - val_accuracy: 0.9516 - val_loss: 0.1976\n\nEpoch 76/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9906 - loss: 0.0211 - val_accuracy: 0.9510 - val_loss: 0.2270\n\nEpoch 77/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9909 - loss: 0.0231 - val_accuracy: 0.9516 - val_loss: 0.2278\n\nEpoch 78/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9915 - loss: 0.0187 - val_accuracy: 0.9513 - val_loss: 0.1978\n\nEpoch 79/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9900 - loss: 0.0273 - val_accuracy: 0.9476 - val_loss: 0.2254\n\nEpoch 80/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0168 - val_accuracy: 0.9498 - val_loss: 0.2048\n\nEpoch 81/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0205 - val_accuracy: 0.9501 - val_loss: 0.2156\n\nEpoch 82/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9910 - loss: 0.0237 - val_accuracy: 0.9501 - val_loss: 0.2132\n\nEpoch 83/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0193 - val_accuracy: 0.9473 - val_loss: 0.2162\n\nEpoch 84/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0184 - val_accuracy: 0.9498 - val_loss: 0.2180\n\nEpoch 85/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0193 - val_accuracy: 0.9513 - val_loss: 0.2290\n\nEpoch 86/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0192 - val_accuracy: 0.9485 - val_loss: 0.2239\n\nEpoch 87/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9906 - loss: 0.0207 - val_accuracy: 0.9491 - val_loss: 0.2391\n\nEpoch 88/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9926 - loss: 0.0160 - val_accuracy: 0.9544 - val_loss: 0.2239\n\nEpoch 89/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0164 - val_accuracy: 0.9510 - val_loss: 0.2304\n\nEpoch 90/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9925 - loss: 0.0186 - val_accuracy: 0.9491 - val_loss: 0.2165\n\nEpoch 91/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9919 - loss: 0.0200 - val_accuracy: 0.9510 - val_loss: 0.2429\n\nEpoch 92/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9921 - loss: 0.0177 - val_accuracy: 0.9485 - val_loss: 0.2611\n\nEpoch 93/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9918 - loss: 0.0187 - val_accuracy: 0.9491 - val_loss: 0.2557\n\nEpoch 94/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9936 - loss: 0.0183 - val_accuracy: 0.9526 - val_loss: 0.2335\n\nEpoch 95/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0162 - val_accuracy: 0.9526 - val_loss: 0.2347\n\nEpoch 96/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9938 - loss: 0.0167 - val_accuracy: 0.9548 - val_loss: 0.2131\n\nEpoch 97/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0166 - val_accuracy: 0.9451 - val_loss: 0.2566\n\nEpoch 98/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0142 - val_accuracy: 0.9485 - val_loss: 0.2523\n\nEpoch 99/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9928 - loss: 0.0168 - val_accuracy: 0.9523 - val_loss: 0.2491\n\nEpoch 100/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9935 - loss: 0.0155 - val_accuracy: 0.9495 - val_loss: 0.2256\n\nEpoch 101/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0173 - val_accuracy: 0.9529 - val_loss: 0.2275\n\nEpoch 102/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0157 - val_accuracy: 0.9491 - val_loss: 0.2738\n\nEpoch 103/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9927 - loss: 0.0171 - val_accuracy: 0.9498 - val_loss: 0.2701\n\nEpoch 104/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9939 - loss: 0.0160 - val_accuracy: 0.9538 - val_loss: 0.2411\n\nEpoch 105/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0155 - val_accuracy: 0.9523 - val_loss: 0.2339\n\nEpoch 106/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0171 - val_accuracy: 0.9485 - val_loss: 0.2338\n\nEpoch 107/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0137 - val_accuracy: 0.9491 - val_loss: 0.2479\n\nEpoch 108/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0159 - val_accuracy: 0.9470 - val_loss: 0.2775\n\nEpoch 109/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9930 - loss: 0.0163 - val_accuracy: 0.9520 - val_loss: 0.2463\n\nEpoch 110/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9937 - loss: 0.0156 - val_accuracy: 0.9441 - val_loss: 0.2477\n\nEpoch 111/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9924 - loss: 0.0167 - val_accuracy: 0.9485 - val_loss: 0.2720\n\nEpoch 112/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9942 - loss: 0.0141 - val_accuracy: 0.9498 - val_loss: 0.2691\n\nEpoch 113/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0134 - val_accuracy: 0.9466 - val_loss: 0.2886\n\nEpoch 114/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0142 - val_accuracy: 0.9510 - val_loss: 0.2473\n\nEpoch 115/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0144 - val_accuracy: 0.9520 - val_loss: 0.2568\n\nEpoch 116/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0115 - val_accuracy: 0.9560 - val_loss: 0.2565\n\nEpoch 117/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0119 - val_accuracy: 0.9488 - val_loss: 0.3045\n\nEpoch 118/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0165 - val_accuracy: 0.9523 - val_loss: 0.2828\n\nEpoch 119/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0157 - val_accuracy: 0.9504 - val_loss: 0.3007\n\nEpoch 120/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0117 - val_accuracy: 0.9498 - val_loss: 0.2798\n\nEpoch 121/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0138 - val_accuracy: 0.9526 - val_loss: 0.2539\n\nEpoch 122/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0128 - val_accuracy: 0.9463 - val_loss: 0.2929\n\nEpoch 123/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0188 - val_accuracy: 0.9488 - val_loss: 0.2644\n\nEpoch 124/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9923 - loss: 0.0173 - val_accuracy: 0.9526 - val_loss: 0.2780\n\nEpoch 125/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0099 - val_accuracy: 0.9457 - val_loss: 0.3009\n\nEpoch 126/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0124 - val_accuracy: 0.9541 - val_loss: 0.2578\n\nEpoch 127/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0105 - val_accuracy: 0.9448 - val_loss: 0.2611\n\nEpoch 128/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9941 - loss: 0.0139 - val_accuracy: 0.9501 - val_loss: 0.2652\n\nEpoch 129/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0140 - val_accuracy: 0.9526 - val_loss: 0.2972\n\nEpoch 130/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0125 - val_accuracy: 0.9504 - val_loss: 0.2700\n\nEpoch 131/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0111 - val_accuracy: 0.9498 - val_loss: 0.3058\n\nEpoch 132/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0121 - val_accuracy: 0.9513 - val_loss: 0.2675\n\nEpoch 133/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0133 - val_accuracy: 0.9520 - val_loss: 0.2748\n\nEpoch 134/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9933 - loss: 0.0159 - val_accuracy: 0.9523 - val_loss: 0.2534\n\nEpoch 135/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9956 - loss: 0.0106 - val_accuracy: 0.9532 - val_loss: 0.2676\n\nEpoch 136/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9940 - loss: 0.0130 - val_accuracy: 0.9544 - val_loss: 0.2530\n\nEpoch 137/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0112 - val_accuracy: 0.9538 - val_loss: 0.2781\n\nEpoch 138/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9944 - loss: 0.0165 - val_accuracy: 0.9535 - val_loss: 0.2605\n\nEpoch 139/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0121 - val_accuracy: 0.9498 - val_loss: 0.2993\n\nEpoch 140/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0123 - val_accuracy: 0.9544 - val_loss: 0.2650\n\nEpoch 141/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9948 - loss: 0.0119 - val_accuracy: 0.9513 - val_loss: 0.3028\n\nEpoch 142/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0141 - val_accuracy: 0.9535 - val_loss: 0.2662\n\nEpoch 143/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0130 - val_accuracy: 0.9535 - val_loss: 0.2557\n\nEpoch 144/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9946 - loss: 0.0119 - val_accuracy: 0.9566 - val_loss: 0.2531\n\nEpoch 145/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0098 - val_accuracy: 0.9488 - val_loss: 0.2852\n\nEpoch 146/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0101 - val_accuracy: 0.9529 - val_loss: 0.2898\n\nEpoch 147/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0089 - val_accuracy: 0.9520 - val_loss: 0.2989\n\nEpoch 148/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0087 - val_accuracy: 0.9501 - val_loss: 0.2794\n\nEpoch 149/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9945 - loss: 0.0136 - val_accuracy: 0.9513 - val_loss: 0.2897\n\nEpoch 150/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9943 - loss: 0.0136 - val_accuracy: 0.9535 - val_loss: 0.2810\n\nEpoch 151/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0093 - val_accuracy: 0.9526 - val_loss: 0.2824\n\nEpoch 152/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0125 - val_accuracy: 0.9516 - val_loss: 0.3143\n\nEpoch 153/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0113 - val_accuracy: 0.9504 - val_loss: 0.2786\n\nEpoch 154/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0106 - val_accuracy: 0.9535 - val_loss: 0.2914\n\nEpoch 155/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0086 - val_accuracy: 0.9535 - val_loss: 0.2524\n\nEpoch 156/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0123 - val_accuracy: 0.9529 - val_loss: 0.2498\n\nEpoch 157/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0092 - val_accuracy: 0.9541 - val_loss: 0.2613\n\nEpoch 158/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0087 - val_accuracy: 0.9532 - val_loss: 0.2773\n\nEpoch 159/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0105 - val_accuracy: 0.9485 - val_loss: 0.3109\n\nEpoch 160/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.9529 - val_loss: 0.2886\n\nEpoch 161/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0111 - val_accuracy: 0.9507 - val_loss: 0.3086\n\nEpoch 162/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0081 - val_accuracy: 0.9520 - val_loss: 0.2940\n\nEpoch 163/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9951 - loss: 0.0117 - val_accuracy: 0.9510 - val_loss: 0.2699\n\nEpoch 164/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0093 - val_accuracy: 0.9563 - val_loss: 0.2831\n\nEpoch 165/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0083 - val_accuracy: 0.9504 - val_loss: 0.2856\n\nEpoch 166/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0104 - val_accuracy: 0.9544 - val_loss: 0.2668\n\nEpoch 167/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0080 - val_accuracy: 0.9538 - val_loss: 0.2608\n\nEpoch 168/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0152 - val_accuracy: 0.9538 - val_loss: 0.2837\n\nEpoch 169/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0082 - val_accuracy: 0.9501 - val_loss: 0.2745\n\nEpoch 170/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0092 - val_accuracy: 0.9535 - val_loss: 0.2782\n\nEpoch 171/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9953 - loss: 0.0118 - val_accuracy: 0.9495 - val_loss: 0.3033\n\nEpoch 172/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0121 - val_accuracy: 0.9538 - val_loss: 0.2681\n\nEpoch 173/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0088 - val_accuracy: 0.9529 - val_loss: 0.2841\n\nEpoch 174/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0081 - val_accuracy: 0.9491 - val_loss: 0.3045\n\nEpoch 175/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9958 - loss: 0.0097 - val_accuracy: 0.9554 - val_loss: 0.2553\n\nEpoch 176/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9548 - val_loss: 0.2584\n\nEpoch 177/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0095 - val_accuracy: 0.9526 - val_loss: 0.2766\n\nEpoch 178/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0136 - val_accuracy: 0.9544 - val_loss: 0.2864\n\nEpoch 179/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9950 - loss: 0.0104 - val_accuracy: 0.9516 - val_loss: 0.2898\n\nEpoch 180/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0105 - val_accuracy: 0.9529 - val_loss: 0.2957\n\nEpoch 181/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0086 - val_accuracy: 0.9557 - val_loss: 0.2688\n\nEpoch 182/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0089 - val_accuracy: 0.9560 - val_loss: 0.2531\n\nEpoch 183/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0074 - val_accuracy: 0.9560 - val_loss: 0.2819\n\nEpoch 184/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0152 - val_accuracy: 0.9544 - val_loss: 0.2832\n\nEpoch 185/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.9529 - val_loss: 0.2784\n\nEpoch 186/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0071 - val_accuracy: 0.9573 - val_loss: 0.2841\n\nEpoch 187/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0087 - val_accuracy: 0.9435 - val_loss: 0.3101\n\nEpoch 188/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0138 - val_accuracy: 0.9482 - val_loss: 0.2922\n\nEpoch 189/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.9520 - val_loss: 0.2959\n\nEpoch 190/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0094 - val_accuracy: 0.9535 - val_loss: 0.2964\n\nEpoch 191/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0124 - val_accuracy: 0.9513 - val_loss: 0.2744\n\nEpoch 192/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9952 - loss: 0.0131 - val_accuracy: 0.9573 - val_loss: 0.2653\n\nEpoch 193/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9949 - loss: 0.0198 - val_accuracy: 0.9535 - val_loss: 0.2697\n\nEpoch 194/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9929 - loss: 0.0188 - val_accuracy: 0.9551 - val_loss: 0.2538\n\nEpoch 195/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9947 - loss: 0.0137 - val_accuracy: 0.9529 - val_loss: 0.2588\n\nEpoch 196/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9955 - loss: 0.0109 - val_accuracy: 0.9560 - val_loss: 0.2730\n\nEpoch 197/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0081 - val_accuracy: 0.9544 - val_loss: 0.2815\n\nEpoch 198/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0083 - val_accuracy: 0.9523 - val_loss: 0.2767\n\nEpoch 199/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9959 - loss: 0.0099 - val_accuracy: 0.9554 - val_loss: 0.2833\n\nEpoch 200/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.9532 - val_loss: 0.2894\n\nEpoch 201/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0077 - val_accuracy: 0.9544 - val_loss: 0.2653\n\nEpoch 202/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0071 - val_accuracy: 0.9579 - val_loss: 0.2596\n\nEpoch 203/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0088 - val_accuracy: 0.9554 - val_loss: 0.2811\n\nEpoch 204/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0081 - val_accuracy: 0.9554 - val_loss: 0.2850\n\nEpoch 205/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0100 - val_accuracy: 0.9560 - val_loss: 0.2712\n\nEpoch 206/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0061 - val_accuracy: 0.9541 - val_loss: 0.2906\n\nEpoch 207/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0093 - val_accuracy: 0.9516 - val_loss: 0.2999\n\nEpoch 208/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0067 - val_accuracy: 0.9544 - val_loss: 0.2982\n\nEpoch 209/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0084 - val_accuracy: 0.9538 - val_loss: 0.2913\n\nEpoch 210/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 0.9526 - val_loss: 0.2955\n\nEpoch 211/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0071 - val_accuracy: 0.9548 - val_loss: 0.2836\n\nEpoch 212/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.9526 - val_loss: 0.3179\n\nEpoch 213/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.9566 - val_loss: 0.2691\n\nEpoch 214/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0081 - val_accuracy: 0.9523 - val_loss: 0.3207\n\nEpoch 215/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9529 - val_loss: 0.2928\n\nEpoch 216/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9960 - loss: 0.0087 - val_accuracy: 0.9541 - val_loss: 0.2940\n\nEpoch 217/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.9457 - val_loss: 0.3408\n\nEpoch 218/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9957 - loss: 0.0125 - val_accuracy: 0.9529 - val_loss: 0.3063\n\nEpoch 219/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0067 - val_accuracy: 0.9526 - val_loss: 0.3036\n\nEpoch 220/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0056 - val_accuracy: 0.9541 - val_loss: 0.3012\n\nEpoch 221/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9954 - loss: 0.0112 - val_accuracy: 0.9520 - val_loss: 0.2760\n\nEpoch 222/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0091 - val_accuracy: 0.9538 - val_loss: 0.3204\n\nEpoch 223/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.9554 - val_loss: 0.2693\n\nEpoch 224/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0055 - val_accuracy: 0.9576 - val_loss: 0.2798\n\nEpoch 225/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0060 - val_accuracy: 0.9551 - val_loss: 0.2620\n\nEpoch 226/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0085 - val_accuracy: 0.9526 - val_loss: 0.3061\n\nEpoch 227/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.9548 - val_loss: 0.2799\n\nEpoch 228/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9516 - val_loss: 0.2882\n\nEpoch 229/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0067 - val_accuracy: 0.9516 - val_loss: 0.2872\n\nEpoch 230/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9967 - loss: 0.0114 - val_accuracy: 0.9538 - val_loss: 0.2792\n\nEpoch 231/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.9529 - val_loss: 0.3005\n\nEpoch 232/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0046 - val_accuracy: 0.9507 - val_loss: 0.3142\n\nEpoch 233/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0059 - val_accuracy: 0.9504 - val_loss: 0.2851\n\nEpoch 234/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0054 - val_accuracy: 0.9573 - val_loss: 0.2757\n\nEpoch 235/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9961 - loss: 0.0141 - val_accuracy: 0.9445 - val_loss: 0.3208\n\nEpoch 236/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0085 - val_accuracy: 0.9529 - val_loss: 0.2923\n\nEpoch 237/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9529 - val_loss: 0.2968\n\nEpoch 238/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0051 - val_accuracy: 0.9529 - val_loss: 0.3054\n\nEpoch 239/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9557 - val_loss: 0.3052\n\nEpoch 240/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.9529 - val_loss: 0.2782\n\nEpoch 241/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0058 - val_accuracy: 0.9535 - val_loss: 0.2931\n\nEpoch 242/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0074 - val_accuracy: 0.9551 - val_loss: 0.3006\n\nEpoch 243/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9532 - val_loss: 0.2764\n\nEpoch 244/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0068 - val_accuracy: 0.9532 - val_loss: 0.2929\n\nEpoch 245/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0065 - val_accuracy: 0.9507 - val_loss: 0.3163\n\nEpoch 246/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9576 - val_loss: 0.2750\n\nEpoch 247/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9962 - loss: 0.0094 - val_accuracy: 0.9523 - val_loss: 0.3154\n\nEpoch 248/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 0.9498 - val_loss: 0.3191\n\nEpoch 249/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9491 - val_loss: 0.3258\n\nEpoch 250/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0075 - val_accuracy: 0.9526 - val_loss: 0.3074\n\nEpoch 251/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0053 - val_accuracy: 0.9538 - val_loss: 0.3120\n\nEpoch 252/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0057 - val_accuracy: 0.9535 - val_loss: 0.3352\n\nEpoch 253/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0102 - val_accuracy: 0.9529 - val_loss: 0.2980\n\nEpoch 254/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0050 - val_accuracy: 0.9541 - val_loss: 0.3001\n\nEpoch 255/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0074 - val_accuracy: 0.9548 - val_loss: 0.2922\n\nEpoch 256/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.9566 - val_loss: 0.2723\n\nEpoch 257/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9504 - val_loss: 0.3323\n\nEpoch 258/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.9532 - val_loss: 0.2908\n\nEpoch 259/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0064 - val_accuracy: 0.9541 - val_loss: 0.3138\n\nEpoch 260/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0042 - val_accuracy: 0.9551 - val_loss: 0.2988\n\nEpoch 261/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0055 - val_accuracy: 0.9541 - val_loss: 0.3119\n\nEpoch 262/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0097 - val_accuracy: 0.9548 - val_loss: 0.2946\n\nEpoch 263/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0077 - val_accuracy: 0.9573 - val_loss: 0.2948\n\nEpoch 264/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9573 - val_loss: 0.2791\n\nEpoch 265/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 0.9476 - val_loss: 0.3303\n\nEpoch 266/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0071 - val_accuracy: 0.9498 - val_loss: 0.3287\n\nEpoch 267/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9510 - val_loss: 0.3236\n\nEpoch 268/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0046 - val_accuracy: 0.9532 - val_loss: 0.3196\n\nEpoch 269/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0047 - val_accuracy: 0.9532 - val_loss: 0.3209\n\nEpoch 270/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0042 - val_accuracy: 0.9541 - val_loss: 0.3139\n\nEpoch 271/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0054 - val_accuracy: 0.9551 - val_loss: 0.3145\n\nEpoch 272/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0095 - val_accuracy: 0.9566 - val_loss: 0.3012\n\nEpoch 273/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0062 - val_accuracy: 0.9576 - val_loss: 0.2962\n\nEpoch 274/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0060 - val_accuracy: 0.9516 - val_loss: 0.3032\n\nEpoch 275/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0079 - val_accuracy: 0.9516 - val_loss: 0.3039\n\nEpoch 276/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.9554 - val_loss: 0.3032\n\nEpoch 277/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0037 - val_accuracy: 0.9532 - val_loss: 0.3226\n\nEpoch 278/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0034 - val_accuracy: 0.9557 - val_loss: 0.3170\n\nEpoch 279/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9557 - val_loss: 0.2906\n\nEpoch 280/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0055 - val_accuracy: 0.9554 - val_loss: 0.2967\n\nEpoch 281/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0044 - val_accuracy: 0.9563 - val_loss: 0.3091\n\nEpoch 282/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.9566 - val_loss: 0.3063\n\nEpoch 283/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9529 - val_loss: 0.3447\n\nEpoch 284/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9551 - val_loss: 0.2989\n\nEpoch 285/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9573 - val_loss: 0.3162\n\nEpoch 286/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0050 - val_accuracy: 0.9554 - val_loss: 0.2993\n\nEpoch 287/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9557 - val_loss: 0.2829\n\nEpoch 288/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9563 - val_loss: 0.2842\n\nEpoch 289/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0066 - val_accuracy: 0.9548 - val_loss: 0.3055\n\nEpoch 290/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9969 - loss: 0.0084 - val_accuracy: 0.9548 - val_loss: 0.2923\n\nEpoch 291/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 0.9520 - val_loss: 0.3005\n\nEpoch 292/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 0.9523 - val_loss: 0.2952\n\nEpoch 293/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.9557 - val_loss: 0.2763\n\nEpoch 294/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0043 - val_accuracy: 0.9523 - val_loss: 0.2974\n\nEpoch 295/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9560 - val_loss: 0.3011\n\nEpoch 296/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0067 - val_accuracy: 0.9529 - val_loss: 0.3057\n\nEpoch 297/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0056 - val_accuracy: 0.9532 - val_loss: 0.3179\n\nEpoch 298/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0047 - val_accuracy: 0.9601 - val_loss: 0.2929\n\nEpoch 299/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 0.9538 - val_loss: 0.3112\n\nEpoch 300/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0067 - val_accuracy: 0.9585 - val_loss: 0.2988\n\nEpoch 301/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9551 - val_loss: 0.3097\n\nEpoch 302/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.9554 - val_loss: 0.3264\n\nEpoch 303/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 0.9544 - val_loss: 0.3278\n\nEpoch 304/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.9544 - val_loss: 0.3127\n\nEpoch 305/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.9541 - val_loss: 0.3085\n\nEpoch 306/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9563 - val_loss: 0.3150\n\nEpoch 307/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.9520 - val_loss: 0.3352\n\nEpoch 308/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9532 - val_loss: 0.3451\n\nEpoch 309/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0092 - val_accuracy: 0.9582 - val_loss: 0.3002\n\nEpoch 310/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.9544 - val_loss: 0.3220\n\nEpoch 311/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9563 - val_loss: 0.3166\n\nEpoch 312/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9548 - val_loss: 0.3157\n\nEpoch 313/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.9523 - val_loss: 0.3463\n\nEpoch 314/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0060 - val_accuracy: 0.9579 - val_loss: 0.3180\n\nEpoch 315/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9523 - val_loss: 0.3161\n\nEpoch 316/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0056 - val_accuracy: 0.9551 - val_loss: 0.2943\n\nEpoch 317/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9554 - val_loss: 0.2973\n\nEpoch 318/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0023 - val_accuracy: 0.9532 - val_loss: 0.3008\n\nEpoch 319/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0058 - val_accuracy: 0.9510 - val_loss: 0.3110\n\nEpoch 320/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9498 - val_loss: 0.3240\n\nEpoch 321/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0048 - val_accuracy: 0.9548 - val_loss: 0.3005\n\nEpoch 322/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0032 - val_accuracy: 0.9498 - val_loss: 0.3526\n\nEpoch 323/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9523 - val_loss: 0.3207\n\nEpoch 324/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.9569 - val_loss: 0.3033\n\nEpoch 325/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0045 - val_accuracy: 0.9513 - val_loss: 0.3167\n\nEpoch 326/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0053 - val_accuracy: 0.9557 - val_loss: 0.3101\n\nEpoch 327/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9569 - val_loss: 0.3096\n\nEpoch 328/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9554 - val_loss: 0.3087\n\nEpoch 329/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9963 - loss: 0.0102 - val_accuracy: 0.9566 - val_loss: 0.2628\n\nEpoch 330/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 0.9529 - val_loss: 0.3137\n\nEpoch 331/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9566 - val_loss: 0.2938\n\nEpoch 332/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9532 - val_loss: 0.3221\n\nEpoch 333/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9541 - val_loss: 0.3166\n\nEpoch 334/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0029 - val_accuracy: 0.9513 - val_loss: 0.3425\n\nEpoch 335/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0035 - val_accuracy: 0.9563 - val_loss: 0.3013\n\nEpoch 336/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.9551 - val_loss: 0.3172\n\nEpoch 337/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9569 - val_loss: 0.2952\n\nEpoch 338/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9563 - val_loss: 0.3019\n\nEpoch 339/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.9554 - val_loss: 0.3231\n\nEpoch 340/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9501 - val_loss: 0.3052\n\nEpoch 341/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9965 - loss: 0.0122 - val_accuracy: 0.9569 - val_loss: 0.2781\n\nEpoch 342/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0034 - val_accuracy: 0.9579 - val_loss: 0.2988\n\nEpoch 343/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9544 - val_loss: 0.3069\n\nEpoch 344/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0064 - val_accuracy: 0.9576 - val_loss: 0.2895\n\nEpoch 345/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9582 - val_loss: 0.3035\n\nEpoch 346/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9563 - val_loss: 0.3311\n\nEpoch 347/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9520 - val_loss: 0.3139\n\nEpoch 348/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0085 - val_accuracy: 0.9560 - val_loss: 0.3220\n\nEpoch 349/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.9576 - val_loss: 0.2907\n\nEpoch 350/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0037 - val_accuracy: 0.9573 - val_loss: 0.2992\n\nEpoch 351/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.9563 - val_loss: 0.3139\n\nEpoch 352/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9598 - val_loss: 0.3043\n\nEpoch 353/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9598 - val_loss: 0.3118\n\nEpoch 354/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0036 - val_accuracy: 0.9576 - val_loss: 0.3351\n\nEpoch 355/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9551 - val_loss: 0.3568\n\nEpoch 356/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0045 - val_accuracy: 0.9560 - val_loss: 0.3327\n\nEpoch 357/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 0.9563 - val_loss: 0.3299\n\nEpoch 358/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0056 - val_accuracy: 0.9563 - val_loss: 0.3509\n\nEpoch 359/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0052 - val_accuracy: 0.9535 - val_loss: 0.3575\n\nEpoch 360/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9491 - val_loss: 0.3866\n\nEpoch 361/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0071 - val_accuracy: 0.9532 - val_loss: 0.3478\n\nEpoch 362/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.9507 - val_loss: 0.3562\n\nEpoch 363/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0098 - val_accuracy: 0.9579 - val_loss: 0.3046\n\nEpoch 364/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0021 - val_accuracy: 0.9573 - val_loss: 0.3188\n\nEpoch 365/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9544 - val_loss: 0.3234\n\nEpoch 366/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0022 - val_accuracy: 0.9582 - val_loss: 0.3211\n\nEpoch 367/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9554 - val_loss: 0.3381\n\nEpoch 368/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0045 - val_accuracy: 0.9538 - val_loss: 0.3058\n\nEpoch 369/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0020 - val_accuracy: 0.9544 - val_loss: 0.3295\n\nEpoch 370/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9557 - val_loss: 0.3124\n\nEpoch 371/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.9566 - val_loss: 0.3140\n\nEpoch 372/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0034 - val_accuracy: 0.9557 - val_loss: 0.3371\n\nEpoch 373/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9551 - val_loss: 0.3328\n\nEpoch 374/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9560 - val_loss: 0.3491\n\nEpoch 375/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 0.9554 - val_loss: 0.3223\n\nEpoch 376/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.9554 - val_loss: 0.3432\n\nEpoch 377/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9598 - val_loss: 0.3118\n\nEpoch 378/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9972 - loss: 0.0096 - val_accuracy: 0.9529 - val_loss: 0.3438\n\nEpoch 379/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0030 - val_accuracy: 0.9526 - val_loss: 0.3701\n\nEpoch 380/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9569 - val_loss: 0.3450\n\nEpoch 381/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.9551 - val_loss: 0.3638\n\nEpoch 382/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 0.9557 - val_loss: 0.3461\n\nEpoch 383/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9979 - loss: 0.0080 - val_accuracy: 0.9541 - val_loss: 0.3369\n\nEpoch 384/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9560 - val_loss: 0.3146\n\nEpoch 385/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9563 - val_loss: 0.3261\n\nEpoch 386/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9526 - val_loss: 0.3559\n\nEpoch 387/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9504 - val_loss: 0.3727\n\nEpoch 388/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0067 - val_accuracy: 0.9516 - val_loss: 0.3642\n\nEpoch 389/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0020 - val_accuracy: 0.9510 - val_loss: 0.3845\n\nEpoch 390/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9529 - val_loss: 0.3815\n\nEpoch 391/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9501 - val_loss: 0.3791\n\nEpoch 392/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9970 - loss: 0.0111 - val_accuracy: 0.9510 - val_loss: 0.3576\n\nEpoch 393/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0059 - val_accuracy: 0.9532 - val_loss: 0.3315\n\nEpoch 394/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9529 - val_loss: 0.3557\n\nEpoch 395/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 0.9532 - val_loss: 0.3529\n\nEpoch 396/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 8.1463e-04 - val_accuracy: 0.9560 - val_loss: 0.3332\n\nEpoch 397/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.9544 - val_loss: 0.3290\n\nEpoch 398/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 0.9551 - val_loss: 0.3226\n\nEpoch 399/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9554 - val_loss: 0.3259\n\nEpoch 400/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9529 - val_loss: 0.3313\n\nEpoch 401/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.9554 - val_loss: 0.3218\n\nEpoch 402/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9544 - val_loss: 0.3508\n\nEpoch 403/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9984 - loss: 0.0042 - val_accuracy: 0.9535 - val_loss: 0.3268\n\nEpoch 404/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9541 - val_loss: 0.3527\n\nEpoch 405/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.9526 - val_loss: 0.3501\n\nEpoch 406/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9573 - val_loss: 0.3407\n\nEpoch 407/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.9566 - val_loss: 0.3285\n\nEpoch 408/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9566 - val_loss: 0.3473\n\nEpoch 409/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9569 - val_loss: 0.3424\n\nEpoch 410/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0098 - val_accuracy: 0.9566 - val_loss: 0.3179\n\nEpoch 411/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9532 - val_loss: 0.3398\n\nEpoch 412/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.9573 - val_loss: 0.3164\n\nEpoch 413/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0019 - val_accuracy: 0.9538 - val_loss: 0.3470\n\nEpoch 414/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9526 - val_loss: 0.3457\n\nEpoch 415/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9551 - val_loss: 0.3346\n\nEpoch 416/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9554 - val_loss: 0.3477\n\nEpoch 417/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9516 - val_loss: 0.3395\n\nEpoch 418/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.9548 - val_loss: 0.3242\n\nEpoch 419/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0047 - val_accuracy: 0.9538 - val_loss: 0.3262\n\nEpoch 420/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9526 - val_loss: 0.3332\n\nEpoch 421/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 0.9548 - val_loss: 0.3263\n\nEpoch 422/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9551 - val_loss: 0.3244\n\nEpoch 423/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.9560 - val_loss: 0.3303\n\nEpoch 424/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9535 - val_loss: 0.3495\n\nEpoch 425/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9968 - loss: 0.0078 - val_accuracy: 0.9501 - val_loss: 0.3534\n\nEpoch 426/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0068 - val_accuracy: 0.9548 - val_loss: 0.3066\n\nEpoch 427/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9541 - val_loss: 0.3190\n\nEpoch 428/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 8.7372e-04 - val_accuracy: 0.9548 - val_loss: 0.3178\n\nEpoch 429/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 9.1576e-04 - val_accuracy: 0.9563 - val_loss: 0.3276\n\nEpoch 430/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9520 - val_loss: 0.3567\n\nEpoch 431/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9513 - val_loss: 0.3354\n\nEpoch 432/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9569 - val_loss: 0.3264\n\nEpoch 433/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9535 - val_loss: 0.3314\n\nEpoch 434/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0023 - val_accuracy: 0.9538 - val_loss: 0.3329\n\nEpoch 435/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9588 - val_loss: 0.3107\n\nEpoch 436/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0019 - val_accuracy: 0.9516 - val_loss: 0.3769\n\nEpoch 437/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9526 - val_loss: 0.3728\n\nEpoch 438/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9541 - val_loss: 0.3675\n\nEpoch 439/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0051 - val_accuracy: 0.9535 - val_loss: 0.3301\n\nEpoch 440/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0107 - val_accuracy: 0.9535 - val_loss: 0.3317\n\nEpoch 441/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9538 - val_loss: 0.3428\n\nEpoch 442/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9560 - val_loss: 0.3360\n\nEpoch 443/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9529 - val_loss: 0.3405\n\nEpoch 444/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 0.9532 - val_loss: 0.3318\n\nEpoch 445/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9548 - val_loss: 0.3035\n\nEpoch 446/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9538 - val_loss: 0.3492\n\nEpoch 447/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.9529 - val_loss: 0.3104\n\nEpoch 448/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9526 - val_loss: 0.3139\n\nEpoch 449/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9544 - val_loss: 0.3243\n\nEpoch 450/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9551 - val_loss: 0.3288\n\nEpoch 451/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9541 - val_loss: 0.3511\n\nEpoch 452/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9510 - val_loss: 0.3463\n\nEpoch 453/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 0.9526 - val_loss: 0.3293\n\nEpoch 454/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0048 - val_accuracy: 0.9526 - val_loss: 0.3355\n\nEpoch 455/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9557 - val_loss: 0.2998\n\nEpoch 456/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.9582 - val_loss: 0.3135\n\nEpoch 457/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 8.1867e-04 - val_accuracy: 0.9560 - val_loss: 0.3397\n\nEpoch 458/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0020 - val_accuracy: 0.9576 - val_loss: 0.3263\n\nEpoch 459/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.9576 - val_loss: 0.3205\n\nEpoch 460/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9973 - loss: 0.0059 - val_accuracy: 0.9544 - val_loss: 0.3323\n\nEpoch 461/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9538 - val_loss: 0.3395\n\nEpoch 462/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9548 - val_loss: 0.3236\n\nEpoch 463/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9573 - val_loss: 0.3066\n\nEpoch 464/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 8.9702e-04 - val_accuracy: 0.9544 - val_loss: 0.3300\n\nEpoch 465/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9520 - val_loss: 0.3615\n\nEpoch 466/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9520 - val_loss: 0.3407\n\nEpoch 467/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0040 - val_accuracy: 0.9535 - val_loss: 0.3279\n\nEpoch 468/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9977 - loss: 0.0053 - val_accuracy: 0.9532 - val_loss: 0.3228\n\nEpoch 469/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9538 - val_loss: 0.3331\n\nEpoch 470/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 8.4425e-04 - val_accuracy: 0.9526 - val_loss: 0.3549\n\nEpoch 471/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 5.1477e-04 - val_accuracy: 0.9529 - val_loss: 0.3459\n\nEpoch 472/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9538 - val_loss: 0.3658\n\nEpoch 473/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9538 - val_loss: 0.3216\n\nEpoch 474/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9976 - loss: 0.0067 - val_accuracy: 0.9560 - val_loss: 0.3059\n\nEpoch 475/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9535 - val_loss: 0.3277\n\nEpoch 476/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0016 - val_accuracy: 0.9548 - val_loss: 0.3428\n\nEpoch 477/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9504 - val_loss: 0.3713\n\nEpoch 478/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 4.6766e-04 - val_accuracy: 0.9529 - val_loss: 0.3709\n\nEpoch 479/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9529 - val_loss: 0.3732\n\nEpoch 480/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9998 - loss: 6.5820e-04 - val_accuracy: 0.9510 - val_loss: 0.3821\n\nEpoch 481/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9974 - loss: 0.0087 - val_accuracy: 0.9526 - val_loss: 0.3572\n\nEpoch 482/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9975 - loss: 0.0064 - val_accuracy: 0.9560 - val_loss: 0.3133\n\nEpoch 483/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9529 - val_loss: 0.3438\n\nEpoch 484/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9520 - val_loss: 0.3549\n\nEpoch 485/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 6.7081e-04 - val_accuracy: 0.9560 - val_loss: 0.3505\n\nEpoch 486/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9548 - val_loss: 0.3560\n\nEpoch 487/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9999 - loss: 7.3747e-04 - val_accuracy: 0.9551 - val_loss: 0.3653\n\nEpoch 488/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9526 - val_loss: 0.3714\n\nEpoch 489/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9563 - val_loss: 0.3318\n\nEpoch 490/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9966 - loss: 0.0096 - val_accuracy: 0.9544 - val_loss: 0.3339\n\nEpoch 491/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.9526 - val_loss: 0.3292\n\nEpoch 492/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9516 - val_loss: 0.3323\n\nEpoch 493/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9990 - loss: 0.0023 - val_accuracy: 0.9579 - val_loss: 0.3187\n\nEpoch 494/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9560 - val_loss: 0.3174\n\nEpoch 495/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9980 - loss: 0.0079 - val_accuracy: 0.9548 - val_loss: 0.3340\n\nEpoch 496/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9548 - val_loss: 0.3302\n\nEpoch 497/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.9551 - val_loss: 0.3333\n\nEpoch 498/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9554 - val_loss: 0.3382\n\nEpoch 499/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.9566 - val_loss: 0.3237\n\nEpoch 500/500\n\n401/401 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9993 - loss: 0.0012 - val_accuracy: 0.9557 - val_loss: 0.3488\n\n\n\n\nINFO: Saved loaded features list for each joint model to 'loaded_features.json'.\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 8), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n\n\n\n\n\n\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step\n\n\n\n\n\n\n\n\n\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 760us/step\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 730us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 895us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 8), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 835us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 789us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 895us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 785us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 860us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 870us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 9), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 775us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 735us/step\n\n\n\n\nINFO: Created LSTM sequences: (3205, 5, 10), (3205,)\n\n\n\n101/101 ━━━━━━━━━━━━━━━━━━━━ 0s 945us/step\n\n\n\n\nINFO: Saved model summary dataframe to ../../data/Deep_Learning_Final/all_models_summary.csv\n\n\n=== Model Summaries ===\n                  Model            Type      MSE       MAE  R2 Score  \\\n0      Exhaustion Model      Regression  0.00596  0.017617  0.918078   \n1          Injury Model  Classification      NaN       NaN       NaN   \n2   L_ANKLE_injury_risk  Classification      NaN       NaN       NaN   \n3   R_ANKLE_injury_risk  Classification      NaN       NaN       NaN   \n4   L_WRIST_injury_risk  Classification      NaN       NaN       NaN   \n5   R_WRIST_injury_risk  Classification      NaN       NaN       NaN   \n6   L_ELBOW_injury_risk  Classification      NaN       NaN       NaN   \n7   R_ELBOW_injury_risk  Classification      NaN       NaN       NaN   \n8    L_KNEE_injury_risk  Classification      NaN       NaN       NaN   \n9    R_KNEE_injury_risk  Classification      NaN       NaN       NaN   \n10    L_HIP_injury_risk  Classification      NaN       NaN       NaN   \n11    R_HIP_injury_risk  Classification      NaN       NaN       NaN   \n\n    Accuracy  Precision    Recall  F1 Score  \n0        NaN        NaN       NaN       NaN  \n1   0.981591   0.938445  0.997704  0.967168  \n2   0.872075   0.854452  0.605583  0.708807  \n3   0.870827   0.761129  0.783240  0.772026  \n4   0.974103   0.944196  0.962457  0.953239  \n5   0.975351   0.950518  0.958237  0.954362  \n6   0.967239   0.915138  0.962606  0.938272  \n7   0.961934   0.892405  0.976905  0.932745  \n8   0.941030   0.861556  0.917174  0.888496  \n9   0.947270   0.866463  0.957207  0.909577  \n10  0.942278   0.851064  0.946746  0.896359  \n11  0.955694   0.890295  0.956916  0.922404"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Capstone Project: Modeling Fatigue and Injury Risk in Baseball Pitching",
    "section": "",
    "text": "Fatigue and injury risk modeling have become pivotal in sports analytics, particularly for baseball pitchers. Predicting fatigue levels and assessing injury risk help in optimizing training programs and enhancing athlete longevity. Long Short-Term Memory (LSTM) networks, a type of Recurrent Neural Network (RNN), offer significant potential due to their ability to capture temporal patterns and sequential dependencies, critical in physiological and biomechanical data analysis.\nRecent developments have showcased that fatigue accumulation can directly impact injury susceptibility, highlighting the importance of accurately modeling temporal fatigue progression. This project aims to leverage LSTM models to effectively forecast fatigue levels and predict joint injury risks in baseball pitchers, contributing valuable insights for injury prevention strategies and optimized athletic performance.\nPrevious research on LSTM’s efficacy in fatigue modeling forms the basis of our methodological approach, emphasizing the use of biomechanical and simulated physiological data."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Capstone Project: Modeling Fatigue and Injury Risk in Baseball Pitching",
    "section": "",
    "text": "Fatigue and injury risk modeling have become pivotal in sports analytics, particularly for baseball pitchers. Predicting fatigue levels and assessing injury risk help in optimizing training programs and enhancing athlete longevity. Long Short-Term Memory (LSTM) networks, a type of Recurrent Neural Network (RNN), offer significant potential due to their ability to capture temporal patterns and sequential dependencies, critical in physiological and biomechanical data analysis.\nRecent developments have showcased that fatigue accumulation can directly impact injury susceptibility, highlighting the importance of accurately modeling temporal fatigue progression. This project aims to leverage LSTM models to effectively forecast fatigue levels and predict joint injury risks in baseball pitchers, contributing valuable insights for injury prevention strategies and optimized athletic performance.\nPrevious research on LSTM’s efficacy in fatigue modeling forms the basis of our methodological approach, emphasizing the use of biomechanical and simulated physiological data."
  },
  {
    "objectID": "index.html#methods",
    "href": "index.html#methods",
    "title": "Capstone Project: Modeling Fatigue and Injury Risk in Baseball Pitching",
    "section": "Methods",
    "text": "Methods\n\nLSTM (Long Short-Term Memory) Networks\nLong Short-Term Memory (LSTM) networks are a specialized type of Recurrent Neural Network (RNN) designed to overcome the vanishing gradient problem that typically hinders standard RNNs when modeling long-term dependencies. Unlike traditional RNNs, LSTMs utilize gating mechanisms to selectively retain or discard information over sequences.\nThe core components of an LSTM cell include:\n\nForget Gate:\n\\[f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\\]\nDetermines which information to remove from the cell state.\nInput Gate:\n\\[i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\\]\n\\[\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)\\]\nDecides which new candidate values to add to the cell state.\nCell State Update:\n\\[C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t\\]\nOutput Gate:\n\\[o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\\]\n\\[h_t = o_t \\odot \\tanh(C_t)\\]\nControls the information output to the next hidden state.\n\nHere, ( W ) and ( b ) represent weights and biases, respectively, ( ) is the sigmoid function, and ( ) is element-wise multiplication.\nCompared to standard RNNs, LSTMs are especially effective in handling data with temporal correlations—making them suitable for modeling fatigue progression and injury risk in sequential biomechanical and physiological data."
  },
  {
    "objectID": "index.html#data-description",
    "href": "index.html#data-description",
    "title": "Capstone Project: Modeling Fatigue and Injury Risk in Baseball Pitching",
    "section": "Data Description",
    "text": "Data Description\nThe dataset utilized in this project comprises biomechanical and simulated physiological data collected from baseball pitchers at Driveline Baseball. Data was gathered during pitching trials, incorporating joint-level biomechanical metrics and simulated physiological signals.\n\nVariables Overview\n\nJoint Metrics:\n\nJoint Energy (Joules, range: 50–250 J)\nJoint Power (Watts, range: 100–1000 W)\n\nSimulated Physiological Metrics:\n\nSimulated Heart Rate (beats per minute, range: 60–180 bpm)\nSleep Quality (index score, range: 0–100)\nSleep Duration (hours, range: 4–10 hrs)\nResting Heart Rate (beats per minute, range: 40–70 bpm)\nHeart Rate Variability (milliseconds, range: 20–150 ms)\nStress Index (index score, range: 0–100)\n\nTemporal Features:\n\nTrial Exhaustion Rate (dimensionless, normalized between 0–1)\nLag and rolling average features derived from trials\n\nAsymmetry Features:\n\nDifferences between left/right joints (Joules, range: -50 to 50 J)\n\n\n\n\nDescriptive Statistics\n\n\n\n\n\n\n\n\n\n\n\nVariable\nType\nMean\nStd Dev\nMin\nMax\n\n\n\n\nJoint Energy\nNumeric\n150\n25\n50\n250\n\n\nJoint Power\nNumeric\n550\n120\n100\n1000\n\n\nSimulated Heart Rate\nNumeric\n120\n15\n60\n180\n\n\nSleep Quality\nNumeric\n75\n10\n40\n100\n\n\nSleep Duration\nNumeric\n7\n1.2\n4\n10\n\n\nResting Heart Rate\nNumeric\n55\n7\n40\n70\n\n\nHeart Rate Variability\nNumeric\n80\n15\n20\n150\n\n\nStress Index\nNumeric\n50\n20\n0\n100\n\n\n\n\n\nData Visualizations\n\nHistogram distributions for joint metrics.\nScatter plots showing correlation between physiological metrics and fatigue rates.\nTemporal trend lines visualizing progression across trials.\n\n\nAbstract\nIn this capstone project, we leverage real athlete data from Driveline Baseball alongside novel sensor measurements to predict fatigue and joint injury risks in baseball pitchers. Using an LSTM-based recurrent neural network (RNN) architecture, the project combines biomechanical data with simulated physiological metrics. Two parallel pipelines—one for regression (predicting trial exhaustion rates) and another for classification (identifying joint injury risk)—are developed. This work integrates advanced feature engineering, temporal dynamics, and modular data preprocessing, offering robust insights for injury prevention and performance analytics. Introduction\nRecent advances in sports science have underscored the importance of combining biomechanical and physiological data for injury prevention. In my internship at Driveline Baseball, the dataset was upgraded to include real athlete data. To further enhance the analysis, this project incorporates EMG sensors to capture muscle contraction, acceleration, and gyroscopic measurements during the pitching motion. These additional measurements—placed on the flexor carpi radialis (FCR) and other key muscles—aim to improve the prediction of ulnar collateral ligament (UCL) injuries.\nTwo resources support this work:\nThe raw sensor data is being compiled and will be available at emg_fatigue_analysis.\n\nA pre-established pipeline for LSTM-based fatigue prediction is available at LSTM RNN Pipeline.\nLiterature Review\nThe literature indicates that predicting fatigue and injury risk in athletes requires an integration of biomechanical outputs with physiological signals. Key findings from previous studies include:\nAthlete Burnout: Research has shown that burnout is influenced by multiple factors (e.g., stress, training load, support systems) that vary among athletes. Customizing training and recovery protocols based on individual warning signs may mitigate injury risks.\n\nFatigue Data Collection: Detailed datasets have been published to capture muscle activity, motion capture data, and self-reported fatigue levels during shoulder rotations. These resources serve as a foundation for building predictive algorithms.\n\nMethodological Advances: Recent studies have applied neural network architectures to model fatigue—such as a fully-connected network for predicting crack growth in metals [DOI: 10.1016/j.engfracmech.2020.107402]—and used combined physical and physiological workload metrics to forecast injury risk in professional soccer players [DOI: 10.52082/jssm.2024.537].\nThese studies, along with tutorials on SHAP values and Bayesian optimization from DataCamp, inform our approach to feature engineering and model selection. Methodology Data Loading and Preprocessing\nThe project begins by merging a CSV file containing trial-level measurements (e.g., joint energy and power) with participant metadata using unique identifiers like trial_id and player_participant_id. Rigorous data cleaning (including imputation and removal of missing values) is performed with comprehensive logging and debugging routines. Feature Engineering\nKey features derived in this project include:\nJoint Metrics: Aggregated joint energy and power are computed to serve as primary indicators of physical output.\n\nSimulated Physiological Measures: A simulated heart rate is calculated as a function of mean and joint energy. In addition, “fake body” metrics (sleep quality, sleep duration, resting heart rate, heart rate variability, and stress index) are introduced to mimic wearable sensor data.\n\nTemporal Dynamics: Lag features (e.g., previous trial exhaustion) and rolling statistics (moving averages, volatility measures) capture trends across trials. The trial exhaustion rate is defined as the change in exhaustion per trial.\n\nAsymmetry Features: Differences between left and right joint metrics are measured to detect imbalances that may predispose athletes to injury.\nWorkout Simulation\nTo mimic the progression of fatigue:\nWorkout 1: Contains the original 125 trials.\n\nWorkout 2: Is a duplicate of the original trials but simulates gradual deterioration in fake body metrics (e.g., lower sleep quality, higher resting heart rate) by adding a workout_id and trial counter. These two datasets are concatenated to form a comprehensive dataset for subsequent modeling.\nPredictive Modeling Pipelines Pipeline 1: Regression for Predicting Trial Exhaustion Rate\nInput Features: Aggregated joint metrics, simulated physiological features, and temporal features.\n\nModel: A baseline linear regression model is used, with future plans to incorporate Random Forests, Gradient Boosting, or LSTM networks.\n\nEvaluation: Model performance is assessed using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R², along with visualizations comparing predicted versus actual exhaustion rates.\nPipeline 2: Classification for Predicting Joint Injury Risk\nInput Features: Joint-specific metrics, asymmetry measurements, and cumulative load indicators.\n\nLabeling: Trials are classified as high injury risk if a rolling sum of joint stress exceeds a threshold (e.g., the 75th percentile).\n\nModel: Initially, logistic regression or decision tree classifiers are employed. Future work may involve Random Forests or neural network-based methods.\n\nEvaluation: Metrics such as accuracy, precision, recall, F1-score, and ROC-AUC are used, supplemented by feature importance analyses using SHAP values.\nIntegration and Modularity\nBoth pipelines share common preprocessing and feature engineering modules, ensuring that the workflow is modular and reproducible. Visualization tools—including histograms, correlation matrices, and temporal trend plots—are used throughout the analysis to validate each transformation step. Experimental Results\nThe LSTM-based regression model for fatigue prediction demonstrated promising results:\nMSE: 0.00596\n\nMAE: 0.01762\n\nR² Score: 0.91808\nSimilarly, the injury risk classifier achieved strong performance:\nOverall Accuracy: 98.16%\n\nPrecision: 93.84%\n\nRecall: 99.77%\n\nF1 Score: 96.72%\nJoint-specific models yielded varying metrics, reflecting the inherent complexity of localized biomechanical data. Discussion\nThis project illustrates the successful application of deep learning to model fatigue and predict injury risk in a real-world sports setting. Key challenges included managing the variability in biomechanical signals and optimizing model performance through careful feature engineering. The integration of temporal dynamics and asymmetry features was critical in capturing the underlying physiological responses. Future work may explore attention mechanisms or hybrid architectures to further refine predictive accuracy. Conclusion\nBy combining real athlete data with simulated physiological metrics, this capstone project provides a novel approach to predicting fatigue and injury risks in baseball pitchers. The dual-pipeline strategy (regression and classification) along with modular integration of preprocessing and feature engineering modules establishes a robust framework that is transparent, reproducible, and adaptable for future research and practical deployment. References\nDataCamp Tutorial: Introduction to SHAP Values for Machine Learning Interpretability\n\nDataCamp Tutorial: Mastering Bayesian Optimization in Data Science\n\nFatigue Analysis Study, DOI: 10.1016/j.engfracmech.2020.107402\n\nInjury Prediction Study, DOI: 10.52082/jssm.2024.537\n\nNature Articles:\n\n    Factors Leading to Athlete Burnout\n\n    Dataset for Fatigue Analysis during Shoulder Rotations"
  }
]